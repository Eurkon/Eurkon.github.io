<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1,viewport-fit=cover"><title>Spark RDD 常用算子</title><meta name="author" content="Eurkon,eurkon@foxmail.com"><meta name="copyright" content="Eurkon"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="ffffff"><meta name="description" content="Spark 的算子的分类 从大方向来说，Spark 算子大致可以分为以下两类:  Transformation 变换&#x2F;转换算子：这种变换并不触发提交作业，完成作业中间过程处理。 Transformation 操作是延迟计算的，也就是说从一个 RDD 转换生成另一个 RDD 的转换操作不是马上执行，需要等到有 Action 操作的时候才会真正触发运算。  Action 行动算子：这类算子会触发 Sp"><meta property="og:type" content="article"><meta property="og:title" content="Spark RDD 常用算子"><meta property="og:url" content="https://blog.eurkon.com/post/c55e5115.html"><meta property="og:site_name" content="Eurkon"><meta property="og:description" content="Spark 的算子的分类 从大方向来说，Spark 算子大致可以分为以下两类:  Transformation 变换&#x2F;转换算子：这种变换并不触发提交作业，完成作业中间过程处理。 Transformation 操作是延迟计算的，也就是说从一个 RDD 转换生成另一个 RDD 的转换操作不是马上执行，需要等到有 Action 操作的时候才会真正触发运算。  Action 行动算子：这类算子会触发 Sp"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="https://blog.eurkon.com/images/cover/spark_rdd.jpg"><meta property="article:published_time" content="2021-05-07T01:00:00.000Z"><meta property="article:modified_time" content="2021-05-07T01:00:00.000Z"><meta property="article:author" content="Eurkon"><meta property="article:tag" content="大数据"><meta property="article:tag" content="Spark"><meta name="twitter:card" content="summary"><meta name="twitter:image" content="https://blog.eurkon.com/images/cover/spark_rdd.jpg"><link rel="shortcut icon" href="https://npm.elemecdn.com/eurkon-cdn/hexo/images/user/favicon.jpg"><link rel="canonical" href="https://blog.eurkon.com/post/c55e5115.html"><link rel="preconnect" href="//cdn.jsdelivr.net"><link rel="preconnect" href="//hm.baidu.com"><link rel="preconnect" href="//busuanzi.ibruce.info"><meta name="google-site-verification" content="rClKrjtCYPsDaynvUNmfe2YGPxb7ehnuwEF9aMdG7no"><meta name="msvalidate.01" content="F299EA4E7AD0E2B28FDF4E0EA94879BA"><meta name="baidu-site-verification" content="code-GmAI2TORJk"><meta name="360-site-verification" content="ac410c1012e6f0acc65b5c0805c91f01"><meta name="yandex-verification" content="ac410c1012e6f0acc65b5c0805c91f01"><meta name="bytedance-verification-code" content="D4gz9gUv9Wh0pS4d20uQ"><meta name="sogou_site_verification" content="uYYKpHOGXl"><link rel="stylesheet" href="/css/index.css?v=5.1.0"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.6.0/css/all.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/node-snackbar@0.1.16/dist/snackbar.min.css" media="print" onload='this.media="all"'><script>(() => {
      
    const saveToLocal = {
      set: (key, value, ttl) => {
        if (!ttl) return
        const expiry = Date.now() + ttl * 86400000
        localStorage.setItem(key, JSON.stringify({ value, expiry }))
      },
      get: key => {
        const itemStr = localStorage.getItem(key)
        if (!itemStr) return undefined
        const { value, expiry } = JSON.parse(itemStr)
        if (Date.now() > expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return value
      }
    }

    window.btf = {
      saveToLocal,
      getScript: (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        Object.entries(attr).forEach(([key, val]) => script.setAttribute(key, val))
        script.onload = script.onreadystatechange = () => {
          if (!script.readyState || /loaded|complete/.test(script.readyState)) resolve()
        }
        script.onerror = reject
        document.head.appendChild(script)
      }),
      getCSS: (url, id) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onload = link.onreadystatechange = () => {
          if (!link.readyState || /loaded|complete/.test(link.readyState)) resolve()
        }
        link.onerror = reject
        document.head.appendChild(link)
      }),
      addGlobalFn: (key, fn, name = false, parent = window) => {
        if (!true && key.startsWith('pjax')) return
        const globalFn = parent.globalFn || {}
        globalFn[key] = globalFn[key] || {}
        if (name && globalFn[key][name]) return
        globalFn[key][name || Object.keys(globalFn[key]).length] = fn
        parent.globalFn = globalFn
      }
    }
  
      
      const activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      const activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', 'ffffff')
        }
      }

      btf.activateDarkMode = activateDarkMode
      btf.activateLightMode = activateLightMode

      const theme = saveToLocal.get('theme')
    
          theme === 'dark' ? activateDarkMode() : theme === 'light' ? activateLightMode() : null
        
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        document.documentElement.classList.toggle('hide-aside', asideStatus === 'hide')
      }
    
      
    const detectApple = () => {
      if (/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)) {
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
  
    })()</script><script>var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?ca4902422e728abe0603d52ce2e7757a";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
btf.addGlobalFn('pjaxComplete', () => {
  _hmt.push(['_trackPageview',window.location.pathname])
}, 'baidu_analytics')</script><script>!function(a){"use strict";!function(t){var e=window,s=document,c=a,i="".concat("https:"===s.location.protocol?"https://":"http://","sdk.51.la/js-sdk-pro.min.js"),n=s.createElement("script"),r=s.getElementsByTagName("script")[0];n.type="text/javascript",n.setAttribute("charset","UTF-8"),n.async=!0,n.src=i,n.id="LA_COLLECT",c.d=n;var o=function(){e.LA.ids.push(c)};e.LA?e.LA.ids&&o():(e.LA=a,e.LA.ids=[],o()),r.parentNode.insertBefore(n,r)}()}({id:"Je3G46ggxUPbVh1P",ck:"Je3G46ggxUPbVh1P"})</script><script>!function(e,t,n,i){var r=t.createElement("script"),s=t.getElementsByTagName("script")[0];r.type="text/javascript",r.crossorigin=!0,r.onload=function(){(new e.LingQue.Monitor).init({id:"Je3HZw0g4jpQRh3f"})},s.parentNode.insertBefore(r,s),r.src="https://sdk.51.la/perf/js-sdk-perf.min.js"}(window,document)</script><script>const GLOBAL_CONFIG = {
  root: '/',
  emoji: {"categories":{"面试系列":"📝","魔改教程":"🎨","生活随笔":"💬","学习笔记":"📚","分享转载":"🌐","作品案例":"🖥️"},"tags":null},
  algolia: undefined,
  localSearch: {"path":"/search.xml","preload":false,"top_n_per_article":1,"unescape":false,"languages":{"hits_empty":"未找到符合您查询的内容：${query}","hits_stats":"共找到 ${hits} 篇文章"}},
  translate: {"defaultEncoding":2,"translateDelay":0,"msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"簡"},
  noticeOutdate: undefined,
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":250,"highlightFullpage":false,"highlightMacStyle":false},
  copy: {
    success: '复制成功',
    error: '复制失败',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'null',
  Snackbar: {"chs_to_cht":"已切换为繁体中文","cht_to_chs":"已切换为简体中文","day_to_night":"已切换为深色模式","night_to_day":"已切换为浅色模式","bgLight":"#1677B3","bgDark":"#1f1f1f","position":"top-right"},
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid@4.12.0/dist/infinitegrid.min.js',
    buttonText: '加载更多'
  },
  isPhotoFigcaption: false,
  islazyload: true,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE={title:"Spark RDD 常用算子",isPost:!0,isHome:!1,isHighlightShrink:!1,isToc:!0,postUpdate:"2021-05-07 09:00:00"}</script><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/custom.css"><link rel="stylesheet" href="https://lf3-cdn-tos.bytecdntp.com/cdn/expire-1-M/Swiper/8.0.6/swiper-bundle.min.css"><script src="https://lf3-cdn-tos.bytecdntp.com/cdn/expire-1-M/Swiper/8.0.6/swiper-bundle.min.js"></script><script src="https://npm.elemecdn.com/echarts/dist/echarts.js"></script><script src="https://npm.elemecdn.com/echarts@4.9.0/map/js/china.js"></script><script src="https://npm.elemecdn.com/echarts-wordcloud/dist/echarts-wordcloud.js"></script><script src="https://npm.elemecdn.com/echarts-liquidfill/dist/echarts-liquidfill.js"></script><script src="/js/Lately.min.js"></script><meta name="generator" content="Hexo 5.4.0"><link rel="alternate" href="/atom.xml" title="Eurkon" type="application/atom+xml"><link rel="alternate" href="/rss.xml" title="Eurkon" type="application/rss+xml"></head><body><div id="loading-box"><div class="loading-left-bg"></div><div class="loading-right-bg"></div><i class="fa fas fa-spinner fa-spin load-spinner"></i></div><script>const preloader = {
  endLoading: () => {
    document.body.style.overflow = 'auto';
    document.getElementById('loading-box').style.transition = 'opacity 1s';
    document.getElementById('loading-box').style.opacity = '0';
    setTimeout(function () { document.getElementById('loading-box').classList.add("loaded") }, 1000)
    document.body.classList.remove("hidden-y")
  },
  initLoading: () => {
    document.body.style.overflow = '';
    document.getElementById('loading-box').style.transition = '';
    document.getElementById('loading-box').style.opacity = '1'; 
    document.getElementById('loading-box').classList.remove("loaded")
    document.body.classList.add("hidden-y")
  }
}
window.addEventListener('load',()=> { preloader.endLoading() })

if (true) {
  document.addEventListener('pjax:send', () => { preloader.initLoading() })
  document.addEventListener('pjax:complete', () => { preloader.endLoading() })
}

setTimeout(function () { preloader.endLoading() }, 3000)
document.getElementById('loading-box').addEventListener('click', () => { preloader.endLoading() })</script><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img text-center"><img src="https://npm.elemecdn.com/eurkon-cdn/hexo/images/user/avatar.jpg" onerror='onerror=null,src="https://npm.elemecdn.com/eurkon-cdn/hexo/images/user/loading.gif"' alt="avatar"></div><div class="site-data text-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">88</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">28</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">6</div></a></div><div class="menus_items"><div class="menus_item"><span class="site-page group"><i class="fa-fw fas fa-book-open"></i> <span>文章</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="/archives/"><i class="fa-fw fas fa-archive"></i> <span>文章列表</span></a></li><li><a class="site-page child" href="/categories/"><i class="fa-fw fas fa-shapes"></i> <span>全部分类</span></a></li><li><a class="site-page child" href="/tags/"><i class="fa-fw fas fa-tags"></i> <span>所有标签</span></a></li><li><a class="site-page child" href="javascript:toRandomPost();" rel="external nofollow noreferrer"><i class="fa-fw fas fa-random"></i> <span>随便看看</span></a></li></ul></div><div class="menus_item"><span class="site-page group"><i class="fa-fw fas fa-chart-bar"></i> <span>统计</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="/charts/"><i class="fa-fw fas fa-chart-area"></i> <span>文章统计</span></a></li><li><a class="site-page child" href="/census/"><i class="fa-fw fas fa-chart-line"></i> <span>博客统计</span></a></li></ul></div><div class="menus_item"><span class="site-page group"><i class="fa-fw fas fa-link"></i> <span>导航</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="/fcircle/"><i class="fa-fw fas fa-blog"></i> <span>友链订阅</span></a></li><li><a class="site-page child" href="/link/"><i class="fa-fw fas fa-user-friends"></i> <span>友情链接</span></a></li><li><a class="site-page child" href="/stars/"><i class="fa-fw fas fa-star"></i> <span>网站收藏</span></a></li></ul></div><div class="menus_item"><span class="site-page group"><i class="fa-fw fas fa-laptop"></i> <span>博客</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="/about/"><i class="fa-fw fas fa-address-card"></i> <span>关于本站</span></a></li><li><a class="site-page child" href="/notice/"><i class="fa-fw fas fa-bullhorn"></i> <span>网站公告</span></a></li><li><a class="site-page child" href="/message/"><i class="fa-fw fas fa-envelope"></i> <span>留言信箱</span></a></li><li><a class="site-page child" href="/update/"><i class="fa-fw fas fa-cloud-upload-alt"></i> <span>博客更新</span></a></li></ul></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image:url(/images/cover/spark_rdd.jpg)"><nav id="nav"><div id="nav-group"><span id="blog-info"><a class="site-page" href="/" title="Eurkon"><span class="site-name">Eurkon</span><i class="fas fa-home"></i></a></span><a class="nav-page-title" title="回到顶部" onclick="btf.scrollToDest(0,500)"><span class="site-name" id="page-title">Spark RDD 常用算子</span></a><div id="menus"><div class="menus_items"><div class="menus_item"><span class="site-page group"><i class="fa-fw fas fa-book-open"></i> <span>文章</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="/archives/"><i class="fa-fw fas fa-archive"></i> <span>文章列表</span></a></li><li><a class="site-page child" href="/categories/"><i class="fa-fw fas fa-shapes"></i> <span>全部分类</span></a></li><li><a class="site-page child" href="/tags/"><i class="fa-fw fas fa-tags"></i> <span>所有标签</span></a></li><li><a class="site-page child" href="javascript:toRandomPost();" rel="external nofollow noreferrer"><i class="fa-fw fas fa-random"></i> <span>随便看看</span></a></li></ul></div><div class="menus_item"><span class="site-page group"><i class="fa-fw fas fa-chart-bar"></i> <span>统计</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="/charts/"><i class="fa-fw fas fa-chart-area"></i> <span>文章统计</span></a></li><li><a class="site-page child" href="/census/"><i class="fa-fw fas fa-chart-line"></i> <span>博客统计</span></a></li></ul></div><div class="menus_item"><span class="site-page group"><i class="fa-fw fas fa-link"></i> <span>导航</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="/fcircle/"><i class="fa-fw fas fa-blog"></i> <span>友链订阅</span></a></li><li><a class="site-page child" href="/link/"><i class="fa-fw fas fa-user-friends"></i> <span>友情链接</span></a></li><li><a class="site-page child" href="/stars/"><i class="fa-fw fas fa-star"></i> <span>网站收藏</span></a></li></ul></div><div class="menus_item"><span class="site-page group"><i class="fa-fw fas fa-laptop"></i> <span>博客</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="/about/"><i class="fa-fw fas fa-address-card"></i> <span>关于本站</span></a></li><li><a class="site-page child" href="/notice/"><i class="fa-fw fas fa-bullhorn"></i> <span>网站公告</span></a></li><li><a class="site-page child" href="/message/"><i class="fa-fw fas fa-envelope"></i> <span>留言信箱</span></a></li><li><a class="site-page child" href="/update/"><i class="fa-fw fas fa-cloud-upload-alt"></i> <span>博客更新</span></a></li></ul></div></div></div><div id="hotkey"><div id="search-button"><span class="site-page social-icon search" href="javascript:void(0);" title="搜索"><i class="fas fa-search fa-fw"></i> <span>搜索</span></span></div><div id="comment-button"><a class="site-page" href="#post-comment" title="前往评论"><i class="fas fa-comments fa-fw"></i></a></div><div id="setting-button" onclick="eurkon.switchRightSide()"><a class="site-page" href="javascript:void(0);" rel="external nofollow noreferrer" title="设置"><i class="fas fa-screwdriver-wrench fa-fw"></i></a></div><div id="top-button"><a class="site-page" href="javascript:void(0);" rel="external nofollow noreferrer" title="回到顶部" onclick="btf.scrollToDest(0,500)"><span class="scroll-percent"></span><i class="fas fa-arrow-up fa-fw"></i></a></div><div id="toggle-menu"><a class="site-page" href="javascript:void(0);" rel="external nofollow noreferrer"><i class="fas fa-bars fa-fw"></i></a></div></div></div></nav><div id="post-cover"><img class="cover" id="post-cover-img" src="/images/cover/spark_rdd.jpg" alt="cover"></div><div id="post-info"><div id="post-meta"><div class="meta-firstline"><span class="post-meta-categories"><i class="fas fa-shapes fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/">📚学习笔记</a></span><span class="post-meta-tags"><span class="post-meta-separator">|</span><i class="fas fa-tags fa-fw post-meta-icon"></i><a class="post-meta-tags" href="/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/">大数据</a><span class="post-meta-separator">•</span><a class="post-meta-tags" href="/tags/Spark/">Spark</a></span></div><h1 class="post-title">Spark RDD 常用算子</h1><div class="meta-secondline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2021-05-07T01:00:00.000Z" title="发表于 2021-05-07 09:00:00">2021-05-07</time></span><span class="post-meta-separator">|</span><span class="post-meta-date"><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2021-05-07T01:00:00.000Z" title="更新于 2021-05-07 09:00:00">2021-05-07</time></span><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">总字数:</span><span class="word-count">10,070</span><span class="post-meta-separator">|</span></span><span class="post-meta-min2read"><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>48分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" data-flag-title=""><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">浏览量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span><span class="post-meta-separator">|</span><span class="post-meta-commentcount"><i class="far fa-comments fa-fw post-meta-icon"></i><span class="post-meta-label">评论数:</span><a href="/post/c55e5115.html#post-comment"><span id="twikoo-count"><i class="fa-solid fa-spinner fa-spin"></i></span></a></span></div></div></div><section class="main-hero-waves-area waves-area"><svg class="waves-svg" xmlns="http://www.w3.org/2000/svg" xlink="http://www.w3.org/1999/xlink" viewBox="0 24 150 28" preserveAspectRatio="none" shape-rendering="auto"><defs><path id="gentle-wave" d="M-160 44c30 0 58-18 88-18s58 18 88 18 58-18 88-18 58 18 88 18v44h-352Z"></path></defs><g class="parallax"><use href="#gentle-wave" x="48" y="0"></use><use href="#gentle-wave" x="48" y="3"></use><use href="#gentle-wave" x="48" y="5"></use><use href="#gentle-wave" x="48" y="7"></use></g></svg></section></header><main class="layout" id="content-inner"><div><div id="post"><article class="post-content" id="article-container"><h2 id="Spark-的算子的分类"><a href="#Spark-的算子的分类" class="headerlink" title="Spark 的算子的分类"></a>Spark 的算子的分类</h2><ul><li><p>从大方向来说，Spark 算子大致可以分为以下两类:</p><ul><li><p><strong>Transformation 变换/转换算子</strong>：这种变换并不触发提交作业，完成作业中间过程处理。</p><p>Transformation 操作是延迟计算的，也就是说从一个 RDD 转换生成另一个 RDD 的转换操作不是马上执行，需要等到有 Action 操作的时候才会真正触发运算。</p></li><li><p><strong>Action 行动算子</strong>：这类算子会触发 SparkContext 提交 Job 作业。</p><p>Action 算子会触发 Spark 提交作业（Job），并将数据输出 Spark 系统。</p></li></ul></li><li><p>从小方向来说，Spark 算子大致可以分为以下三类:</p><ul><li><a href="#Value-数据类型的-Transformation-算子">Value 数据类型的 Transformation 算子</a>，这种变换并不触发提交作业，针对处理的数据项是 Value 型的数据。</li><li><a href="#Key-Value-数据类型的-Transformation-算子">Key-Value 数据类型的 Transformation 算子</a>，这种变换并不触发提交作业，针对处理的数据项是 Key-Value 型的数据对。</li><li><a href="#Action-算子">Action 算子</a>，这类算子会触发 SparkContext 提交 Job 作业。</li></ul></li></ul><h2 id="Value-数据类型的-Transformation-算子"><a href="#Value-数据类型的-Transformation-算子" class="headerlink" title="Value 数据类型的 Transformation 算子"></a>Value 数据类型的 Transformation 算子</h2><h3 id="输入分区与输出分区一对一型"><a href="#输入分区与输出分区一对一型" class="headerlink" title="输入分区与输出分区一对一型"></a>输入分区与输出分区一对一型</h3><h4 id="map-算子"><a href="#map-算子" class="headerlink" title="map 算子"></a>map 算子</h4><ul><li><p><strong>说明：</strong>通过将函数应用于此 RDD 的所有元素来返回新的 RDD。</p><p>将原来 RDD 的每个数据项通过 map 中的用户自定义函数 f 映射转变为一个新的元素。源码中 map 算子相当于初始化一个 RDD， 新 RDD 叫做 MappedRDD(this, sc.clean(f))。</p><p>图中每个方框表示一个 RDD 分区，左侧的分区经过用户自定义函数 <code>f:T-&gt;U</code> 映射为右侧的新 RDD 分区。但是，实际只有等到 Action 算子触发后，这个 f 函数才会和其他函数在一个 stage 中对数据进行运算。在图中的第一个分区，数据记录 V1 输入 f，通过 f 转换输出为转换后的分区中的数据记录 V&#39;1。</p><p><img src="https://npm.elemecdn.com/eurkon-cdn/hexo/images/user/loading.gif" data-lazy-src="/images/post/spark_rdd/map.png" alt="map 算子"></p></li><li><p><strong>用法：</strong></p><p></p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">map</span></span>[<span class="type">U</span>](f: (<span class="type">T</span>) ⇒ <span class="type">U</span>)(<span class="keyword">implicit</span> arg0: <span class="type">ClassTag</span>[<span class="type">U</span>]): <span class="type">RDD</span>[<span class="type">U</span>]</span><br><span class="line"><span class="type">Return</span> a <span class="keyword">new</span> <span class="type">RDD</span> by applying a function to all elements of <span class="keyword">this</span> <span class="type">RDD</span>.</span><br></pre></td></tr></table></figure><p></p></li><li><p><strong>示例：</strong></p><p></p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> data = sc.parallelize(<span class="number">1</span> to <span class="number">10</span>, <span class="number">3</span>)</span><br><span class="line">data.map(item =&gt; item + <span class="number">1</span>).collect</span><br><span class="line">data.map(_ + <span class="number">1</span>).collect</span><br><span class="line"></span><br><span class="line"><span class="comment">// 输出结果</span></span><br><span class="line">data: org.apache.spark.rdd.<span class="type">RDD</span>[<span class="type">Int</span>] = <span class="type">ParallelCollectionRDD</span>[<span class="number">0</span>] at parallelize at &lt;console&gt;:<span class="number">25</span></span><br><span class="line">res0: <span class="type">Array</span>[<span class="type">Int</span>] = <span class="type">Array</span>(<span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>, <span class="number">10</span>, <span class="number">11</span>)</span><br><span class="line">res1: <span class="type">Array</span>[<span class="type">Int</span>] = <span class="type">Array</span>(<span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>, <span class="number">10</span>, <span class="number">11</span>)</span><br></pre></td></tr></table></figure><p></p></li></ul><h4 id="flatMap-算子"><a href="#flatMap-算子" class="headerlink" title="flatMap 算子"></a>flatMap 算子</h4><ul><li><p><strong>说明：</strong>首先向该 RDD 的所有元素应用函数，然后将结果展平，以返回新的 RDD。</p><p>将原来 RDD 中的每个元素通过函数 f 转换为新的元素，并将生成的 RDD 的每个集合中的元素合并为一个集合，内部创建 FlatMappedRDD(this，sc.clean(f))。</p><p>下图表示 RDD 的一个分区，进行 flatMap 函数操作，flatMap 中传入的函数为 <code>f:T-&gt;U</code>， T 和 U 可以是任意的数据类型。将分区中的数据通过用户自定义函数 f 转换为新的数据。外部大方框可以认为是一个 RDD 分区，小方框代表一个集合。 V1、 V2、 V3 在一个集合作为 RDD 的一个数据项，可能存储为数组或其他容器，转换为 V&#39;1、 V&#39;2、 V&#39;3 后，将原来的数组或容器结合拆散，拆散的数据形成为 RDD 中的数据项。</p><p><img src="https://npm.elemecdn.com/eurkon-cdn/hexo/images/user/loading.gif" data-lazy-src="/images/post/spark_rdd/flat_map.png" alt="flatMap 算子"></p></li><li><p><strong>用法：</strong></p><p></p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">flatMap</span></span>[<span class="type">U</span>](f: (<span class="type">T</span>) ⇒ <span class="type">TraversableOnce</span>[<span class="type">U</span>])(<span class="keyword">implicit</span> arg0: <span class="type">ClassTag</span>[<span class="type">U</span>]): <span class="type">RDD</span>[<span class="type">U</span>]</span><br><span class="line"><span class="type">Return</span> a <span class="keyword">new</span> <span class="type">RDD</span> by first applying a function to all elements of <span class="keyword">this</span> <span class="type">RDD</span>, and then flattening the results.</span><br></pre></td></tr></table></figure><p></p></li><li><p><strong>示例：</strong></p><p></p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> data = sc.parallelize(<span class="number">1</span> to <span class="number">10</span>, <span class="number">3</span>)</span><br><span class="line">data.flatMap(item =&gt; item to <span class="number">10</span>).collect</span><br><span class="line">data.flatMap(_ to <span class="number">10</span>).collect</span><br><span class="line"></span><br><span class="line"><span class="comment">// 输出结果</span></span><br><span class="line">data: org.apache.spark.rdd.<span class="type">RDD</span>[<span class="type">Int</span>] = <span class="type">ParallelCollectionRDD</span>[<span class="number">0</span>] at parallelize at &lt;console&gt;:<span class="number">25</span></span><br><span class="line">res0: <span class="type">Array</span>[<span class="type">Int</span>] = <span class="type">Array</span>(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>, <span class="number">10</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>, <span class="number">10</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>, <span class="number">10</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>, <span class="number">10</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>, <span class="number">10</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>, <span class="number">10</span>, <span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>, <span class="number">10</span>, <span class="number">8</span>, <span class="number">9</span>, <span class="number">10</span>, <span class="number">9</span>, <span class="number">10</span>, <span class="number">10</span>)</span><br><span class="line">res1: <span class="type">Array</span>[<span class="type">Int</span>] = <span class="type">Array</span>(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>, <span class="number">10</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>, <span class="number">10</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>, <span class="number">10</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>, <span class="number">10</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>, <span class="number">10</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>, <span class="number">10</span>, <span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>, <span class="number">10</span>, <span class="number">8</span>, <span class="number">9</span>, <span class="number">10</span>, <span class="number">9</span>, <span class="number">10</span>, <span class="number">10</span>)</span><br></pre></td></tr></table></figure><p></p></li></ul><h4 id="mapPartitions-算子"><a href="#mapPartitions-算子" class="headerlink" title="mapPartitions 算子"></a>mapPartitions 算子</h4><ul><li><p><strong>说明：</strong>通过将函数应用于此 RDD 的每个分区来返回新的 RDD。</p><p>mapPartitions 函数获取到每个分区的迭代器，在函数中通过这个分区整体的迭代器对整个分区的元素进行操作。内部实现是生成 MapPartitionsRDD。图中的方框代表一个 RDD 分区，用户通过函数 <code>f(iter)=&gt;iter.filter(_&gt;=3)</code> 对分区中所有数据进行过滤，大于和等于 3 的数据保留。一个方块代表一个 RDD 分区，含有 1、2、3 的分区过滤只剩下元素 3。</p><p><img src="https://npm.elemecdn.com/eurkon-cdn/hexo/images/user/loading.gif" data-lazy-src="/images/post/spark_rdd/map_partitions.png" alt="mapPartitions 算子"></p></li><li><p><strong>用法：</strong></p><p></p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">mapPartitions</span></span>[<span class="type">U</span>](f: (<span class="type">Iterator</span>[<span class="type">T</span>]) ⇒ <span class="type">Iterator</span>[<span class="type">U</span>], preservesPartitioning: <span class="type">Boolean</span> = <span class="literal">false</span>)(<span class="keyword">implicit</span> arg0: <span class="type">ClassTag</span>[<span class="type">U</span>]): <span class="type">RDD</span>[<span class="type">U</span>]</span><br><span class="line"><span class="type">Return</span> a <span class="keyword">new</span> <span class="type">RDD</span> by applying a function to each partition of <span class="keyword">this</span> <span class="type">RDD</span>.</span><br></pre></td></tr></table></figure><p></p></li><li><p><strong>示例：</strong></p><p></p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> data = sc.parallelize(<span class="number">1</span> to <span class="number">10</span>, <span class="number">3</span>)</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">func</span></span>(it: <span class="type">Iterator</span>[<span class="type">Int</span>]): <span class="type">Iterator</span>[<span class="type">Int</span>] = &#123;</span><br><span class="line">  it.filter(_ &gt;= <span class="number">3</span>)</span><br><span class="line">&#125;</span><br><span class="line">data.mapPartitions(func).collect</span><br><span class="line">data.mapPartitions(_.filter(_ &gt;= <span class="number">3</span>)).collect</span><br><span class="line"></span><br><span class="line"><span class="comment">// 输出结果</span></span><br><span class="line">data: org.apache.spark.rdd.<span class="type">RDD</span>[<span class="type">Int</span>] = <span class="type">ParallelCollectionRDD</span>[<span class="number">0</span>] at parallelize at &lt;console&gt;:<span class="number">25</span></span><br><span class="line">func: (it: <span class="type">Iterator</span>[<span class="type">Int</span>])<span class="type">Iterator</span>[<span class="type">Int</span>]</span><br><span class="line">res0: <span class="type">Array</span>[<span class="type">Int</span>] = <span class="type">Array</span>(<span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>, <span class="number">10</span>)</span><br><span class="line">res1: <span class="type">Array</span>[<span class="type">Int</span>] = <span class="type">Array</span>(<span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>, <span class="number">10</span>)</span><br></pre></td></tr></table></figure><p></p></li></ul><h4 id="glom-算子"><a href="#glom-算子" class="headerlink" title="glom 算子"></a>glom 算子</h4><ul><li><p><strong>说明：</strong>返回通过将每个分区内的所有元素合并到数组中而创建的 RDD。</p><p>glom 函数将每个分区形成一个数组，内部实现是返回的 GlommedRDD。 图中的每个方框代表一个 RDD 分区。该图表示含有 V1、 V2、 V3 的分区通过函数 glom 形成一数组 Array[(V1),(V2),(V3)]。</p><p><img src="https://npm.elemecdn.com/eurkon-cdn/hexo/images/user/loading.gif" data-lazy-src="/images/post/spark_rdd/glom.png" alt="glom 算子"></p></li><li><p><strong>用法：</strong></p><p></p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">glom</span></span>(): <span class="type">RDD</span>[<span class="type">Array</span>[<span class="type">T</span>]]</span><br><span class="line"><span class="type">Return</span> an <span class="type">RDD</span> created by coalescing all elements within each partition into an array.</span><br></pre></td></tr></table></figure><p></p></li><li><p><strong>示例：</strong></p><p></p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> data = sc.parallelize(<span class="number">1</span> to <span class="number">10</span>, <span class="number">3</span>)</span><br><span class="line">data.glom().collect</span><br><span class="line"></span><br><span class="line"><span class="comment">// 输出结果</span></span><br><span class="line">data: org.apache.spark.rdd.<span class="type">RDD</span>[<span class="type">Int</span>] = <span class="type">ParallelCollectionRDD</span>[<span class="number">0</span>] at parallelize at &lt;console&gt;:<span class="number">25</span></span><br><span class="line">res0: <span class="type">Array</span>[<span class="type">Array</span>[<span class="type">Int</span>]] = <span class="type">Array</span>(<span class="type">Array</span>(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>), <span class="type">Array</span>(<span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>), <span class="type">Array</span>(<span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>, <span class="number">10</span>))</span><br></pre></td></tr></table></figure><p></p></li></ul><h3 id="输入分区与输出分区多对一型"><a href="#输入分区与输出分区多对一型" class="headerlink" title="输入分区与输出分区多对一型"></a>输入分区与输出分区多对一型</h3><h4 id="union-算子"><a href="#union-算子" class="headerlink" title="union 算子"></a>union 算子</h4><ul><li><p><strong>说明：</strong>返回此 RDD 和另一个 RDD 的联合。</p><p>使用 union 函数时需要保证两个 RDD 元素的数据类型相同，返回的 RDD 数据类型和被合并的 RDD 元素数据类型相同，并不进行去重操作，保存所有元素。如果想去重可以使用 <code>distinct()</code>。同时 Spark 还提供更为简洁的使用 union 的 API，通过 ++ 符号相当于 union 函数操作。</p><p>图中左侧大方框代表两个 RDD，大方框内的小方框代表 RDD 的分区。右侧大方框代表合并后的 RDD，大方框内的小方框代表分区。含有 V1、V2、U1、U2、U3、U4 的 RDD 和含有 V1、V8、U5、U6、U7、U8 的 RDD 合并所有元素形成一个 RDD。V1、V1、V2、V8 形成一个分区，U1、U2、U3、U4、U5、U6、U7、U8 形成一个分区。</p><p><img src="https://npm.elemecdn.com/eurkon-cdn/hexo/images/user/loading.gif" data-lazy-src="/images/post/spark_rdd/union.png" alt="union 算子"></p></li><li><p><strong>用法：</strong></p><p></p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">union</span></span>(other: <span class="type">RDD</span>[<span class="type">T</span>]): <span class="type">RDD</span>[<span class="type">T</span>]</span><br><span class="line"><span class="type">Return</span> the union of <span class="keyword">this</span> <span class="type">RDD</span> and another one.</span><br></pre></td></tr></table></figure><p></p></li><li><p><strong>示例：</strong></p><p></p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> data1 = sc.parallelize(<span class="number">1</span> to <span class="number">10</span>, <span class="number">3</span>)</span><br><span class="line"><span class="keyword">val</span> data2 = sc.parallelize(<span class="number">5</span> to <span class="number">15</span>, <span class="number">3</span>)</span><br><span class="line">data1.union(data2).collect</span><br><span class="line"></span><br><span class="line"><span class="comment">// 输出结果</span></span><br><span class="line">data1: org.apache.spark.rdd.<span class="type">RDD</span>[<span class="type">Int</span>] = <span class="type">ParallelCollectionRDD</span>[<span class="number">0</span>] at parallelize at &lt;console&gt;:<span class="number">25</span></span><br><span class="line">data2: org.apache.spark.rdd.<span class="type">RDD</span>[<span class="type">Int</span>] = <span class="type">ParallelCollectionRDD</span>[<span class="number">1</span>] at parallelize at &lt;console&gt;:<span class="number">25</span></span><br><span class="line">res0: <span class="type">Array</span>[<span class="type">Int</span>] = <span class="type">Array</span>(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>, <span class="number">10</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>, <span class="number">10</span>, <span class="number">11</span>, <span class="number">12</span>, <span class="number">13</span>, <span class="number">14</span>, <span class="number">15</span>)</span><br></pre></td></tr></table></figure><p></p></li></ul><h4 id="cartesian-算子"><a href="#cartesian-算子" class="headerlink" title="cartesian 算子"></a>cartesian 算子</h4><ul><li><p><strong>说明：</strong>返回此 RDD 和另一个 RDD 的进行笛卡尔积运算，即返回 a 和 b 的所有元素对 (a,b) 的 RDD。</p><p>对两个 RDD 内的所有元素进行笛卡尔积操作，该操作不会执行 shuffle 操作。操作后，内部实现返回 CartesianRDD。图中左侧大方框代表两个 RDD，大方框内的小方框代表 RDD 的分区。右侧大方框代表合并后的 RDD，大方框内的小方框代表分区。图中的大方框代表 RDD，大方框中的小方框代表 RDD 分区。例如：V1 和另一个 RDD 中的 W1、W2、Q5 进行笛卡尔积运算形成 (V1,W1)、(V1,W2)、(V1,Q5)。</p><p><img src="https://npm.elemecdn.com/eurkon-cdn/hexo/images/user/loading.gif" data-lazy-src="/images/post/spark_rdd/cartesian.png" alt="cartesian 算子"></p></li><li><p><strong>用法：</strong></p><p></p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">cartesian</span></span>[<span class="type">U</span>](other: <span class="type">RDD</span>[<span class="type">U</span>])(<span class="keyword">implicit</span> arg0: <span class="type">ClassTag</span>[<span class="type">U</span>]): <span class="type">RDD</span>[(<span class="type">T</span>, <span class="type">U</span>)]</span><br><span class="line"><span class="type">Return</span> the <span class="type">Cartesian</span> product of <span class="keyword">this</span> <span class="type">RDD</span> and another one, that is, the <span class="type">RDD</span> of all pairs of elements (a, b) where a is in <span class="keyword">this</span> and b is in other.</span><br></pre></td></tr></table></figure><p></p></li><li><p><strong>示例：</strong></p><p></p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> data1 = sc.parallelize(<span class="number">1</span> to <span class="number">5</span>, <span class="number">3</span>)</span><br><span class="line"><span class="keyword">val</span> data2 = sc.parallelize(<span class="number">5</span> to <span class="number">10</span>, <span class="number">3</span>)</span><br><span class="line">data1.cartesian(data2).collect</span><br><span class="line"></span><br><span class="line"><span class="comment">// 输出结果</span></span><br><span class="line">data1: org.apache.spark.rdd.<span class="type">RDD</span>[<span class="type">Int</span>] = <span class="type">ParallelCollectionRDD</span>[<span class="number">0</span>] at parallelize at &lt;console&gt;:<span class="number">25</span></span><br><span class="line">data2: org.apache.spark.rdd.<span class="type">RDD</span>[<span class="type">Int</span>] = <span class="type">ParallelCollectionRDD</span>[<span class="number">1</span>] at parallelize at &lt;console&gt;:<span class="number">25</span></span><br><span class="line">res0: <span class="type">Array</span>[(<span class="type">Int</span>, <span class="type">Int</span>)] = <span class="type">Array</span>((<span class="number">1</span>,<span class="number">5</span>), (<span class="number">1</span>,<span class="number">6</span>), (<span class="number">1</span>,<span class="number">7</span>), (<span class="number">1</span>,<span class="number">8</span>), (<span class="number">1</span>,<span class="number">9</span>), (<span class="number">1</span>,<span class="number">10</span>), (<span class="number">2</span>,<span class="number">5</span>), (<span class="number">2</span>,<span class="number">6</span>), (<span class="number">3</span>,<span class="number">5</span>), (<span class="number">3</span>,<span class="number">6</span>), (<span class="number">2</span>,<span class="number">7</span>), (<span class="number">2</span>,<span class="number">8</span>), (<span class="number">3</span>,<span class="number">7</span>), (<span class="number">3</span>,<span class="number">8</span>), (<span class="number">2</span>,<span class="number">9</span>), (<span class="number">2</span>,<span class="number">10</span>), (<span class="number">3</span>,<span class="number">9</span>), (<span class="number">3</span>,<span class="number">10</span>), (<span class="number">4</span>,<span class="number">5</span>), (<span class="number">4</span>,<span class="number">6</span>), (<span class="number">5</span>,<span class="number">5</span>), (<span class="number">5</span>,<span class="number">6</span>), (<span class="number">4</span>,<span class="number">7</span>), (<span class="number">4</span>,<span class="number">8</span>), (<span class="number">5</span>,<span class="number">7</span>), (<span class="number">5</span>,<span class="number">8</span>), (<span class="number">4</span>,<span class="number">9</span>), (<span class="number">4</span>,<span class="number">10</span>), (<span class="number">5</span>,<span class="number">9</span>), (<span class="number">5</span>,<span class="number">10</span>))</span><br></pre></td></tr></table></figure><p></p></li></ul><h3 id="输入分区与输出分区多对多型"><a href="#输入分区与输出分区多对多型" class="headerlink" title="输入分区与输出分区多对多型"></a>输入分区与输出分区多对多型</h3><h4 id="groupBy-算子"><a href="#groupBy-算子" class="headerlink" title="groupBy 算子"></a>groupBy 算子</h4><ul><li><p><strong>说明：</strong>返回分组元素的 RDD。每个组由一个键和映射到该键的一系列元素组成。不能保证每个组中元素的顺序，并且每次生成的 RDD 时甚至可能会有所不同。</p><p>将元素通过函数生成相应的 Key，数据就转化为 Key-Value 格式，之后将 Key 相同的元素分为一组。 函数实现如下：将用户函数预处理，对数据 map 进行函数操作，最后再进行 groupByKey 分组操作。<code>this.map(t =&gt; (cleanF(t), t)).groupByKey(p)</code>，其中， p 确定了分区个数和分区函数，也就决定了并行化的程度。</p><p>图中方框代表一个 RDD 分区，相同 key 的元素合并到一个组。例如 V1 和 V2 合并为 V，Value 为 V1,V2。形成 V,Seq(V1,V2)。</p><p><img src="https://npm.elemecdn.com/eurkon-cdn/hexo/images/user/loading.gif" data-lazy-src="/images/post/spark_rdd/group_by.png" alt="groupBy 算子"></p></li><li><p><strong>用法：</strong></p><p></p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">groupBy</span></span>[<span class="type">K</span>](f: (<span class="type">T</span>) ⇒ <span class="type">K</span>)(<span class="keyword">implicit</span> kt: <span class="type">ClassTag</span>[<span class="type">K</span>]): <span class="type">RDD</span>[(<span class="type">K</span>, <span class="type">Iterable</span>[<span class="type">T</span>])]</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">groupBy</span></span>[<span class="type">K</span>](f: (<span class="type">T</span>) ⇒ <span class="type">K</span>, numPartitions: <span class="type">Int</span>)(<span class="keyword">implicit</span> kt: <span class="type">ClassTag</span>[<span class="type">K</span>]): <span class="type">RDD</span>[(<span class="type">K</span>, <span class="type">Iterable</span>[<span class="type">T</span>])]</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">groupBy</span></span>[<span class="type">K</span>](f: (<span class="type">T</span>) ⇒ <span class="type">K</span>, p: <span class="type">Partitioner</span>)(<span class="keyword">implicit</span> kt: <span class="type">ClassTag</span>[<span class="type">K</span>], ord: <span class="type">Ordering</span>[<span class="type">K</span>] = <span class="literal">null</span>): <span class="type">RDD</span>[(<span class="type">K</span>, <span class="type">Iterable</span>[<span class="type">T</span>])]</span><br><span class="line"><span class="type">Return</span> an <span class="type">RDD</span> of grouped elements. <span class="type">Each</span> group consists of a key and a sequence of elements mapping to that key. <span class="type">The</span> ordering of elements within each group is not guaranteed, and may even differ each time the resulting <span class="type">RDD</span> is evaluated.</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">groupByKey</span></span>(): <span class="type">RDD</span>[(<span class="type">K</span>, <span class="type">Iterable</span>[<span class="type">V</span>])]</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">groupByKey</span></span>(numPartitions: <span class="type">Int</span>): <span class="type">RDD</span>[(<span class="type">K</span>, <span class="type">Iterable</span>[<span class="type">V</span>])]</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">groupByKey</span></span>(partitioner: <span class="type">Partitioner</span>): <span class="type">RDD</span>[(<span class="type">K</span>, <span class="type">Iterable</span>[<span class="type">V</span>])]</span><br><span class="line"><span class="type">Group</span> the values <span class="keyword">for</span> each key in the <span class="type">RDD</span> into a single sequence. <span class="type">Hash</span>-partitions the resulting <span class="type">RDD</span> <span class="keyword">with</span> the existing partitioner/parallelism level. <span class="type">The</span> ordering of elements within each group is not guaranteed, and may even differ each time the resulting <span class="type">RDD</span> is evaluated.</span><br></pre></td></tr></table></figure><p></p></li><li><p><strong>示例：</strong></p><p></p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> data1 = sc.parallelize(<span class="number">1</span> to <span class="number">10</span>, <span class="number">3</span>)</span><br><span class="line">data1.groupBy(_ % <span class="number">2</span>).collect  <span class="comment">// 分成两组</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> data2 = sc.parallelize(<span class="type">Array</span>(<span class="string">&quot;a&quot;</span>, <span class="string">&quot;b&quot;</span>, <span class="string">&quot;c&quot;</span>, <span class="string">&quot;aa&quot;</span>, <span class="string">&quot;bb&quot;</span>, <span class="string">&quot;cc&quot;</span>, <span class="string">&quot;aaa&quot;</span>, <span class="string">&quot;bbb&quot;</span>, <span class="string">&quot;ccc&quot;</span>), <span class="number">1</span>)</span><br><span class="line"><span class="keyword">val</span> data3 = data2.keyBy(_.length)  <span class="comment">// 给 value 加上 key，key 为对应 string 的长度</span></span><br><span class="line">data3.groupByKey.collect</span><br><span class="line"></span><br><span class="line"><span class="comment">// 输出结果</span></span><br><span class="line">data1: org.apache.spark.rdd.<span class="type">RDD</span>[<span class="type">Int</span>] = <span class="type">ParallelCollectionRDD</span>[<span class="number">0</span>] at parallelize at &lt;console&gt;:<span class="number">25</span></span><br><span class="line">res0: <span class="type">Array</span>[(<span class="type">Int</span>, <span class="type">Iterable</span>[<span class="type">Int</span>])] = <span class="type">Array</span>((<span class="number">0</span>,<span class="type">CompactBuffer</span>(<span class="number">4</span>, <span class="number">6</span>, <span class="number">2</span>, <span class="number">8</span>, <span class="number">10</span>)), (<span class="number">1</span>,<span class="type">CompactBuffer</span>(<span class="number">1</span>, <span class="number">3</span>, <span class="number">7</span>, <span class="number">9</span>, <span class="number">5</span>)))</span><br><span class="line"></span><br><span class="line">data2: org.apache.spark.rdd.<span class="type">RDD</span>[<span class="type">String</span>] = <span class="type">ParallelCollectionRDD</span>[<span class="number">1</span>] at parallelize at &lt;console&gt;:<span class="number">25</span></span><br><span class="line">data3: org.apache.spark.rdd.<span class="type">RDD</span>[(<span class="type">Int</span>, <span class="type">String</span>)] = <span class="type">MapPartitionsRDD</span>[<span class="number">2</span>] at keyBy at &lt;console&gt;:<span class="number">25</span></span><br><span class="line">res1: <span class="type">Array</span>[(<span class="type">Int</span>, <span class="type">Iterable</span>[<span class="type">String</span>])] = <span class="type">Array</span>((<span class="number">1</span>,<span class="type">CompactBuffer</span>(a, b, c)), (<span class="number">3</span>,<span class="type">CompactBuffer</span>(aaa, bbb, ccc)), (<span class="number">2</span>,<span class="type">CompactBuffer</span>(aa, bb, cc)))</span><br></pre></td></tr></table></figure><p></p></li></ul><h3 id="输出分区为输入分区子集型"><a href="#输出分区为输入分区子集型" class="headerlink" title="输出分区为输入分区子集型"></a>输出分区为输入分区子集型</h3><h4 id="filter-算子"><a href="#filter-算子" class="headerlink" title="filter 算子"></a>filter 算子</h4><ul><li><p><strong>说明：</strong>返回仅包含满足条件的元素的新 RDD。</p><p>filter 函数功能是对元素进行过滤，对每个元素应用 f 函 数，返回值为 true 的元素在 RDD 中保留，返回值为 false 的元素将被过滤掉。内部实现相当于生成 <code>FilteredRDD(this，sc.clean(f))</code>。图中每个方框代表一个 RDD 分区， T 可以是任意的类型。通过用户自定义的过滤函数 f，对每个数据项操作，将满足条件、返回结果为 true 的数据项保留。例如，过滤掉 V2 和 V3 保留了 V1，为区分命名为 V&#39;1。</p><p>下面代码为函数的本质实现：<code>def filter(f:T=&gt;Boolean):RDD[T]=newFilteredRDD(this,sc.clean(f))</code></p><p><img src="https://npm.elemecdn.com/eurkon-cdn/hexo/images/user/loading.gif" data-lazy-src="/images/post/spark_rdd/filter.png" alt="filter 算子"></p></li><li><p><strong>用法：</strong></p><p></p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">filter</span></span>(f: (<span class="type">T</span>) ⇒ <span class="type">Boolean</span>): <span class="type">RDD</span>[<span class="type">T</span>]</span><br><span class="line"><span class="type">Return</span> a <span class="keyword">new</span> <span class="type">RDD</span> containing only the elements that satisfy a predicate.</span><br></pre></td></tr></table></figure><p></p></li><li><p><strong>示例：</strong></p><p></p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> data = sc.parallelize(<span class="number">1</span> to <span class="number">10</span>, <span class="number">3</span>)</span><br><span class="line">data.filter(_ % <span class="number">2</span> == <span class="number">0</span>).collect</span><br><span class="line"></span><br><span class="line"><span class="comment">// 输出结果</span></span><br><span class="line">data: org.apache.spark.rdd.<span class="type">RDD</span>[<span class="type">Int</span>] = <span class="type">ParallelCollectionRDD</span>[<span class="number">0</span>] at parallelize at &lt;console&gt;:<span class="number">25</span></span><br><span class="line">res0: <span class="type">Array</span>[<span class="type">Int</span>] = <span class="type">Array</span>(<span class="number">2</span>, <span class="number">4</span>, <span class="number">6</span>, <span class="number">8</span>, <span class="number">10</span>)</span><br></pre></td></tr></table></figure><p></p></li></ul><h4 id="distinct-算子"><a href="#distinct-算子" class="headerlink" title="distinct 算子"></a>distinct 算子</h4><ul><li><p><strong>说明：</strong>返回一个包含该 RDD 中不同元素的新 RDD。</p><p>distinct 将 RDD 中的元素进行去重操作。图中的每个方框代表一个 RDD 分区，通过 distinct 函数，将数据去重。例如，重复数据 V1、V1 去重后只保留一份 V1。</p><p><img src="https://npm.elemecdn.com/eurkon-cdn/hexo/images/user/loading.gif" data-lazy-src="/images/post/spark_rdd/distinct.png" alt="distinct 算子"></p></li><li><p><strong>用法：</strong></p><p></p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">distinct</span></span>(): <span class="type">RDD</span>[<span class="type">T</span>]</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">distinct</span></span>(numPartitions: <span class="type">Int</span>)(<span class="keyword">implicit</span> ord: <span class="type">Ordering</span>[<span class="type">T</span>] = <span class="literal">null</span>): <span class="type">RDD</span>[<span class="type">T</span>]</span><br><span class="line"><span class="type">Return</span> a <span class="keyword">new</span> <span class="type">RDD</span> containing the distinct elements in <span class="keyword">this</span> <span class="type">RDD</span>.</span><br></pre></td></tr></table></figure><p></p></li><li><p><strong>示例：</strong></p><p></p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> data = sc.parallelize(<span class="type">Array</span>(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">1</span>), <span class="number">3</span>)</span><br><span class="line">data.distinct.collect</span><br><span class="line"></span><br><span class="line"><span class="comment">// 输出结果</span></span><br><span class="line">data: org.apache.spark.rdd.<span class="type">RDD</span>[<span class="type">Int</span>] = <span class="type">ParallelCollectionRDD</span>[<span class="number">0</span>] at parallelize at &lt;console&gt;:<span class="number">25</span></span><br><span class="line">res0: <span class="type">Array</span>[<span class="type">Int</span>] = <span class="type">Array</span>(<span class="number">3</span>, <span class="number">1</span>, <span class="number">2</span>)</span><br></pre></td></tr></table></figure><p></p></li></ul><h4 id="subtract-算子"><a href="#subtract-算子" class="headerlink" title="subtract 算子"></a>subtract 算子</h4><ul><li><p><strong>说明：</strong>返回一个新 RDD，其中的元素在第一个 RDD 有，第二个 RDD 没有。</p><p>subtract 相当于进行集合的差操作，RDD1 去除 RDD1 和 RDD2 交集中的所有元素。图中左侧的大方框代表两个 RDD，大方框内的小方框代表 RDD 的分区。右侧大方框代表合并后的 RDD，大方框内的小方框代表分区。V1 在两个 RDD 中均有，根据差集运算规则，新 RDD 不保留，V2 在第一个 RDD 有，第二个 RDD 没有，则在新 RDD 元素中包含 V2。</p><p><img src="https://npm.elemecdn.com/eurkon-cdn/hexo/images/user/loading.gif" data-lazy-src="/images/post/spark_rdd/subtract.png" alt="subtract 算子"></p></li><li><p><strong>用法：</strong></p><p></p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">subtract</span></span>(other: <span class="type">RDD</span>[<span class="type">T</span>]): <span class="type">RDD</span>[<span class="type">T</span>]</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">subtract</span></span>(other: <span class="type">RDD</span>[<span class="type">T</span>], numPartitions: <span class="type">Int</span>): <span class="type">RDD</span>[<span class="type">T</span>]</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">subtract</span></span>(other: <span class="type">RDD</span>[<span class="type">T</span>], p: <span class="type">Partitioner</span>)(<span class="keyword">implicit</span> ord: <span class="type">Ordering</span>[<span class="type">T</span>] = <span class="literal">null</span>): <span class="type">RDD</span>[<span class="type">T</span>]</span><br><span class="line"><span class="type">Return</span> an <span class="type">RDD</span> <span class="keyword">with</span> the elements from <span class="keyword">this</span> that are not in other.</span><br></pre></td></tr></table></figure><p></p></li><li><p><strong>示例：</strong></p><p></p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> data1 = sc.parallelize(<span class="number">1</span> to <span class="number">10</span>, <span class="number">3</span>)</span><br><span class="line"><span class="keyword">val</span> data2 = sc.parallelize(<span class="number">1</span> to <span class="number">5</span>, <span class="number">3</span>)</span><br><span class="line">data1.subtract(data2).collect</span><br><span class="line"></span><br><span class="line"><span class="comment">// 输出结果</span></span><br><span class="line">data1: org.apache.spark.rdd.<span class="type">RDD</span>[<span class="type">Int</span>] = <span class="type">ParallelCollectionRDD</span>[<span class="number">0</span>] at parallelize at &lt;console&gt;:<span class="number">25</span></span><br><span class="line">data2: org.apache.spark.rdd.<span class="type">RDD</span>[<span class="type">Int</span>] = <span class="type">ParallelCollectionRDD</span>[<span class="number">1</span>] at parallelize at &lt;console&gt;:<span class="number">25</span></span><br><span class="line">res0: <span class="type">Array</span>[<span class="type">Int</span>] = <span class="type">Array</span>(<span class="number">6</span>, <span class="number">9</span>, <span class="number">7</span>, <span class="number">10</span>, <span class="number">8</span>)</span><br></pre></td></tr></table></figure><p></p></li></ul><h4 id="sample-算子"><a href="#sample-算子" class="headerlink" title="sample 算子"></a>sample 算子</h4><ul><li><p><strong>说明：</strong>返回此 RDD 的采样子集。</p><p>sample 将 RDD 这个集合内的元素进行采样，获取所有元素的子集。用户可以设定是否有放回的抽样、百分比、随机种子，进而决定采样方式。内部实现是生成 SampledRDD(withReplacement, fraction, seed)。图中的每个方框是一个 RDD 分区。通过 sample 函数， 采样 50% 的数据。V1、V2、U1、U2、U3、U4 采样出数据 V1 和 U1、U2 形成新的 RDD。</p><p><img src="https://npm.elemecdn.com/eurkon-cdn/hexo/images/user/loading.gif" data-lazy-src="/images/post/spark_rdd/sample.png" alt="sample 算子"></p></li><li><p><strong>用法：</strong></p><p></p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">sample</span></span>(withReplacement: <span class="type">Boolean</span>, fraction: <span class="type">Double</span>, seed: <span class="type">Long</span> = <span class="type">Utils</span>.random.nextLong): <span class="type">RDD</span>[<span class="type">T</span>]</span><br><span class="line"><span class="type">Return</span> a sampled subset of <span class="keyword">this</span> <span class="type">RDD</span>.</span><br><span class="line"></span><br><span class="line">withReplacement：can elements be sampled multiple times (replaced when sampled out)</span><br><span class="line">可以多次采样元素（采样时替换），<span class="literal">true</span> 表示有放回抽样，<span class="literal">false</span> 表示无放回抽样，</span><br><span class="line"></span><br><span class="line">fraction：expected size of the sample as a fraction of <span class="keyword">this</span> <span class="type">RDD</span><span class="symbol">&#x27;s</span> size without replacement: probability that each element is chosen; fraction must be [<span class="number">0</span>, <span class="number">1</span>] <span class="keyword">with</span> replacement: expected number of times each element is chosen; fraction must be greater than or equal to <span class="number">0</span></span><br><span class="line">样本的预期大小，占该 <span class="type">RDD</span> 大小的一部分，无需替换：选择每个元素的概率；分数必须为 [<span class="number">0</span>，<span class="number">1</span>]，并带有替换：选择每个元素的预期次数；小数必须大于或等于 <span class="number">0</span></span><br><span class="line"></span><br><span class="line">seed：seed <span class="keyword">for</span> the random number generator</span><br><span class="line">随机数生成器的种子</span><br></pre></td></tr></table></figure><p></p></li><li><p><strong>示例：</strong></p><p></p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> data = sc.parallelize(<span class="number">1</span> to <span class="number">10</span>, <span class="number">3</span>)</span><br><span class="line">data.sample(<span class="literal">true</span>, <span class="number">0.5</span>, <span class="number">9</span>).collect</span><br><span class="line">data.sample(<span class="literal">false</span>, <span class="number">0.5</span>, <span class="number">9</span>).collect</span><br><span class="line"></span><br><span class="line"><span class="comment">// 输出结果</span></span><br><span class="line">data: org.apache.spark.rdd.<span class="type">RDD</span>[<span class="type">Int</span>] = <span class="type">ParallelCollectionRDD</span>[<span class="number">0</span>] at parallelize at &lt;console&gt;:<span class="number">25</span></span><br><span class="line">res0: <span class="type">Array</span>[<span class="type">Int</span>] = <span class="type">Array</span>(<span class="number">1</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">8</span>, <span class="number">9</span>, <span class="number">9</span>)</span><br><span class="line">res1: <span class="type">Array</span>[<span class="type">Int</span>] = <span class="type">Array</span>(<span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">6</span>, <span class="number">8</span>, <span class="number">9</span>)</span><br></pre></td></tr></table></figure><p></p></li></ul><h3 id="Cache-型"><a href="#Cache-型" class="headerlink" title="Cache 型"></a>Cache 型</h3><h4 id="cache-算子"><a href="#cache-算子" class="headerlink" title="cache 算子"></a>cache 算子</h4><ul><li><p><strong>说明：</strong>使用默认存储级别（MEMORY_ONLY）缓存该 RDD。</p><p>cache 将 RDD 元素从磁盘缓存到内存。相当于 persist(MEMORY_ONLY) 函数的功能。图中每个方框代表一个 RDD 分区，左侧相当于数据分区都存储在磁盘，通过 cache 算子将数据缓存在内存。</p><p><img src="https://npm.elemecdn.com/eurkon-cdn/hexo/images/user/loading.gif" data-lazy-src="/images/post/spark_rdd/cache.png" alt="cache 算子"></p></li><li><p><strong>用法：</strong></p><p></p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">cache</span></span>(): <span class="type">RDD</span>.<span class="keyword">this</span>.<span class="keyword">type</span></span><br><span class="line"><span class="type">Persist</span> <span class="keyword">this</span> <span class="type">RDD</span> <span class="keyword">with</span> the <span class="keyword">default</span> storage level (<span class="type">MEMORY_ONLY</span>).</span><br></pre></td></tr></table></figure><p></p></li><li><p><strong>示例：</strong></p><p></p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> data = sc.parallelize(<span class="number">1</span> to <span class="number">10</span>, <span class="number">3</span>)</span><br><span class="line">data.cache()</span><br><span class="line"></span><br><span class="line"><span class="comment">// 输出结果</span></span><br><span class="line">data: org.apache.spark.rdd.<span class="type">RDD</span>[<span class="type">Int</span>] = <span class="type">ParallelCollectionRDD</span>[<span class="number">0</span>] at parallelize at &lt;console&gt;:<span class="number">25</span></span><br><span class="line">res0: data.<span class="keyword">type</span> = <span class="type">ParallelCollectionRDD</span>[<span class="number">0</span>] at parallelize at &lt;console&gt;:<span class="number">25</span></span><br></pre></td></tr></table></figure><p></p></li></ul><h4 id="persist-算子"><a href="#persist-算子" class="headerlink" title="persist 算子"></a>persist 算子</h4><ul><li><p><strong>说明：</strong>设置此 RDD 的存储级别，以在第一次计算它之后将其值持久化到各个操作中。如果 RDD 尚未设置存储级别，则只能用于分配新的存储级别。本地检查点是一个例外。</p><p>persist 函数对 RDD 进行缓存操作。数据缓存在哪里依据 <code>StorageLevel</code> 这个枚举类型进行确定。有以下几种类型的组合，<code>DISK</code> 代表磁盘，<code>MEMORY</code> 代表内存，<code>SER</code> 代表数据是否进行序列化存储。</p><p>下面为函数定义，<code>StorageLevel</code> 是枚举类型，代表存储模式，用户可以按需进行选择。<code>persist(newLevel:StorageLevel)</code>，下面列出 persist 函数可以进行缓存的模式。例如，<code>MEMORY_AND_DISK_SER</code> 代表数据可以存储在内存和磁盘，并且以序列化的方式存储，其他同理。</p><p></p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">StorageLevel</span> <span class="title">private</span>(<span class="params"></span></span></span><br><span class="line"><span class="class"><span class="params">    private var _useDisk: <span class="type">Boolean</span>, //是否使用磁盘</span></span></span><br><span class="line"><span class="class"><span class="params">    private var _useMemory: <span class="type">Boolean</span>, //是否使用内存</span></span></span><br><span class="line"><span class="class"><span class="params">    private var _useOffHeap: <span class="type">Boolean</span>, //是否使用堆外内存</span></span></span><br><span class="line"><span class="class"><span class="params">    private var _deserialized: <span class="type">Boolean</span>, //是否反序列化</span></span></span><br><span class="line"><span class="class"><span class="params">    private var _replication: <span class="type">Int</span> = 1</span>) <span class="comment">//备份因子，默认为 1</span></span></span><br><span class="line"><span class="class">  <span class="keyword">extends</span> <span class="title">Externalizable</span> </span>&#123;&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">StorageLevel</span> </span>&#123;</span><br><span class="line">  <span class="keyword">val</span> <span class="type">NONE</span> = <span class="keyword">new</span> <span class="type">StorageLevel</span>(<span class="literal">false</span>, <span class="literal">false</span>, <span class="literal">false</span>, <span class="literal">false</span>)</span><br><span class="line">  <span class="keyword">val</span> <span class="type">DISK_ONLY</span> = <span class="keyword">new</span> <span class="type">StorageLevel</span>(<span class="literal">true</span>, <span class="literal">false</span>, <span class="literal">false</span>, <span class="literal">false</span>)</span><br><span class="line">  <span class="keyword">val</span> <span class="type">DISK_ONLY_2</span> = <span class="keyword">new</span> <span class="type">StorageLevel</span>(<span class="literal">true</span>, <span class="literal">false</span>, <span class="literal">false</span>, <span class="literal">false</span>, <span class="number">2</span>)</span><br><span class="line">  <span class="keyword">val</span> <span class="type">MEMORY_ONLY</span> = <span class="keyword">new</span> <span class="type">StorageLevel</span>(<span class="literal">false</span>, <span class="literal">true</span>, <span class="literal">false</span>, <span class="literal">true</span>)</span><br><span class="line">  <span class="keyword">val</span> <span class="type">MEMORY_ONLY_2</span> = <span class="keyword">new</span> <span class="type">StorageLevel</span>(<span class="literal">false</span>, <span class="literal">true</span>, <span class="literal">false</span>, <span class="literal">true</span>, <span class="number">2</span>)</span><br><span class="line">  <span class="keyword">val</span> <span class="type">MEMORY_ONLY_SER</span> = <span class="keyword">new</span> <span class="type">StorageLevel</span>(<span class="literal">false</span>, <span class="literal">true</span>, <span class="literal">false</span>, <span class="literal">false</span>)</span><br><span class="line">  <span class="keyword">val</span> <span class="type">MEMORY_ONLY_SER_2</span> = <span class="keyword">new</span> <span class="type">StorageLevel</span>(<span class="literal">false</span>, <span class="literal">true</span>, <span class="literal">false</span>, <span class="literal">false</span>, <span class="number">2</span>)</span><br><span class="line">  <span class="keyword">val</span> <span class="type">MEMORY_AND_DISK</span> = <span class="keyword">new</span> <span class="type">StorageLevel</span>(<span class="literal">true</span>, <span class="literal">true</span>, <span class="literal">false</span>, <span class="literal">true</span>)</span><br><span class="line">  <span class="keyword">val</span> <span class="type">MEMORY_AND_DISK_2</span> = <span class="keyword">new</span> <span class="type">StorageLevel</span>(<span class="literal">true</span>, <span class="literal">true</span>, <span class="literal">false</span>, <span class="literal">true</span>, <span class="number">2</span>)</span><br><span class="line">  <span class="keyword">val</span> <span class="type">MEMORY_AND_DISK_SER</span> = <span class="keyword">new</span> <span class="type">StorageLevel</span>(<span class="literal">true</span>, <span class="literal">true</span>, <span class="literal">false</span>, <span class="literal">false</span>)</span><br><span class="line">  <span class="keyword">val</span> <span class="type">MEMORY_AND_DISK_SER_2</span> = <span class="keyword">new</span> <span class="type">StorageLevel</span>(<span class="literal">true</span>, <span class="literal">true</span>, <span class="literal">false</span>, <span class="literal">false</span>, <span class="number">2</span>)</span><br><span class="line">  <span class="keyword">val</span> <span class="type">OFF_HEAP</span> = <span class="keyword">new</span> <span class="type">StorageLevel</span>(<span class="literal">true</span>, <span class="literal">true</span>, <span class="literal">true</span>, <span class="literal">false</span>, <span class="number">1</span>)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p></p><p>下图中方框代表 RDD 分区。<code>disk</code> 代表存储在磁盘，<code>mem</code> 代表存储在内存。数据最初全部存储在磁盘，通过 <code>persist(MEMORY_AND_DISK)</code> 将数据缓存到内存，但是有的分区无法容纳在内存，将含有 V1、 V2、 V3 的 RDD 存储到磁盘，将含有 U1，U2 的 RDD 仍旧存储在内存。</p><p><img src="https://npm.elemecdn.com/eurkon-cdn/hexo/images/user/loading.gif" data-lazy-src="/images/post/spark_rdd/persist.png" alt="persist 算子"></p></li><li><p><strong>用法：</strong></p><p></p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">persist</span></span>(): <span class="type">RDD</span>.<span class="keyword">this</span>.<span class="keyword">type</span></span><br><span class="line"><span class="type">Persist</span> <span class="keyword">this</span> <span class="type">RDD</span> <span class="keyword">with</span> the <span class="keyword">default</span> storage level (<span class="type">MEMORY_ONLY</span>).</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">persist</span></span>(newLevel: <span class="type">StorageLevel</span>): <span class="type">RDD</span>.<span class="keyword">this</span>.<span class="keyword">type</span></span><br><span class="line"><span class="type">Set</span> <span class="keyword">this</span> <span class="type">RDD</span><span class="symbol">&#x27;s</span> storage level to persist its values across operations after the first time it is computed. <span class="type">This</span> can only be used to assign a <span class="keyword">new</span> storage level <span class="keyword">if</span> the <span class="type">RDD</span> does not have a storage level set yet. <span class="type">Local</span> checkpointing is an exception.</span><br></pre></td></tr></table></figure><p></p></li><li><p><strong>示例：</strong></p><p></p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> data = sc.parallelize(<span class="number">1</span> to <span class="number">10</span>, <span class="number">3</span>)</span><br><span class="line">data.persist(<span class="type">StorageLevel</span>.<span class="type">MEMORY_AND_DISK</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 输出结果</span></span><br><span class="line">data: org.apache.spark.rdd.<span class="type">RDD</span>[<span class="type">Int</span>] = <span class="type">ParallelCollectionRDD</span>[<span class="number">0</span>] at parallelize at &lt;console&gt;:<span class="number">25</span></span><br><span class="line">res0: data.<span class="keyword">type</span> = <span class="type">ParallelCollectionRDD</span>[<span class="number">0</span>] at parallelize at &lt;console&gt;:<span class="number">25</span></span><br></pre></td></tr></table></figure><p></p></li></ul><h2 id="Key-Value-数据类型的-Transformation-算子"><a href="#Key-Value-数据类型的-Transformation-算子" class="headerlink" title="Key-Value 数据类型的 Transformation 算子"></a>Key-Value 数据类型的 Transformation 算子</h2><h3 id="输入分区与输出分区一对一"><a href="#输入分区与输出分区一对一" class="headerlink" title="输入分区与输出分区一对一"></a>输入分区与输出分区一对一</h3><h4 id="mapValues-算子"><a href="#mapValues-算子" class="headerlink" title="mapValues 算子"></a>mapValues 算子</h4><ul><li><p><strong>说明：</strong>在不更改键的情况下，通过映射函数传递键值对 RDD 中的每个值；这也保留了原始 RDD 的分区。</p><p>针对 (Key, Value) 型数据中的 Value 进行 Map 操作，而不对 Key 进行处理。图中的方框代表 RDD 分区。 <code>a=&gt;a+2</code> 代表对 (V1, 1) 这样的 Key-Value 数据对，数据只对 Value 中的 1 进行加 2 操作，返回结果为 3。</p><p><img src="https://npm.elemecdn.com/eurkon-cdn/hexo/images/user/loading.gif" data-lazy-src="/images/post/spark_rdd/map_values.png" alt="mapValues 算子"></p></li><li><p><strong>用法：</strong></p><p></p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">mapValues</span></span>[<span class="type">U</span>](f: (<span class="type">V</span>) ⇒ <span class="type">U</span>): <span class="type">RDD</span>[(<span class="type">K</span>, <span class="type">U</span>)]</span><br><span class="line"><span class="type">Pass</span> each value in the key-value pair <span class="type">RDD</span> through a map function without changing the keys; <span class="keyword">this</span> also retains the original <span class="type">RDD</span><span class="symbol">&#x27;s</span> partitioning.</span><br></pre></td></tr></table></figure><p></p></li><li><p><strong>示例：</strong></p><p></p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> data = sc.parallelize(<span class="type">Array</span>(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>), <span class="number">3</span>)</span><br><span class="line">data.map(x =&gt; (x, x)).mapValues(a =&gt; (a + <span class="number">2</span>)).collect</span><br><span class="line"></span><br><span class="line"><span class="comment">// 输出结果</span></span><br><span class="line">data: org.apache.spark.rdd.<span class="type">RDD</span>[<span class="type">Int</span>] = <span class="type">ParallelCollectionRDD</span>[<span class="number">0</span>] at parallelize at &lt;console&gt;:<span class="number">25</span></span><br><span class="line">res0: <span class="type">Array</span>[(<span class="type">Int</span>, <span class="type">Int</span>)] = <span class="type">Array</span>((<span class="number">1</span>,<span class="number">3</span>), (<span class="number">2</span>,<span class="number">4</span>), (<span class="number">3</span>,<span class="number">5</span>), (<span class="number">4</span>,<span class="number">6</span>), (<span class="number">5</span>,<span class="number">7</span>), (<span class="number">6</span>,<span class="number">8</span>))</span><br></pre></td></tr></table></figure><p></p></li></ul><h3 id="对单个-RDD-或两个-RDD-聚合"><a href="#对单个-RDD-或两个-RDD-聚合" class="headerlink" title="对单个 RDD 或两个 RDD 聚合"></a>对单个 RDD 或两个 RDD 聚合</h3><p><strong>单个 RDD 聚合</strong></p><h4 id="combineByKey-算子"><a href="#combineByKey-算子" class="headerlink" title="combineByKey 算子"></a>combineByKey 算子</h4><ul><li><p><strong>说明：</strong>CombineByKeyWithClassTag 的简化版本，它使用现有的分区程序/并行度级别对生成的 RDD 进行哈希分区。此方法是为了向后兼容。它不向混洗提供组合器类标签信息。</p><p>例如，相当于将元素为 (Int， Int) 的 RDD 转变为了 (Int, Seq[Int]) 类型元素的 RDD。图中的方框代表 RDD 分区。如图，通过 combineByKey，将 (V1,2)， (V1,1) 数据合并为 (V1, Seq(2, 1))。</p><p><img src="https://npm.elemecdn.com/eurkon-cdn/hexo/images/user/loading.gif" data-lazy-src="/images/post/spark_rdd/combine_by_key.png" alt="combineByKey 算子"></p></li><li><p><strong>用法：</strong></p><p></p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">combineByKey</span></span>[<span class="type">C</span>](createCombiner: (<span class="type">V</span>) ⇒ <span class="type">C</span>, mergeValue: (<span class="type">C</span>, <span class="type">V</span>) ⇒ <span class="type">C</span>, mergeCombiners: (<span class="type">C</span>, <span class="type">C</span>) ⇒ <span class="type">C</span>): <span class="type">RDD</span>[(<span class="type">K</span>, <span class="type">C</span>)]</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">combineByKey</span></span>[<span class="type">C</span>](createCombiner: (<span class="type">V</span>) ⇒ <span class="type">C</span>, mergeValue: (<span class="type">C</span>, <span class="type">V</span>) ⇒ <span class="type">C</span>, mergeCombiners: (<span class="type">C</span>, <span class="type">C</span>) ⇒ <span class="type">C</span>, numPartitions: <span class="type">Int</span>): <span class="type">RDD</span>[(<span class="type">K</span>, <span class="type">C</span>)]</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">combineByKey</span></span>[<span class="type">C</span>](createCombiner: (<span class="type">V</span>) ⇒ <span class="type">C</span>, mergeValue: (<span class="type">C</span>, <span class="type">V</span>) ⇒ <span class="type">C</span>, mergeCombiners: (<span class="type">C</span>, <span class="type">C</span>) ⇒ <span class="type">C</span>, partitioner: <span class="type">Partitioner</span>, mapSideCombine: <span class="type">Boolean</span> = <span class="literal">true</span>, serializer: <span class="type">Serializer</span> = <span class="literal">null</span>): <span class="type">RDD</span>[(<span class="type">K</span>, <span class="type">C</span>)]</span><br><span class="line"></span><br><span class="line">createCombiner，createCombiner, which turns a <span class="type">V</span> into a <span class="type">C</span> (e.g., creates a one-element <span class="type">Array</span>)</span><br><span class="line">将 <span class="type">V</span> 变成 <span class="type">C</span>（例如，创建一个元素列表），<span class="type">C</span> 不存在的情况下，比如通过 <span class="type">V</span> 创建 seq <span class="type">C</span>。</span><br><span class="line"></span><br><span class="line">mergeValue, to merge a <span class="type">V</span> into a <span class="type">C</span> (e.g., adds it to the end of a <span class="type">Array</span>)</span><br><span class="line">将 <span class="type">V</span> 合并为 <span class="type">C</span>（例如，将其添加到列表的末尾），当 <span class="type">C</span> 已经存在的情况下，需要 merge，比如把 item <span class="type">V</span> 加到 seq <span class="type">C</span> 中，或者叠加。</span><br><span class="line"></span><br><span class="line">mergeCombiners, to combine two <span class="type">C</span><span class="symbol">&#x27;s</span> into a single one.</span><br><span class="line">将两个 <span class="type">C</span> 合并为一个。</span><br><span class="line"></span><br><span class="line">mapSideCombine <span class="type">Boolean</span> = <span class="literal">true</span></span><br><span class="line">为了减小传输量，很多 combine 可以在 map 端先做，比如叠加，可以先在一个 partition 中把所有相同的 key 的 value 叠加，再 shuffle。</span><br><span class="line"></span><br><span class="line">serializerClass： <span class="type">String</span> = <span class="literal">null</span></span><br><span class="line">传输需要序列化，用户可以自定义序列化类。</span><br></pre></td></tr></table></figure><p></p></li><li><p><strong>示例：</strong></p><p></p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> data = sc.parallelize(<span class="type">Array</span>((<span class="string">&quot;a&quot;</span>, <span class="number">88</span>), (<span class="string">&quot;a&quot;</span>, <span class="number">95</span>), (<span class="string">&quot;a&quot;</span>, <span class="number">91</span>), (<span class="string">&quot;b&quot;</span>, <span class="number">93</span>), (<span class="string">&quot;b&quot;</span>, <span class="number">95</span>), (<span class="string">&quot;b&quot;</span>, <span class="number">98</span>)))</span><br><span class="line">data.combineByKey(</span><br><span class="line">    (v) =&gt; (v, <span class="number">1</span>),</span><br><span class="line">    (c: (<span class="type">Int</span>, <span class="type">Int</span>), v) =&gt; (c._1 + v, c._2 + <span class="number">1</span>),</span><br><span class="line">    (c1: (<span class="type">Int</span>, <span class="type">Int</span>), c2: (<span class="type">Int</span>, <span class="type">Int</span>)) =&gt; (c1._1 + c2._1, c1._2 + c2._2)</span><br><span class="line">).collect</span><br><span class="line"></span><br><span class="line"><span class="comment">// 输出结果</span></span><br><span class="line">data: org.apache.spark.rdd.<span class="type">RDD</span>[(<span class="type">String</span>, <span class="type">Int</span>)] = <span class="type">ParallelCollectionRDD</span>[<span class="number">0</span>] at parallelize at &lt;console&gt;:<span class="number">25</span></span><br><span class="line">res0: <span class="type">Array</span>[(<span class="type">String</span>, (<span class="type">Int</span>, <span class="type">Int</span>))] = <span class="type">Array</span>((a,(<span class="number">274</span>,<span class="number">3</span>)), (b,(<span class="number">286</span>,<span class="number">3</span>)))</span><br></pre></td></tr></table></figure><p></p></li></ul><h4 id="reduceByKey-算子"><a href="#reduceByKey-算子" class="headerlink" title="reduceByKey 算子"></a>reduceByKey 算子</h4><ul><li><p><strong>说明：</strong>使用关联和可交换的归约函数合并每个键的值。在将结果发送给 reducer 之前，这还将在每个 Mapper 上本地执行合并，这与 MapReduce 中的 combiner 类似。输出将使用现有分区/并行级别进行哈希分区。</p><p>reduceByKey 是比 combineByKey 更简单的一种情况，只是两个值合并成一个值，(Int, Int V) to (Int, Int C)，比如叠加。所以 createCombiner reduceByKey 很简单，就是直接返回 v，而 mergeValue 和 mergeCombiners 逻辑是相同的，没有区别。图中的方框代表 RDD 分区。通过用户自定义函数 (A,B) =&gt; (A + B) 函数，将相同 key 的数据 (V1,2) 和 (V1,1) 的 value 相加运算，结果为 (V1,3)。</p><p><img src="https://npm.elemecdn.com/eurkon-cdn/hexo/images/user/loading.gif" data-lazy-src="/images/post/spark_rdd/reduce_by_key.png" alt="reduceByKey 算子"></p></li><li><p><strong>用法：</strong></p><p></p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">reduceByKey</span></span>(func: (<span class="type">V</span>, <span class="type">V</span>) ⇒ <span class="type">V</span>): <span class="type">RDD</span>[(<span class="type">K</span>, <span class="type">V</span>)]</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">reduceByKey</span></span>(func: (<span class="type">V</span>, <span class="type">V</span>) ⇒ <span class="type">V</span>, numPartitions: <span class="type">Int</span>): <span class="type">RDD</span>[(<span class="type">K</span>, <span class="type">V</span>)]</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">reduceByKey</span></span>(partitioner: <span class="type">Partitioner</span>, func: (<span class="type">V</span>, <span class="type">V</span>) ⇒ <span class="type">V</span>): <span class="type">RDD</span>[(<span class="type">K</span>, <span class="type">V</span>)]</span><br><span class="line"><span class="type">Merge</span> the values <span class="keyword">for</span> each key using an associative and commutative reduce function.</span><br></pre></td></tr></table></figure><p></p></li><li><p><strong>示例：</strong></p><p></p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> data = sc.parallelize(<span class="type">Array</span>((<span class="string">&quot;a&quot;</span>, <span class="number">1</span>), (<span class="string">&quot;a&quot;</span>, <span class="number">2</span>), (<span class="string">&quot;b&quot;</span>, <span class="number">3</span>), (<span class="string">&quot;b&quot;</span>, <span class="number">4</span>)))</span><br><span class="line">data.reduceByKey((x, y) =&gt; x + y).collect</span><br><span class="line">data.reduceByKey(_ + _).collect</span><br><span class="line"></span><br><span class="line"><span class="comment">// 输出结果</span></span><br><span class="line">data: org.apache.spark.rdd.<span class="type">RDD</span>[(<span class="type">Int</span>, <span class="type">Int</span>)] = <span class="type">ParallelCollectionRDD</span>[<span class="number">0</span>] at parallelize at &lt;console&gt;:<span class="number">25</span></span><br><span class="line">res0: <span class="type">Array</span>[(<span class="type">String</span>, <span class="type">Int</span>)] = <span class="type">Array</span>((b,<span class="number">7</span>), (a,<span class="number">3</span>))</span><br><span class="line">res1: <span class="type">Array</span>[(<span class="type">String</span>, <span class="type">Int</span>)] = <span class="type">Array</span>((b,<span class="number">7</span>), (a,<span class="number">3</span>))</span><br></pre></td></tr></table></figure><p></p></li></ul><h4 id="partitionBy-算子"><a href="#partitionBy-算子" class="headerlink" title="partitionBy 算子"></a>partitionBy 算子</h4><ul><li><p><strong>说明：</strong>返回使用指定分区程序分区的 RDD 的副本。</p><p>如果原有 RDD 的分区器和现有分区器（partitioner）一致，则不重分区，如果不一致，则相当于根据分区器生成一个新的 ShuffledRDD。图中的方框代表 RDD 分区。通过新的分区策略将原来在不同分区的 V1、 V2 数据都合并到了一个分区。</p><p><img src="https://npm.elemecdn.com/eurkon-cdn/hexo/images/user/loading.gif" data-lazy-src="/images/post/spark_rdd/partition_by.png" alt="partitionBy 算子"></p></li><li><p><strong>用法：</strong></p><p></p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">partitionBy</span></span>(partitioner: <span class="type">Partitioner</span>): <span class="type">RDD</span>[(<span class="type">K</span>, <span class="type">V</span>)]</span><br><span class="line"><span class="type">Return</span> a copy of the <span class="type">RDD</span> partitioned using the specified partitioner.</span><br></pre></td></tr></table></figure><p></p></li><li><p><strong>示例：</strong></p><p></p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> data = sc.parallelize(<span class="type">Array</span>(<span class="string">&quot;a&quot;</span>, <span class="number">1</span>), (<span class="string">&quot;a&quot;</span>, <span class="number">2</span>), (<span class="string">&quot;b&quot;</span>, <span class="number">1</span>), (<span class="string">&quot;b&quot;</span>, <span class="number">3</span>), (<span class="string">&quot;c&quot;</span>, <span class="number">1</span>), (<span class="string">&quot;e&quot;</span>, <span class="number">5</span>), <span class="number">2</span>)</span><br><span class="line">data.partitionBy(<span class="keyword">new</span> <span class="type">HashPartitioner</span>(<span class="number">4</span>)).glom.collect</span><br><span class="line"></span><br><span class="line"><span class="comment">// 输出结果</span></span><br><span class="line">data: org.apache.spark.rdd.<span class="type">RDD</span>[(<span class="type">Int</span>, <span class="type">Int</span>)] = <span class="type">ParallelCollectionRDD</span>[<span class="number">0</span>] at parallelize at &lt;console&gt;:<span class="number">25</span></span><br><span class="line">res0: <span class="type">Array</span>[<span class="type">Array</span>[(<span class="type">String</span>, <span class="type">Int</span>)]] = <span class="type">Array</span>(<span class="type">Array</span>((a,<span class="number">2</span>), (c,<span class="number">1</span>)), <span class="type">Array</span>((b,<span class="number">2</span>), (e,<span class="number">5</span>)), <span class="type">Array</span>(), <span class="type">Array</span>((a,<span class="number">1</span>), (b,<span class="number">3</span>)))</span><br></pre></td></tr></table></figure><p></p></li></ul><p><strong>两个 RDD 聚合</strong></p><h4 id="cogroup-算子"><a href="#cogroup-算子" class="headerlink" title="cogroup 算子"></a>cogroup 算子</h4><ul><li><p><strong>说明：</strong>对在两个 RDD 中的 Key-Value 类型的元素，每个 RDD 相同 Key 的元素分别聚合为一个集合，并且返回两个 RDD 中对应 Key 的元素集合的迭代器。</p><p>其中，Key 和 Value，Value 是两个 RDD 下相同 Key 的两个数据集合的迭代器所构成的元组。图中的大方框代表 RDD，大方框内的小方框代表 RDD 中的分区。将 RDD1 中的数据 (U,1)、(U1,2) 和 RDD2 中的数据 (U1，2) 合并为 (U1,((1,2),(2)))。</p><p><img src="https://npm.elemecdn.com/eurkon-cdn/hexo/images/user/loading.gif" data-lazy-src="/images/post/spark_rdd/cogroup.png" alt="cogroup 算子"></p></li><li><p><strong>用法：</strong></p><p></p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">cogroup</span></span>[<span class="type">W1</span>, <span class="type">W2</span>](other1: <span class="type">RDD</span>[(<span class="type">K</span>, <span class="type">W1</span>)], other2: <span class="type">RDD</span>[(<span class="type">K</span>, <span class="type">W2</span>)], numPartitions: <span class="type">Int</span>): <span class="type">RDD</span>[(<span class="type">K</span>, (<span class="type">Iterable</span>[<span class="type">V</span>], <span class="type">Iterable</span>[<span class="type">W1</span>], <span class="type">Iterable</span>[<span class="type">W2</span>]))]</span><br><span class="line"><span class="type">For</span> each key k in <span class="keyword">this</span> or other1 or other2, <span class="keyword">return</span> a resulting <span class="type">RDD</span> that contains a tuple <span class="keyword">with</span> the list of values <span class="keyword">for</span> that key in <span class="keyword">this</span>, other1 and other2.</span><br></pre></td></tr></table></figure><p></p></li><li><p><strong>示例：</strong></p><p></p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> data1 = sc.parallelize(<span class="type">Array</span>((<span class="string">&quot;a&quot;</span>, <span class="number">1</span>), (<span class="string">&quot;a&quot;</span>, <span class="number">2</span>)))</span><br><span class="line"><span class="keyword">val</span> data2 = sc.parallelize(<span class="type">Array</span>((<span class="string">&quot;a&quot;</span>, <span class="number">3</span>), (<span class="string">&quot;a&quot;</span>, <span class="number">4</span>)))</span><br><span class="line">data1.cogroup(data2).collect</span><br><span class="line"></span><br><span class="line"><span class="comment">// 输出结果</span></span><br><span class="line">data1: org.apache.spark.rdd.<span class="type">RDD</span>[(<span class="type">String</span>, <span class="type">Int</span>)] = <span class="type">ParallelCollectionRDD</span>[<span class="number">0</span>] at parallelize at &lt;console&gt;:<span class="number">25</span></span><br><span class="line">data2: org.apache.spark.rdd.<span class="type">RDD</span>[(<span class="type">String</span>, <span class="type">Int</span>)] = <span class="type">ParallelCollectionRDD</span>[<span class="number">1</span>] at parallelize at &lt;console&gt;:<span class="number">25</span></span><br><span class="line">res0: <span class="type">Array</span>[(<span class="type">String</span>, (<span class="type">Iterable</span>[<span class="type">Int</span>], <span class="type">Iterable</span>[<span class="type">Int</span>]))] = <span class="type">Array</span>((a,(<span class="type">CompactBuffer</span>(<span class="number">1</span>, <span class="number">2</span>),<span class="type">CompactBuffer</span>(<span class="number">4</span>, <span class="number">3</span>))))</span><br></pre></td></tr></table></figure><p></p></li></ul><h3 id="连接"><a href="#连接" class="headerlink" title="连接"></a>连接</h3><h4 id="join-算子"><a href="#join-算子" class="headerlink" title="join 算子"></a>join 算子</h4><ul><li><p><strong>说明：</strong>返回一个 RDD，其中包含所有成对的元素。</p><p>join 对两个需要连接的 RDD 进行 cogroup 函数操作，将相同 key 的数据能够放到一个分区，在 cogroup 操作之后形成的新 RDD 对每个 key 下的元素进行笛卡尔积的操作，返回的结果再展平，对应 key 下的所有元组形成一个集合。最后返回 RDD[(K， (V， W))]。</p><p>下面代码为 join 的函数实现，本质是通过 cogroup 算子先进行协同划分，再通过 flatMapValues 将合并的数据打散。</p><p><code>this.cogroup(other, partitioner).flatMapValues&#123;case(vs, ws) =&gt; for(v&lt;-vs; w&lt;-ws) yield(v, w) &#125;</code></p><p>下图是对两个 RDD 的 join 操作示意图。大方框代表 RDD，小方框代表 RDD 中的分区。函数对相同 key 的元素，如 V1 为 key 做连接后结果为 (V1,(1,1)) 和 (V1,(1,2))。</p><p><img src="https://npm.elemecdn.com/eurkon-cdn/hexo/images/user/loading.gif" data-lazy-src="/images/post/spark_rdd/join.png" alt="join 算子"></p></li><li><p><strong>用法：</strong></p><p></p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">join</span></span>[<span class="type">W</span>](other: <span class="type">RDD</span>[(<span class="type">K</span>, <span class="type">W</span>)]): <span class="type">RDD</span>[(<span class="type">K</span>, (<span class="type">V</span>, <span class="type">W</span>))]</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">join</span></span>[<span class="type">W</span>](other: <span class="type">RDD</span>[(<span class="type">K</span>, <span class="type">W</span>)], numPartitions: <span class="type">Int</span>): <span class="type">RDD</span>[(<span class="type">K</span>, (<span class="type">V</span>, <span class="type">W</span>))]</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">join</span></span>[<span class="type">W</span>](other: <span class="type">RDD</span>[(<span class="type">K</span>, <span class="type">W</span>)], partitioner: <span class="type">Partitioner</span>): <span class="type">RDD</span>[(<span class="type">K</span>, (<span class="type">V</span>, <span class="type">W</span>))]</span><br><span class="line"><span class="type">Return</span> an <span class="type">RDD</span> containing all pairs of elements <span class="keyword">with</span> matching keys in <span class="keyword">this</span> and other.</span><br></pre></td></tr></table></figure><p></p></li><li><p><strong>示例：</strong></p><p></p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> data1 = sc.parallelize(<span class="type">Array</span>((<span class="string">&quot;a&quot;</span>, <span class="number">1</span>), (<span class="string">&quot;a&quot;</span>, <span class="number">2</span>)))</span><br><span class="line"><span class="keyword">val</span> data2 = sc.parallelize(<span class="type">Array</span>((<span class="string">&quot;a&quot;</span>, <span class="number">3</span>), (<span class="string">&quot;a&quot;</span>, <span class="number">4</span>)))</span><br><span class="line">data1.join(data2).collect</span><br><span class="line"></span><br><span class="line"><span class="comment">// 输出结果</span></span><br><span class="line">data1: org.apache.spark.rdd.<span class="type">RDD</span>[(<span class="type">String</span>, <span class="type">Int</span>)] = <span class="type">ParallelCollectionRDD</span>[<span class="number">0</span>] at parallelize at &lt;console&gt;:<span class="number">25</span></span><br><span class="line">data2: org.apache.spark.rdd.<span class="type">RDD</span>[(<span class="type">String</span>, <span class="type">Int</span>)] = <span class="type">ParallelCollectionRDD</span>[<span class="number">1</span>] at parallelize at &lt;console&gt;:<span class="number">25</span></span><br><span class="line">res0: <span class="type">Array</span>[(<span class="type">String</span>, (<span class="type">Int</span>, <span class="type">Int</span>))] = <span class="type">Array</span>((a,(<span class="number">1</span>,<span class="number">3</span>)), (a,(<span class="number">1</span>,<span class="number">4</span>)), (a,(<span class="number">2</span>,<span class="number">3</span>)), (a,(<span class="number">2</span>,<span class="number">4</span>)))</span><br></pre></td></tr></table></figure><p></p></li></ul><h4 id="leftOuterJoin-和-rightOuterJoin-算子"><a href="#leftOuterJoin-和-rightOuterJoin-算子" class="headerlink" title="leftOuterJoin 和 rightOuterJoin 算子"></a>leftOuterJoin 和 rightOuterJoin 算子</h4><ul><li><p><strong>说明：</strong>leftOuterJoin（左外连接）和 rightOuterJoin（右外连接）相当于在 join 的基础上先判断一侧的 RDD 元素是否为空，如果为空，则填充为空。如果不为空，则将数据进行连接运算，并返回结果。</p></li><li><p><strong>用法：</strong></p><p></p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">leftOuterJoin</span></span>[<span class="type">W</span>](other: <span class="type">RDD</span>[(<span class="type">K</span>, <span class="type">W</span>)]): <span class="type">RDD</span>[(<span class="type">K</span>, (<span class="type">V</span>, <span class="type">Option</span>[<span class="type">W</span>]))]</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">leftOuterJoin</span></span>[<span class="type">W</span>](other: <span class="type">RDD</span>[(<span class="type">K</span>, <span class="type">W</span>)], numPartitions: <span class="type">Int</span>): <span class="type">RDD</span>[(<span class="type">K</span>, (<span class="type">V</span>, <span class="type">Option</span>[<span class="type">W</span>]))]</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">leftOuterJoin</span></span>[<span class="type">W</span>](other: <span class="type">RDD</span>[(<span class="type">K</span>, <span class="type">W</span>)], partitioner: <span class="type">Partitioner</span>): <span class="type">RDD</span>[(<span class="type">K</span>, (<span class="type">V</span>, <span class="type">Option</span>[<span class="type">W</span>]))]</span><br><span class="line"><span class="type">Perform</span> a left outer join of <span class="keyword">this</span> and other. <span class="type">For</span> each element (k, v) in <span class="keyword">this</span>, the resulting <span class="type">RDD</span> will either contain all pairs (k, (v, <span class="type">Some</span>(w))) <span class="keyword">for</span> w in other, or the pair (k, (v, <span class="type">None</span>)) <span class="keyword">if</span> no elements in other have key k. <span class="type">Hash</span>-partitions the output using the existing partitioner/parallelism level.</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">rightOuterJoin</span></span>[<span class="type">W</span>](other: <span class="type">RDD</span>[(<span class="type">K</span>, <span class="type">W</span>)]): <span class="type">RDD</span>[(<span class="type">K</span>, (<span class="type">Option</span>[<span class="type">V</span>], <span class="type">W</span>))]</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">rightOuterJoin</span></span>[<span class="type">W</span>](other: <span class="type">RDD</span>[(<span class="type">K</span>, <span class="type">W</span>)], numPartitions: <span class="type">Int</span>): <span class="type">RDD</span>[(<span class="type">K</span>, (<span class="type">Option</span>[<span class="type">V</span>], <span class="type">W</span>))]</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">rightOuterJoin</span></span>[<span class="type">W</span>](other: <span class="type">RDD</span>[(<span class="type">K</span>, <span class="type">W</span>)], partitioner: <span class="type">Partitioner</span>): <span class="type">RDD</span>[(<span class="type">K</span>, (<span class="type">Option</span>[<span class="type">V</span>], <span class="type">W</span>))]</span><br><span class="line"><span class="type">Perform</span> a right outer join of <span class="keyword">this</span> and other. <span class="type">For</span> each element (k, w) in other, the resulting <span class="type">RDD</span> will either contain all pairs (k, (<span class="type">Some</span>(v), w)) <span class="keyword">for</span> v in <span class="keyword">this</span>, or the pair (k, (<span class="type">None</span>, w)) <span class="keyword">if</span> no elements in <span class="keyword">this</span> have key k. <span class="type">Hash</span>-partitions the resulting <span class="type">RDD</span> using the existing partitioner/parallelism level.</span><br></pre></td></tr></table></figure><p></p></li><li><p><strong>示例：</strong></p><p></p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> data1 = sc.parallelize(<span class="type">Array</span>((<span class="string">&quot;a&quot;</span>, <span class="number">1</span>), (<span class="string">&quot;a&quot;</span>, <span class="number">2</span>)))</span><br><span class="line"><span class="keyword">val</span> data2 = sc.parallelize(<span class="type">Array</span>((<span class="string">&quot;a&quot;</span>, <span class="number">3</span>), (<span class="string">&quot;b&quot;</span>, <span class="number">4</span>)))</span><br><span class="line">data1.leftOuterJoin(data2).collect</span><br><span class="line">data2.leftOuterJoin(data1).collect</span><br><span class="line">data1.rightOuterJoin(data2).collect</span><br><span class="line">data2.rightOuterJoin(data1).collect</span><br><span class="line"></span><br><span class="line"><span class="comment">// 输出结果</span></span><br><span class="line">data1: org.apache.spark.rdd.<span class="type">RDD</span>[(<span class="type">String</span>, <span class="type">Int</span>)] = <span class="type">ParallelCollectionRDD</span>[<span class="number">0</span>] at parallelize at &lt;console&gt;:<span class="number">25</span></span><br><span class="line">data2: org.apache.spark.rdd.<span class="type">RDD</span>[(<span class="type">String</span>, <span class="type">Int</span>)] = <span class="type">ParallelCollectionRDD</span>[<span class="number">1</span>] at parallelize at &lt;console&gt;:<span class="number">25</span></span><br><span class="line">res0: <span class="type">Array</span>[(<span class="type">String</span>, (<span class="type">Int</span>, <span class="type">Option</span>[<span class="type">Int</span>]))] = <span class="type">Array</span>((a,(<span class="number">2</span>,<span class="type">Some</span>(<span class="number">3</span>))), (a,(<span class="number">1</span>,<span class="type">Some</span>(<span class="number">3</span>))))</span><br><span class="line">res1: <span class="type">Array</span>[(<span class="type">String</span>, (<span class="type">Int</span>, <span class="type">Option</span>[<span class="type">Int</span>]))] = <span class="type">Array</span>((b,(<span class="number">4</span>,<span class="type">None</span>)), (a,(<span class="number">3</span>,<span class="type">Some</span>(<span class="number">1</span>))), (a,(<span class="number">3</span>,<span class="type">Some</span>(<span class="number">2</span>))))</span><br><span class="line">res2: <span class="type">Array</span>[(<span class="type">String</span>, (<span class="type">Option</span>[<span class="type">Int</span>], <span class="type">Int</span>))] = <span class="type">Array</span>((b,(<span class="type">None</span>,<span class="number">4</span>)), (a,(<span class="type">Some</span>(<span class="number">1</span>),<span class="number">3</span>)), (a,(<span class="type">Some</span>(<span class="number">2</span>),<span class="number">3</span>)))</span><br><span class="line">res3: <span class="type">Array</span>[(<span class="type">String</span>, (<span class="type">Option</span>[<span class="type">Int</span>], <span class="type">Int</span>))] = <span class="type">Array</span>((a,(<span class="type">Some</span>(<span class="number">3</span>),<span class="number">2</span>)), (a,(<span class="type">Some</span>(<span class="number">3</span>),<span class="number">1</span>)))</span><br></pre></td></tr></table></figure><p></p></li></ul><h2 id="Action-算子"><a href="#Action-算子" class="headerlink" title="Action 算子"></a>Action 算子</h2><p>本质上在 Action 算子中通过 SparkContext 进行了提交作业的 runJob 操作，触发了 RDD DAG 的执行。</p><h3 id="无输出"><a href="#无输出" class="headerlink" title="无输出"></a>无输出</h3><h4 id="foreach-算子"><a href="#foreach-算子" class="headerlink" title="foreach 算子"></a>foreach 算子</h4><ul><li><p><strong>说明：</strong>foreach 对 RDD 中的每个元素都应用 f 函数操作，不返回 RDD 和 Array， 而是返回 Uint。下图表示 foreach 算子通过用户自定义函数对每个数据项进行操作。本例中自定义函数为 println()，控制台打印所有数据项。</p><p><img src="https://npm.elemecdn.com/eurkon-cdn/hexo/images/user/loading.gif" data-lazy-src="/images/post/spark_rdd/foreach.png" alt="foreach 算子"></p></li><li><p><strong>用法：</strong></p><p></p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">foreach</span></span>[<span class="type">U</span>](f: (<span class="type">T</span>) ⇒ <span class="type">U</span>)(<span class="keyword">implicit</span> executor: <span class="type">ExecutionContext</span>): <span class="type">Unit</span></span><br></pre></td></tr></table></figure><p></p></li><li><p><strong>示例：</strong></p><p></p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> data = sc.parallelize(<span class="number">1</span> to <span class="number">5</span>)</span><br><span class="line"><span class="keyword">var</span> sum = sc.accumulator(<span class="number">0</span>)</span><br><span class="line">data.foreach(sum += _)</span><br><span class="line">sum.value</span><br><span class="line">data.collect().foreach(println)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 输出结果</span></span><br><span class="line">data: org.apache.spark.rdd.<span class="type">RDD</span>[<span class="type">Int</span>] = <span class="type">ParallelCollectionRDD</span>[<span class="number">0</span>] at parallelize at &lt;console&gt;:<span class="number">25</span></span><br><span class="line">sum: org.apache.spark.<span class="type">Accumulator</span>[<span class="type">Int</span>] = <span class="number">0</span></span><br><span class="line">res0: <span class="type">Int</span> = <span class="number">15</span></span><br><span class="line"><span class="number">1</span></span><br><span class="line"><span class="number">2</span></span><br><span class="line"><span class="number">3</span></span><br><span class="line"><span class="number">4</span></span><br><span class="line"><span class="number">5</span></span><br></pre></td></tr></table></figure><p></p></li></ul><h3 id="HDFS"><a href="#HDFS" class="headerlink" title="HDFS"></a>HDFS</h3><h4 id="saveAsTextFile-算子"><a href="#saveAsTextFile-算子" class="headerlink" title="saveAsTextFile 算子"></a>saveAsTextFile 算子</h4><ul><li><p><strong>说明：</strong>使用元素的字符串表示形式将此 RDD 保存为文本文件。将数据输出，存储到 HDFS 的指定目录。</p><p>下面为 saveAsTextFile 函数的内部实现，其内部通过调用 saveAsHadoopFile 进行实现：</p><p><code>this.map(x =&gt; (NullWritable.get(), new Text(x.toString))).saveAsHadoopFile[TextOutputFormat[NullWritable, Text]](path)</code></p><p>将 RDD 中的每个元素映射转变为 (null, x.toString)，然后再将其写入 HDFS。下图中左侧方框代表 RDD 分区，右侧方框代表 HDFS 的 Block。通过函数将 RDD 的每个分区存储为 HDFS 中的一个 Block。</p><p><img src="https://npm.elemecdn.com/eurkon-cdn/hexo/images/user/loading.gif" data-lazy-src="/images/post/spark_rdd/save_as_text_file.png" alt="saveAsTextFile 算子"></p></li><li><p><strong>用法：</strong></p><p></p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">saveAsTextFile</span></span>(path: <span class="type">String</span>): <span class="type">Unit</span></span><br><span class="line"><span class="type">Save</span> <span class="keyword">this</span> <span class="type">RDD</span> as a text file, using string representations of elements.</span><br></pre></td></tr></table></figure><p></p></li><li><p><strong>示例：</strong></p><p></p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> data = sc.parallelize(<span class="number">1</span> to <span class="number">10</span>, <span class="number">3</span>)</span><br><span class="line">data.partitions.size</span><br><span class="line">data.saveAsTextFile(<span class="string">&quot;/test/rdd&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 输出结果</span></span><br><span class="line">data: org.apache.spark.rdd.<span class="type">RDD</span>[scala.collection.immutable.<span class="type">Range</span>.<span class="type">Inclusive</span>] = <span class="type">ParallelCollectionRDD</span>[<span class="number">0</span>] at parallelize at &lt;console&gt;:<span class="number">25</span></span><br><span class="line">res0: <span class="type">Int</span> = <span class="number">3</span></span><br><span class="line"></span><br><span class="line">[root<span class="meta">@master</span>]# hdfs dfs -ls /test/rdd</span><br><span class="line"><span class="type">Found</span> <span class="number">4</span> items</span><br><span class="line">-rw-r--r--   <span class="number">3</span> root supergroup          <span class="number">0</span> <span class="number">2021</span><span class="number">-05</span><span class="number">-07</span> <span class="number">16</span>:<span class="number">57</span> /test/rdd/_SUCCESS</span><br><span class="line">-rw-r--r--   <span class="number">3</span> root supergroup          <span class="number">0</span> <span class="number">2021</span><span class="number">-05</span><span class="number">-07</span> <span class="number">16</span>:<span class="number">57</span> /test/rdd/part<span class="number">-00000</span></span><br><span class="line">-rw-r--r--   <span class="number">3</span> root supergroup          <span class="number">0</span> <span class="number">2021</span><span class="number">-05</span><span class="number">-07</span> <span class="number">16</span>:<span class="number">57</span> /test/rdd/part<span class="number">-00001</span></span><br><span class="line">-rw-r--r--   <span class="number">3</span> root supergroup          <span class="number">0</span> <span class="number">2021</span><span class="number">-05</span><span class="number">-07</span> <span class="number">16</span>:<span class="number">57</span> /test/rdd/part<span class="number">-00002</span></span><br></pre></td></tr></table></figure><p></p></li></ul><h4 id="saveAsObjectFile-算子"><a href="#saveAsObjectFile-算子" class="headerlink" title="saveAsObjectFile 算子"></a>saveAsObjectFile 算子</h4><ul><li><p><strong>说明：</strong>将此 RDD 保存为序列化对象的 SequenceFile。</p><p>saveAsObjectFile 将分区中的每 10 个元素组成一个 Array，然后将这个 Array 序列化，映射为 (Null, BytesWritable(Y)) 的元素，写入 HDFS 为 SequenceFile 的格式。下面代码为函数内部实现。</p><p><code>map(x=&gt;(NullWritable.get()，new BytesWritable(Utils.serialize(x))))</code></p><p>下图中的左侧方框代表 RDD 分区，右侧方框代表 HDFS 的 Block。通过函数将 RDD 的每个分区存储为 HDFS 上的一个 Block。</p><p><img src="https://npm.elemecdn.com/eurkon-cdn/hexo/images/user/loading.gif" data-lazy-src="/images/post/spark_rdd/save_as_object_file.png" alt="saveAsObjectFile 算子"></p></li><li><p><strong>用法：</strong></p><p></p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">saveAsObjectFile</span></span>(path: <span class="type">String</span>): <span class="type">Unit</span></span><br><span class="line"><span class="type">Save</span> <span class="keyword">this</span> <span class="type">RDD</span> as a <span class="type">SequenceFile</span> of serialized objects.</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">saveAsTextFile</span></span>(path: <span class="type">String</span>, codec: <span class="type">Class</span>[_ &lt;: <span class="type">CompressionCodec</span>]): <span class="type">Unit</span></span><br><span class="line"><span class="type">Save</span> <span class="keyword">this</span> <span class="type">RDD</span> as a compressed text file, using string representations of elements.</span><br></pre></td></tr></table></figure><p></p></li><li><p><strong>示例：</strong></p><p></p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> data = sc.parallelize(<span class="number">1</span> to <span class="number">10</span>, <span class="number">3</span>)</span><br><span class="line">data.partitions.size</span><br><span class="line">data.saveAsObjectFile(<span class="string">&quot;/test/rdd&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 输出结果</span></span><br><span class="line">data: org.apache.spark.rdd.<span class="type">RDD</span>[scala.collection.immutable.<span class="type">Range</span>.<span class="type">Inclusive</span>] = <span class="type">ParallelCollectionRDD</span>[<span class="number">0</span>] at parallelize at &lt;console&gt;:<span class="number">25</span></span><br><span class="line">res0: <span class="type">Int</span> = <span class="number">3</span></span><br><span class="line"></span><br><span class="line">[root<span class="meta">@master</span>]# hdfs dfs -ls /test/rdd</span><br><span class="line"><span class="type">Found</span> <span class="number">4</span> items</span><br><span class="line">-rw-r--r--   <span class="number">3</span> root supergroup          <span class="number">0</span> <span class="number">2021</span><span class="number">-05</span><span class="number">-07</span> <span class="number">16</span>:<span class="number">57</span> /test/rdd/_SUCCESS</span><br><span class="line">-rw-r--r--   <span class="number">3</span> root supergroup          <span class="number">0</span> <span class="number">2021</span><span class="number">-05</span><span class="number">-07</span> <span class="number">16</span>:<span class="number">57</span> /test/rdd/part<span class="number">-00000</span></span><br><span class="line">-rw-r--r--   <span class="number">3</span> root supergroup          <span class="number">0</span> <span class="number">2021</span><span class="number">-05</span><span class="number">-07</span> <span class="number">16</span>:<span class="number">57</span> /test/rdd/part<span class="number">-00001</span></span><br><span class="line">-rw-r--r--   <span class="number">3</span> root supergroup          <span class="number">0</span> <span class="number">2021</span><span class="number">-05</span><span class="number">-07</span> <span class="number">16</span>:<span class="number">57</span> /test/rdd/part<span class="number">-00002</span></span><br><span class="line"></span><br><span class="line">[root<span class="meta">@master</span>]# hadoop fs -cat /test/rdd/part<span class="number">-00000</span></span><br><span class="line"><span class="type">SEQ</span> !org.apache.hadoop.io.<span class="type">NullWritable</span><span class="string">&quot;org.apache.hadoop.io.BytesWritableT</span></span><br></pre></td></tr></table></figure><p></p></li></ul><h3 id="Scala-集合和数据类型"><a href="#Scala-集合和数据类型" class="headerlink" title="Scala 集合和数据类型"></a>Scala 集合和数据类型</h3><h4 id="collect-算子"><a href="#collect-算子" class="headerlink" title="collect 算子"></a>collect 算子</h4><ul><li><p><strong>说明：</strong>返回一个包含此 RDD 中所有元素的数组。</p><p>collect 相当于 toArray，toArray 已经过时不推荐使用，collect 将分布式的 RDD 返回为一个单机的 scala Array 数组。在这个数组上运用 scala 的函数式操作。下图中左侧方框代表 RDD 分区，右侧方框代表单机内存中的数组。通过函数操作，将结果返回到 Driver 程序所在的节点，以数组形式存储。</p><p><img src="https://npm.elemecdn.com/eurkon-cdn/hexo/images/user/loading.gif" data-lazy-src="/images/post/spark_rdd/collect.png" alt="collect 算子"></p></li><li><p><strong>用法：</strong></p><p></p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">collect</span></span>(): <span class="type">List</span>[<span class="type">T</span>]</span><br><span class="line"><span class="type">Return</span> an array that contains all of the elements in <span class="keyword">this</span> <span class="type">RDD</span>.</span><br></pre></td></tr></table></figure><p></p></li><li><p><strong>示例：</strong></p><p></p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> data = sc.parallelize(<span class="number">1</span> to <span class="number">10</span>, <span class="number">3</span>)</span><br><span class="line">data.collect</span><br><span class="line"></span><br><span class="line"><span class="comment">// 输出结果</span></span><br><span class="line">data: org.apache.spark.rdd.<span class="type">RDD</span>[<span class="type">Int</span>] = <span class="type">ParallelCollectionRDD</span>[<span class="number">0</span>] at parallelize at &lt;console&gt;:<span class="number">25</span></span><br><span class="line">res0: <span class="type">Array</span>[<span class="type">Int</span>] = <span class="type">Array</span>(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>, <span class="number">10</span>)</span><br></pre></td></tr></table></figure><p></p></li></ul><h4 id="collectAsMap-算子"><a href="#collectAsMap-算子" class="headerlink" title="collectAsMap 算子"></a>collectAsMap 算子</h4><ul><li><p><strong>说明：</strong>collectAsMap 对 (K，V) 型的 RDD 数据返回一个单机 HashMap。对于重复 K 的 RDD 元素，后面的元素覆盖前面的元素。</p><p>下图中的左侧方框代表 RDD 分区，右侧方框代表单机数组。数据通过 collectAsMap 函数返回给 Driver 程序计算结果，结果以 HashMap 形式存储。</p><p><img src="https://npm.elemecdn.com/eurkon-cdn/hexo/images/user/loading.gif" data-lazy-src="/images/post/spark_rdd/collect_as_map.png" alt="collectAsMap 算子"></p></li><li><p><strong>用法：</strong></p><p></p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">collectAsMap</span></span>(): <span class="type">Map</span>[<span class="type">K</span>, <span class="type">V</span>]</span><br><span class="line"><span class="type">Return</span> the key-value pairs in <span class="keyword">this</span> <span class="type">RDD</span> to the master as a <span class="type">Map</span>.</span><br></pre></td></tr></table></figure><p></p></li><li><p><strong>示例：</strong></p><p></p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> data = sc.parallelize(<span class="type">Array</span>((<span class="string">&quot;a&quot;</span>, <span class="number">1</span>), (<span class="string">&quot;b,2&quot;</span>), (<span class="string">&quot;a&quot;</span>, <span class="number">3</span>)))</span><br><span class="line">data.collectAsMap</span><br><span class="line"></span><br><span class="line"><span class="comment">// 输出结果</span></span><br><span class="line">data: org.apache.spark.rdd.<span class="type">RDD</span>[<span class="type">Int</span>] = <span class="type">ParallelCollectionRDD</span>[<span class="number">0</span>] at parallelize at &lt;console&gt;:<span class="number">25</span></span><br><span class="line">res0: scala.collection.<span class="type">Map</span>[<span class="type">String</span>,<span class="type">Int</span>] = <span class="type">Map</span>(a -&gt; <span class="number">3</span>, b -&gt; <span class="number">2</span>)</span><br></pre></td></tr></table></figure><p></p></li></ul><h4 id="reduceByKeyLocally-算子"><a href="#reduceByKeyLocally-算子" class="headerlink" title="reduceByKeyLocally 算子"></a>reduceByKeyLocally 算子</h4><ul><li><p><strong>说明：</strong>使用关联和可交换的 reduce 函数合并每个键的值，但是将结果作为 Map 返回。</p><p>实现的是先 reduce 再 collectAsMap 的功能，先对 RDD 的整体进行 reduce 操作，然后再收集所有结果返回为一个 HashMap。</p></li><li><p><strong>用法：</strong></p><p></p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">reduceByKeyLocally</span></span>(func: <span class="type">Function2</span>[<span class="type">V</span>, <span class="type">V</span>, <span class="type">V</span>]): <span class="type">Map</span>[<span class="type">K</span>, <span class="type">V</span>]</span><br><span class="line"><span class="type">Merge</span> the values <span class="keyword">for</span> each key using an associative and commutative reduce function, but <span class="keyword">return</span> the result immediately to the master as a <span class="type">Map</span>.</span><br></pre></td></tr></table></figure><p></p></li><li><p><strong>示例：</strong></p><p></p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">var</span> data = sc.parallelize(<span class="type">Array</span>((<span class="string">&quot;a&quot;</span>, <span class="number">0</span>), (<span class="string">&quot;a&quot;</span>, <span class="number">2</span>), (<span class="string">&quot;b&quot;</span>, <span class="number">1</span>), (<span class="string">&quot;b&quot;</span>, <span class="number">2</span>), (<span class="string">&quot;c&quot;</span>, <span class="number">1</span>)))</span><br><span class="line">data.reduceByKeyLocally((x, y) =&gt; x + y)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 输出结果</span></span><br><span class="line">data: org.apache.spark.rdd.<span class="type">RDD</span>[<span class="type">Int</span>] = <span class="type">ParallelCollectionRDD</span>[<span class="number">0</span>] at parallelize at &lt;console&gt;:<span class="number">25</span></span><br><span class="line">res0: scala.collection.<span class="type">Map</span>[<span class="type">String</span>,<span class="type">Int</span>] = <span class="type">Map</span>(a -&gt; <span class="number">2</span>, b -&gt; <span class="number">3</span>, c -&gt; <span class="number">1</span>)</span><br></pre></td></tr></table></figure><p></p></li></ul><h4 id="lookup-算子"><a href="#lookup-算子" class="headerlink" title="lookup 算子"></a>lookup 算子</h4><ul><li><p><strong>说明：</strong>返回 RDD 中 key 的值列表。 lookup 函数对 (Key, Value) 型的 RDD 操作，返回指定 Key 对应的元素形成的 Seq。这个函数处理优化的部分在于，如果这个 RDD 包含分区器，则只会对应处理 K 所在的分区，然后返回由 (K,V) 形成的 Seq。如果 RDD 不包含分区器，则需要对全 RDD 元素进行暴力扫描处理，搜索指定 K 对应的元素。</p><p>下图中的左侧方框代表 RDD 分区，右侧方框代表 Seq，最后结果返回到 Driver 所在节点的应用中。</p><p><img src="https://npm.elemecdn.com/eurkon-cdn/hexo/images/user/loading.gif" data-lazy-src="/images/post/spark_rdd/lookup.png" alt="lookup 算子"></p></li><li><p><strong>用法：</strong></p><p></p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">lookup</span></span>(key: <span class="type">K</span>): <span class="type">List</span>[<span class="type">V</span>]</span><br><span class="line"><span class="type">Return</span> the list of values in the <span class="type">RDD</span> <span class="keyword">for</span> key.</span><br></pre></td></tr></table></figure><p></p></li><li><p><strong>示例：</strong></p><p></p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">var</span> data = sc.parallelize(<span class="type">Array</span>((<span class="string">&quot;a&quot;</span>, <span class="number">0</span>), (<span class="string">&quot;a&quot;</span>, <span class="number">2</span>), (<span class="string">&quot;b&quot;</span>, <span class="number">1</span>)))</span><br><span class="line">data.lookup(<span class="string">&quot;a&quot;</span>)</span><br><span class="line">data.lookup(<span class="string">&quot;b&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 输出结果</span></span><br><span class="line">data: org.apache.spark.rdd.<span class="type">RDD</span>[(<span class="type">String</span>, <span class="type">Int</span>)] = <span class="type">ParallelCollectionRDD</span>[<span class="number">0</span>] at parallelize at &lt;console&gt;:<span class="number">25</span></span><br><span class="line">res0: <span class="type">Seq</span>[<span class="type">Int</span>] = <span class="type">WrappedArray</span>(<span class="number">0</span>, <span class="number">2</span>)</span><br><span class="line">res1: <span class="type">Seq</span>[<span class="type">Int</span>] = <span class="type">WrappedArray</span>(<span class="number">1</span>)</span><br></pre></td></tr></table></figure><p></p></li></ul><h4 id="count-算子"><a href="#count-算子" class="headerlink" title="count 算子"></a>count 算子</h4><ul><li><p><strong>说明：</strong> 返回整个 RDD 的元素个数。</p><p>下图中，返回数据的个数为 5。一个方块代表一个 RDD 分区。</p><p><img src="https://npm.elemecdn.com/eurkon-cdn/hexo/images/user/loading.gif" data-lazy-src="/images/post/spark_rdd/count.png" alt="count 算子"></p></li><li><p><strong>用法：</strong></p><p></p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">count</span></span>(): <span class="type">Long</span></span><br><span class="line"><span class="type">Return</span> the number of elements in the <span class="type">RDD</span>.</span><br></pre></td></tr></table></figure><p></p></li><li><p><strong>示例：</strong></p><p></p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> data = sc.parallelize(<span class="number">1</span> to <span class="number">5</span>)</span><br><span class="line">data.count</span><br><span class="line"></span><br><span class="line"><span class="comment">// 输出结果</span></span><br><span class="line">data: org.apache.spark.rdd.<span class="type">RDD</span>[<span class="type">Int</span>] = <span class="type">ParallelCollectionRDD</span>[<span class="number">0</span>] at parallelize at &lt;console&gt;:<span class="number">25</span></span><br><span class="line">res0: <span class="type">Long</span> = <span class="number">5</span></span><br></pre></td></tr></table></figure><p></p></li></ul><h4 id="top-算子"><a href="#top-算子" class="headerlink" title="top 算子"></a>top 算子</h4><ul><li><p><strong>说明：</strong>返回此 RDD 中的前 k 个（最大）元素，并保持顺序。</p><p>相近函数:</p><ul><li>top 返回最大的 k 个元素。</li><li>take 返回最小的 k 个元素。</li><li>takeOrdered 返回前 k 个（最小）元素，并且在返回的数组中保持元素的顺序。</li><li>first 相当于 top(1) 返回整个 RDD 中的前 k 个元素。</li></ul></li></ul><ul><li><p><strong>用法：</strong></p><p></p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">top</span></span>(num: <span class="type">Int</span>): <span class="type">List</span>[(<span class="type">K</span>, <span class="type">V</span>)]</span><br><span class="line"><span class="type">Returns</span> the top k (largest) elements from <span class="keyword">this</span> <span class="type">RDD</span> using the natural ordering <span class="keyword">for</span> <span class="type">T</span> and maintains the order.</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">top</span></span>(num: <span class="type">Int</span>, comp: <span class="type">Comparator</span>[(<span class="type">K</span>, <span class="type">V</span>)]): <span class="type">List</span>[(<span class="type">K</span>, <span class="type">V</span>)]</span><br><span class="line"><span class="type">Returns</span> the top k (largest) elements from <span class="keyword">this</span> <span class="type">RDD</span> as defined by the specified <span class="type">Comparator</span>[<span class="type">T</span>] and maintains the order.</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">take</span></span>(num: <span class="type">Int</span>): <span class="type">List</span>[(<span class="type">K</span>, <span class="type">V</span>)]</span><br><span class="line"><span class="type">Take</span> the first num elements of the <span class="type">RDD</span>.</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">takeOrdered</span></span>(num: <span class="type">Int</span>): <span class="type">List</span>[(<span class="type">K</span>, <span class="type">V</span>)]</span><br><span class="line"><span class="type">Returns</span> the first k (smallest) elements from <span class="keyword">this</span> <span class="type">RDD</span> using the natural ordering <span class="keyword">for</span> <span class="type">T</span> <span class="keyword">while</span> maintain the order.</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">takeOrdered</span></span>(num: <span class="type">Int</span>, comp: <span class="type">Comparator</span>[(<span class="type">K</span>, <span class="type">V</span>)]): <span class="type">List</span>[(<span class="type">K</span>, <span class="type">V</span>)]</span><br><span class="line"><span class="type">Returns</span> the first k (smallest) elements from <span class="keyword">this</span> <span class="type">RDD</span> as defined by the specified <span class="type">Comparator</span>[<span class="type">T</span>] and maintains the order.</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">first</span></span>(): (<span class="type">K</span>, <span class="type">V</span>)</span><br><span class="line"><span class="type">Return</span> the first element in <span class="keyword">this</span> <span class="type">RDD</span>.</span><br></pre></td></tr></table></figure><p></p></li><li><p><strong>示例：</strong></p><p></p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> data = sc.parallelize(<span class="number">1</span> to <span class="number">10</span>)</span><br><span class="line">data.top(<span class="number">3</span>)</span><br><span class="line">data.take(<span class="number">3</span>)</span><br><span class="line">data.takeOrdered(<span class="number">3</span>)</span><br><span class="line">data.first</span><br><span class="line"></span><br><span class="line"><span class="comment">// 输出结果</span></span><br><span class="line">data: org.apache.spark.rdd.<span class="type">RDD</span>[<span class="type">Int</span>] = <span class="type">ParallelCollectionRDD</span>[<span class="number">0</span>] at parallelize at &lt;console&gt;:<span class="number">25</span></span><br><span class="line">res0: <span class="type">Array</span>[<span class="type">Int</span>] = <span class="type">Array</span>(<span class="number">10</span>, <span class="number">9</span>, <span class="number">8</span>)</span><br><span class="line">res1: <span class="type">Array</span>[<span class="type">Int</span>] = <span class="type">Array</span>(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>)</span><br><span class="line">res2: <span class="type">Array</span>[<span class="type">Int</span>] = <span class="type">Array</span>(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>)</span><br><span class="line">res3: <span class="type">Int</span> = <span class="number">1</span></span><br></pre></td></tr></table></figure><p></p></li></ul><h4 id="reduce-算子"><a href="#reduce-算子" class="headerlink" title="reduce 算子"></a>reduce 算子</h4><ul><li><p><strong>说明：</strong>使用指定的可交换和关联的二进制运算符对 RDD 的元素进行运算。</p><p>reduce 函数相当于对 RDD 中的元素进行 reduceLeft 函数的操作。</p><p>reduceLeft 先对两个元素 (K, V) 进行 reduce 函数操作，然后将结果和迭代器取出的下一个元素 (K, V) 进行 reduce 函数操作，直到迭代器遍历完所有元素，得到最后结果。在 RDD 中，先对每个分区中的所有元素 (K, V) 的集合分别进行 reduceLeft。每个分区形成的结果相当于一个元素 (K, V)，再对这个结果集合进行 reduceLeft 操作。</p><p>下图中的方框代表一个 RDD 分区，通过用户自定函数 f 将数据进行 reduce 运算。</p><p><img src="https://npm.elemecdn.com/eurkon-cdn/hexo/images/user/loading.gif" data-lazy-src="/images/post/spark_rdd/reduce.png" alt="reduce 算子"></p></li><li><p><strong>用法：</strong></p><p></p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">reduce</span></span>(f: <span class="type">Function2</span>[(<span class="type">K</span>, <span class="type">V</span>), (<span class="type">K</span>, <span class="type">V</span>), (<span class="type">K</span>, <span class="type">V</span>)]): (<span class="type">K</span>, <span class="type">V</span>)</span><br><span class="line"><span class="type">Reduces</span> the elements of <span class="keyword">this</span> <span class="type">RDD</span> using the specified commutative and associative binary operator.</span><br></pre></td></tr></table></figure><p></p></li><li><p><strong>示例：</strong></p><p></p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">var</span> data = sc.parallelize(<span class="type">Array</span>((<span class="string">&quot;a&quot;</span>, <span class="number">1</span>), (<span class="string">&quot;b&quot;</span>, <span class="number">2</span>), (<span class="string">&quot;c&quot;</span>, <span class="number">1</span>), (<span class="string">&quot;d&quot;</span>, <span class="number">2</span>)))</span><br><span class="line">data.reduce((x, y) =&gt; (x._1 + <span class="string">&quot;@&quot;</span> + y._1, x._2 + y._2))</span><br><span class="line"></span><br><span class="line"><span class="comment">// 输出结果</span></span><br><span class="line">data: org.apache.spark.rdd.<span class="type">RDD</span>[(<span class="type">String</span>, <span class="type">Int</span>)] = <span class="type">ParallelCollectionRDD</span>[<span class="number">0</span>] at parallelize at &lt;console&gt;:<span class="number">25</span></span><br><span class="line">res0: (<span class="type">String</span>, <span class="type">Int</span>) = (c<span class="meta">@d</span><span class="meta">@a</span><span class="meta">@b</span>,<span class="number">6</span>)</span><br></pre></td></tr></table></figure><p></p></li></ul><h4 id="fold-算子"><a href="#fold-算子" class="headerlink" title="fold 算子"></a>fold 算子</h4><ul><li><p><strong>说明：</strong>使用给定的关联函数和中性的“零值”，汇总每个分区的元素，然后汇总所有分区的结果。</p><p>fold 和 reduce 的原理相同，但是与 reduce 不同，相当于每个 reduce 时，迭代器取的第一个元素是 zeroValue。</p><p>下图中通过下面的用户自定义函数进行 fold 运算，图中的一个方框代表一个 RDD 分区。读者可以参照 reduce 函数理解。</p><p><img src="https://npm.elemecdn.com/eurkon-cdn/hexo/images/user/loading.gif" data-lazy-src="/images/post/spark_rdd/fold.png" alt="fold 算子"></p></li><li><p><strong>用法：</strong></p><p></p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">fold</span></span>(zeroValue: (<span class="type">K</span>, <span class="type">V</span>))(f: <span class="type">Function2</span>[(<span class="type">K</span>, <span class="type">V</span>), (<span class="type">K</span>, <span class="type">V</span>), (<span class="type">K</span>, <span class="type">V</span>)]): (<span class="type">K</span>, <span class="type">V</span>)</span><br><span class="line"><span class="type">Aggregate</span> the elements of each partition, and then the results <span class="keyword">for</span> all the partitions, using a given associative function and a neutral <span class="string">&quot;zero value&quot;</span>.</span><br></pre></td></tr></table></figure><p></p></li><li><p><strong>示例：</strong></p><p></p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">var</span> data = sc.parallelize(<span class="type">Array</span>((<span class="string">&quot;a&quot;</span>, <span class="number">1</span>), (<span class="string">&quot;a&quot;</span>, <span class="number">2</span>), (<span class="string">&quot;b&quot;</span>, <span class="number">1</span>), (<span class="string">&quot;b&quot;</span>, <span class="number">2</span>)), <span class="number">2</span>)</span><br><span class="line">data.fold((<span class="string">&quot;A&quot;</span>, <span class="number">10</span>))((x, y) =&gt; (x._1 + <span class="string">&quot;@&quot;</span> + y._1, x._2 + y._2))</span><br><span class="line"></span><br><span class="line"><span class="comment">// 输出结果</span></span><br><span class="line">data: org.apache.spark.rdd.<span class="type">RDD</span>[(<span class="type">String</span>, <span class="type">Int</span>)] = <span class="type">ParallelCollectionRDD</span>[<span class="number">0</span>] at parallelize at &lt;console&gt;:<span class="number">25</span></span><br><span class="line">res0: (<span class="type">String</span>, <span class="type">Int</span>) = (<span class="type">A</span><span class="meta">@A</span><span class="meta">@a</span><span class="meta">@b</span><span class="meta">@A</span><span class="meta">@c</span><span class="meta">@d</span>,<span class="number">36</span>)</span><br></pre></td></tr></table></figure><p></p></li></ul><h4 id="aggregate-算子"><a href="#aggregate-算子" class="headerlink" title="aggregate 算子"></a>aggregate 算子</h4><ul><li><p><strong>说明：</strong>使用给定的合并功能和中性的“零值”，汇总每个分区的元素，然后汇总所有分区的结果。此函数可以返回与该 RDD 的类型 T 不同的结果类型 U。因此，我们需要一个将 T 合并为 U 的操作，以及一个将两个 U 合并的操作。</p><p>aggregate 先对每个分区的所有元素进行 aggregate 操作，再对分区的结果进行 fold 操作。</p><p>aggregate 与 fold 和 reduce 的不同之处在于，aggregate 相当于采用归并的方式进行数据聚合，这种聚合是并行化的。而在 fold 和 reduce 函数的运算过程中，每个分区中需要进行串行处理，每个分区串行计算完结果，结果再按之前的方式进行聚合，并返回最终聚合结果。</p><p>下图图通过用户自定义函数对 RDD 进行 aggregate 的聚合操作，图中的每个方框代表一个 RDD 分区。</p><p><img src="https://npm.elemecdn.com/eurkon-cdn/hexo/images/user/loading.gif" data-lazy-src="/images/post/spark_rdd/aggregate.png" alt="aggregate 算子"></p></li><li><p><strong>用法：</strong></p><p></p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">aggregate</span></span>[<span class="type">U</span>](zeroValue: <span class="type">U</span>)(seqOp: <span class="type">Function2</span>[<span class="type">U</span>, (<span class="type">K</span>, <span class="type">V</span>), <span class="type">U</span>], combOp: <span class="type">Function2</span>[<span class="type">U</span>, <span class="type">U</span>, <span class="type">U</span>]): <span class="type">U</span></span><br><span class="line"><span class="type">Aggregate</span> the elements of each partition, and then the results <span class="keyword">for</span> all the partitions, using given combine functions and a neutral <span class="string">&quot;zero value&quot;</span>.</span><br></pre></td></tr></table></figure><p></p></li><li><p><strong>示例：</strong></p><p></p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">var</span> data = sc.parallelize(<span class="type">Array</span>((<span class="string">&quot;a&quot;</span>, <span class="number">1</span>), (<span class="string">&quot;a&quot;</span>, <span class="number">2</span>), (<span class="string">&quot;b&quot;</span>, <span class="number">1</span>), (<span class="string">&quot;b&quot;</span>, <span class="number">2</span>)), <span class="number">2</span>)</span><br><span class="line">data.aggregate((<span class="string">&quot;A&quot;</span>, <span class="number">10</span>))((x, y) =&gt; (x._1 + <span class="string">&quot;@&quot;</span> + y._1, x._2 + y._2), (x, y) =&gt; (x._1 + <span class="string">&quot;@&quot;</span> + y._1, x._2 + y._2))</span><br><span class="line"></span><br><span class="line"><span class="comment">// 输出结果</span></span><br><span class="line">data: org.apache.spark.rdd.<span class="type">RDD</span>[(<span class="type">String</span>, <span class="type">Int</span>)] = <span class="type">ParallelCollectionRDD</span>[<span class="number">0</span>] at parallelize at &lt;console&gt;:<span class="number">25</span></span><br><span class="line">res0: (<span class="type">String</span>, <span class="type">Int</span>) = (<span class="type">A</span><span class="meta">@A</span><span class="meta">@a</span><span class="meta">@b</span><span class="meta">@A</span><span class="meta">@c</span><span class="meta">@d</span>,<span class="number">36</span>)</span><br></pre></td></tr></table></figure><p></p></li></ul><h4 id="takeSample-算子"><a href="#takeSample-算子" class="headerlink" title="takeSample 算子"></a>takeSample 算子</h4><ul><li><p><strong>说明：</strong>在数组中返回此 RDD 的固定大小的采样子集</p><p>takeSample 函数和上面的 sample 函数是一个原理，但是不使用相对比例采样，而是按设定的采样个数进行采样，同时返回结果不再是 RDD，而是相当于对采样后的数据进行 collect，返回结果的集合为单机的数组。图中左侧的方框代表分布式的各个节点上的分区，右侧方框代表单机上返回的结果数组。通过 takeSample 对数据采样，设置为采样一份数据，返回结果为 V1。</p><p><img src="https://npm.elemecdn.com/eurkon-cdn/hexo/images/user/loading.gif" data-lazy-src="/images/post/spark_rdd/take_sample.png" alt="takeSample 算子"></p></li><li><p><strong>用法：</strong></p><p></p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">takeSample</span></span>(withReplacement: <span class="type">Boolean</span>, num: <span class="type">Int</span>, seed: <span class="type">Long</span> = <span class="type">Utils</span>.random.nextLong): <span class="type">Array</span>[<span class="type">T</span>]</span><br><span class="line"><span class="type">Return</span> a fixed-size sampled subset of <span class="keyword">this</span> <span class="type">RDD</span> in an array</span><br><span class="line"></span><br><span class="line">withReplacement</span><br><span class="line">whether sampling is done <span class="keyword">with</span> replacement</span><br><span class="line">是否通过更换进行采样</span><br><span class="line"></span><br><span class="line">num</span><br><span class="line">size of the returned sample</span><br><span class="line">返回样本的大小</span><br><span class="line"></span><br><span class="line">seed</span><br><span class="line">seed <span class="keyword">for</span> the random number generator</span><br><span class="line">随机数生成器的种子</span><br></pre></td></tr></table></figure><p></p></li><li><p><strong>示例：</strong></p><p></p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> data = sc.parallelize(<span class="number">1</span> to <span class="number">10</span>, <span class="number">3</span>)</span><br><span class="line">data.takeSample(<span class="literal">true</span>, <span class="number">1</span>, <span class="number">9</span>)</span><br><span class="line">data.takeSample(<span class="literal">false</span>, <span class="number">1</span>, <span class="number">9</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 输出结果</span></span><br><span class="line">data: org.apache.spark.rdd.<span class="type">RDD</span>[<span class="type">Int</span>] = <span class="type">ParallelCollectionRDD</span>[<span class="number">0</span>] at parallelize at &lt;console&gt;:<span class="number">25</span></span><br><span class="line">res0: <span class="type">Array</span>[<span class="type">Int</span>] = <span class="type">Array</span>(<span class="number">1</span>)</span><br><span class="line">res1: <span class="type">Array</span>[<span class="type">Int</span>] = <span class="type">Array</span>(<span class="number">3</span>)</span><br></pre></td></tr></table></figure><p></p></li></ul></article><div class="post-copyright"><div class="post-copyright__title"><span class="post-copyright-info">Spark RDD 常用算子</span></div><div class="post-copyright__url"><span class="post-copyright-info"><a id="post-url" href="https://blog.eurkon.com/post/c55e5115.html">https://blog.eurkon.com/post/c55e5115.html</a><a id="post-url-copy" title="复制文章链接" onclick="btf.copyFn(&quot;https://blog.eurkon.com/post/c55e5115.html&quot;)"><i class="fas fa-paste copy-button"></i></a></span></div><div class="post-copyright__cc"><span class="post-copyright-info">转载前请阅读本站 <a href="/protocol/copyright/" title="本站所有原创文章采用知识共享(Creative Commons)署名—非商业性使用—相同方式共享4.0国际公共许可协议">版权协议</a>，文章著作权归 <a href="https://blog.eurkon.com/">Eurkon</a> 所有，转载请注明出处。</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/">大数据</a><a class="post-meta__tags" href="/tags/Spark/">Spark</a></div><div class="post-share"><div class="social-share" data-image="/images/cover/spark_rdd.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.4/sharejs/dist/css/share.min.css" media="print" onload='this.media="all"'><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.4/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><a class="pagination-related" href="/post/817c7d82.html" title="Linux 常用命令"><img class="cover" src="/images/cover/linux_command.png" onerror='onerror=null,src="https://npm.elemecdn.com/eurkon-cdn/hexo/images/user/404.jpg"' alt="cover of previous post"><div class="info"><div class="info-1"><div class="info-item-1">上一篇</div><div class="info-item-2">Linux 常用命令</div></div><div class="info-2"><div class="info-item-1">系统信息 命令 描述 arch 显示机器的处理器架构 uname -m 显示机器的处理器架构 uname -r 显示正在使用的内核版本 dmidecode -q 显示硬件系统部件 -（SMBIOS/DMI） hdparm -i /dev/hda 罗列一个磁盘的架构特性 hdparm -tT /dev/sda 在磁盘上执行测试性读取操作 cat /proc/cpuinfo 显示 CPU info 的信息 cat /proc/interrupts 显示中断 cat /proc/meminfo 校验内存使用 cat /proc/swaps 显示哪些 swap 被使用 cat /proc/version 显示内核的版本 cat /proc/net/dev 显示网络适配器及统计 cat /proc/mounts 显示已加载的文件系统 lspci -tv 罗列 PCI 设备 lsusb -tv 显示 USB 设备 date 显示系统日期 cal 2007 显示 2007 年的日历表 date...</div></div></div></a><a class="pagination-related" href="/post/61763977.html" title="Hexo 博客实时访问统计图"><img class="cover" src="/images/cover/hexo.png" onerror='onerror=null,src="https://npm.elemecdn.com/eurkon-cdn/hexo/images/user/404.jpg"' alt="cover of next post"><div class="info text-right"><div class="info-1"><div class="info-item-1">下一篇</div><div class="info-item-2">Hexo 博客实时访问统计图</div></div><div class="info-2"><div class="info-item-1">前言本文教程主要针对 Hexo 博客，对博客站点的的访问地图、每月访问量、访问来源的维度绘制统计图，使用的是 ECharts 开源可视化库。具体效果可以点击本站的 统计--博客统计 页面查看。 本文数据来源均为百度统计，请确保博客站点已加入百度统计，以 butterfly 主题为例，可参照 Butterfly 安装文档(四) 主题配置-2 的分析统计段落实现。 本地主机访问（localhost）也会记录到百度统计，推荐在 【百度统计】--【管理】--【统计规则设置】--【过滤规则设置】--【受访域名统计规则】--【勾选排除 localhost（本地主机）】 排除本地主机访问（貌似在勾选后生效，但是以前的访问记录仍会统计）。 此文是针对于文章 Hexo 博客访问统计图 改良版，实时调用百度统计 API 获取访问数据。 本教程将会泄漏属于百度统计的站点 ID 和百度统计 AccessToken，请先前往 百度统计用户手册 了解，介意者请谨慎部署。 2021-05-14 新增访客数的统计，统计指标 metrics...</div></div></div></a></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><a class="pagination-related" href="/post/7e24cf66.html" title="大数据面试题解析"><img class="cover" src="/images/cover/bigdata_interview.png" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2021-03-25</div><div class="info-item-2">大数据面试题解析</div></div><div class="info-2"><div class="info-item-1">Hadoop 面试题解析Zookeeper 面试题解析Flume 面试题解析Kafka 面试题解析Hive 面试题解析HBase 面试题解析Sqoop 面试题解析MySQL 面试题解析Spark 面试题解析Elasticsearch 面试题解析</div></div></div></a><a class="pagination-related" href="/post/cccf27af.html" title="Spark 面试题解析"><img class="cover" src="/images/cover/bigdata_interview.png" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2021-05-26</div><div class="info-item-2">Spark 面试题解析</div></div><div class="info-2"><div class="info-item-1">Spark 内核Spark 的有几种部署模式，每种模式特点？ 本地模式：Spark 不一定非要跑在 Hadoop 集群，可以在本地，起多个线程的方式来指定。将 Spark 应用以多线程的方式直接运行在本地，一般都是为了方便调试，本地模式分三类： local：只启动一个 Executor local[k]:启动 k 个 Executor local[*]：启动跟 CPU 数目相同的 Executor standalone 模式：分布式部署集群，自带完整的服务，资源管理和任务监控是 Spark 自己监控，这个模式也是其他模式的基础。 Spark on Yarn 模式：分布式部署集群，资源和任务监控交给 YARN 管理，但是目前仅支持粗粒度资源分配方式，包含 cluster 和 client 运行模式，cluster 适合生产，Driver 运行在集群子节点，具有容错功能，client 适合调试，Driver 运行在客户端。 Spark On Mesos 模式：官方推荐这种模式（当然，原因之一是血缘关系）。正是由于 Spark 开发之初就考虑到支持...</div></div></div></a><a class="pagination-related" href="/post/d1e7dfd3.html" title="HDFS Shell 命令"><img class="cover" src="/images/cover/hdfs_shell.jpg" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2021-03-05</div><div class="info-item-2">HDFS Shell 命令</div></div><div class="info-2"><div class="info-item-1">FS Shell 调用文件系统（FS）的 Shell 命令应使用 bin/hadoop fs &lt;args&gt; 的形式。 所有的 FS shell 命令使用 URI 路径作为参数。 URI 格式是 scheme://authority/path。对 HDFS 文件系统，scheme 是 hdfs，对本地文件系统，scheme 是 file。其中 scheme 和 authority 参数都是可选的，如果未加指定，就会使用配置中指定的默认 scheme。 一个 HDFS 文件或目录比如 /parent/child 可以表示成 hdfs://namenode:namenodeport/parent/child，或者更简单的 /parent/child（假设你配置文件中的默认值是 namenode:namenodeport）。 大多数 FS Shell 命令的行为和对应的 Unix Shell 命令类似，不同之处会在下面介绍各命令使用详情时指出。出错信息会输出到 stderr，其他信息输出到 stdout。 cat 使用方法： 1hadoop fs -cat...</div></div></div></a><a class="pagination-related" href="/post/5a2a12a6.html" title="Flume 面试题解析"><img class="cover" src="/images/cover/bigdata_interview.png" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2021-03-29</div><div class="info-item-2">Flume 面试题解析</div></div><div class="info-2"><div class="info-item-1">Flume 使用场景？线上数据一般主要是落地（存储到磁盘）或者通过 socket 传输给另外一个系统，这种情况下，你很难推动线上应用或服务去修改接口，实现直接向 Kafka 里写数据，这时候你可能就需要 Flume 这样的系统帮你去做传输。 Flume 丢包问题？单机 upd 的 Flume source 的配置，100+M/s 数据量，10w qps Flume 就开始大量丢包，因此很多公司在搭建系统时，抛弃了 Flume，自己研发传输系统，但是往往会参考 Flume 的 Source-Channel-Sink 模式。 一些公司在 Flume 工作过程中，会对业务日志进行监控，例如 Flume agent 中有多少条日志，Flume 到 Kafka 后有多少条日志等等，如果数据丢失保持在 1% 左右是没有问题的，当数据丢失达到 5% 左右时就必须采取相应措施。 Flume 与 Kafka 的选取？采集层主要可以使用 Flume、Kafka 两种技术。 Flume：Flume 是管道流方式，提供了很多的默认实现，让用户通过参数部署，及扩展 API。 Kafka：Kafka...</div></div></div></a><a class="pagination-related" href="/post/420614eb.html" title="Sqoop 面试题解析"><img class="cover" src="/images/cover/bigdata_interview.png" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2021-04-13</div><div class="info-item-2">Sqoop 面试题解析</div></div><div class="info-2"><div class="info-item-1">Sqoop 参数Sqoop 导入数据到 HDFS 中的参数 123456789101112131415/opt/module/sqoop/bin/sqoop import \--connect jdbc 的 url 字符串\--username 账号\--password 密码\# HDFS 目标的目录--target-dir \# 导入的目标目录如果存在则删除那个目录--delete-target-dir \# 相当于 -m，并行导入时 MapTask 的个数--num-mappers \--fields-terminated-by \# 指定满足 sql 和条件的数据导入# --query：增加检索条件部分数据抽取# $CONDITIONS：数据分割条件的占位符--query &quot;$2&quot; &#x27;and $CONDITIONS;&#x27; Sqoop 导入数据到 Hive 中的参数 123456789# 一步将表结构和数据都导入到 hive 中bin/sqoop import \--connect jdbc 的 url 字符串\--table...</div></div></div></a><a class="pagination-related" href="/post/2f1ea7f2.html" title="Zookeeper 面试题解析"><img class="cover" src="/images/cover/bigdata_interview.png" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2021-03-27</div><div class="info-item-2">Zookeeper 面试题解析</div></div><div class="info-2"><div class="info-item-1">请简述 Zookeeper 的选举机制？假设有五台服务器组成的 Zookeeper 集群，它们的 id 从 1-5，同时它们都是最新启动的，也就是没有历史数据，在存放数据量这一点上，都是一样的。假设这些服务器依序启动，来看看会发生什么。 服务器 1 启动，此时只有它一台服务器启动了，它发出去的报没有任何响应，所以它的选举状态一直是 LOOKING 状态； 服务器 2 启动，它与最开始启动的服务器 1 进行通信，互相交换自己的选举结果，由于两者都没有历史数据，所以 id 值较大的服务器 2 胜出，但是由于没有达到超过半数以上的服务器都同意选举它(这个例子中的半数以上是 3)，所以服务器 1、2 还是继续保持 LOOKING 状态； 服务器 3 启动，根据前面的理论分析，服务器 3 成为服务器 1、2、3 中的 Leader，而与上面不同的是，此时有三台服务器选举了它，所以它成为了这次选举的 Leader； 服务器 4 启动，根据前面的分析，理论上服务器 4 应该是服务器 1、2、3、4 中最大的，但是由于前面已经有半数以上的服务器选举了服务器 3，所以它成为...</div></div></div></a></div></div></div><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i> <span>评论</span></div><div id="comment-close" onclick="custom.switchCommentMode()"><i class="fas fa-xmark"></i></div></div><div class="comment-wrap"><div><div id="twikoo-wrap"></div></div></div></div><div id="comment-mask"></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info text-center"><div class="card-info-top"><div id="card-info-hello"></div><div class="card-info-img"><img src="https://npm.elemecdn.com/eurkon-cdn/hexo/images/user/avatar.jpg" onerror='this.onerror=null,this.src="https://npm.elemecdn.com/eurkon-cdn/hexo/images/user/loading.gif"' alt="avatar"></div></div><div class="author-info-name is-center">Eurkon</div><div class="author-info-description">在这里我将记录学习过程中的笔记、分享一些经验与想法。希望能够帮助到您！</div><script defer data-pjax="data-pjax" src="/js/card_info.js"></script><div class="site-data"><a href="/archives/"><div class="headline">文章</div><div class="length-num">88</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">28</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">6</div></a></div><div class="card-info-social-icons"><a class="social-icon" href="https://github.com/Eurkon" rel="external nofollow noreferrer" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="mailto:eurkon@foxmail.com" rel="external nofollow noreferrer" target="_blank" title="Email"><i class="fas fa-envelope"></i></a></div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#Spark-%E7%9A%84%E7%AE%97%E5%AD%90%E7%9A%84%E5%88%86%E7%B1%BB"><span class="toc-number">1.</span> <span class="toc-text">Spark 的算子的分类</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Value-%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B%E7%9A%84-Transformation-%E7%AE%97%E5%AD%90"><span class="toc-number">2.</span> <span class="toc-text">Value 数据类型的 Transformation 算子</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%BE%93%E5%85%A5%E5%88%86%E5%8C%BA%E4%B8%8E%E8%BE%93%E5%87%BA%E5%88%86%E5%8C%BA%E4%B8%80%E5%AF%B9%E4%B8%80%E5%9E%8B"><span class="toc-number">2.1.</span> <span class="toc-text">输入分区与输出分区一对一型</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#map-%E7%AE%97%E5%AD%90"><span class="toc-number">2.1.1.</span> <span class="toc-text">map 算子</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#flatMap-%E7%AE%97%E5%AD%90"><span class="toc-number">2.1.2.</span> <span class="toc-text">flatMap 算子</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#mapPartitions-%E7%AE%97%E5%AD%90"><span class="toc-number">2.1.3.</span> <span class="toc-text">mapPartitions 算子</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#glom-%E7%AE%97%E5%AD%90"><span class="toc-number">2.1.4.</span> <span class="toc-text">glom 算子</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%BE%93%E5%85%A5%E5%88%86%E5%8C%BA%E4%B8%8E%E8%BE%93%E5%87%BA%E5%88%86%E5%8C%BA%E5%A4%9A%E5%AF%B9%E4%B8%80%E5%9E%8B"><span class="toc-number">2.2.</span> <span class="toc-text">输入分区与输出分区多对一型</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#union-%E7%AE%97%E5%AD%90"><span class="toc-number">2.2.1.</span> <span class="toc-text">union 算子</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#cartesian-%E7%AE%97%E5%AD%90"><span class="toc-number">2.2.2.</span> <span class="toc-text">cartesian 算子</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%BE%93%E5%85%A5%E5%88%86%E5%8C%BA%E4%B8%8E%E8%BE%93%E5%87%BA%E5%88%86%E5%8C%BA%E5%A4%9A%E5%AF%B9%E5%A4%9A%E5%9E%8B"><span class="toc-number">2.3.</span> <span class="toc-text">输入分区与输出分区多对多型</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#groupBy-%E7%AE%97%E5%AD%90"><span class="toc-number">2.3.1.</span> <span class="toc-text">groupBy 算子</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%BE%93%E5%87%BA%E5%88%86%E5%8C%BA%E4%B8%BA%E8%BE%93%E5%85%A5%E5%88%86%E5%8C%BA%E5%AD%90%E9%9B%86%E5%9E%8B"><span class="toc-number">2.4.</span> <span class="toc-text">输出分区为输入分区子集型</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#filter-%E7%AE%97%E5%AD%90"><span class="toc-number">2.4.1.</span> <span class="toc-text">filter 算子</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#distinct-%E7%AE%97%E5%AD%90"><span class="toc-number">2.4.2.</span> <span class="toc-text">distinct 算子</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#subtract-%E7%AE%97%E5%AD%90"><span class="toc-number">2.4.3.</span> <span class="toc-text">subtract 算子</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#sample-%E7%AE%97%E5%AD%90"><span class="toc-number">2.4.4.</span> <span class="toc-text">sample 算子</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Cache-%E5%9E%8B"><span class="toc-number">2.5.</span> <span class="toc-text">Cache 型</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#cache-%E7%AE%97%E5%AD%90"><span class="toc-number">2.5.1.</span> <span class="toc-text">cache 算子</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#persist-%E7%AE%97%E5%AD%90"><span class="toc-number">2.5.2.</span> <span class="toc-text">persist 算子</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Key-Value-%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B%E7%9A%84-Transformation-%E7%AE%97%E5%AD%90"><span class="toc-number">3.</span> <span class="toc-text">Key-Value 数据类型的 Transformation 算子</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%BE%93%E5%85%A5%E5%88%86%E5%8C%BA%E4%B8%8E%E8%BE%93%E5%87%BA%E5%88%86%E5%8C%BA%E4%B8%80%E5%AF%B9%E4%B8%80"><span class="toc-number">3.1.</span> <span class="toc-text">输入分区与输出分区一对一</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#mapValues-%E7%AE%97%E5%AD%90"><span class="toc-number">3.1.1.</span> <span class="toc-text">mapValues 算子</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AF%B9%E5%8D%95%E4%B8%AA-RDD-%E6%88%96%E4%B8%A4%E4%B8%AA-RDD-%E8%81%9A%E5%90%88"><span class="toc-number">3.2.</span> <span class="toc-text">对单个 RDD 或两个 RDD 聚合</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#combineByKey-%E7%AE%97%E5%AD%90"><span class="toc-number">3.2.1.</span> <span class="toc-text">combineByKey 算子</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#reduceByKey-%E7%AE%97%E5%AD%90"><span class="toc-number">3.2.2.</span> <span class="toc-text">reduceByKey 算子</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#partitionBy-%E7%AE%97%E5%AD%90"><span class="toc-number">3.2.3.</span> <span class="toc-text">partitionBy 算子</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#cogroup-%E7%AE%97%E5%AD%90"><span class="toc-number">3.2.4.</span> <span class="toc-text">cogroup 算子</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%BF%9E%E6%8E%A5"><span class="toc-number">3.3.</span> <span class="toc-text">连接</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#join-%E7%AE%97%E5%AD%90"><span class="toc-number">3.3.1.</span> <span class="toc-text">join 算子</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#leftOuterJoin-%E5%92%8C-rightOuterJoin-%E7%AE%97%E5%AD%90"><span class="toc-number">3.3.2.</span> <span class="toc-text">leftOuterJoin 和 rightOuterJoin 算子</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Action-%E7%AE%97%E5%AD%90"><span class="toc-number">4.</span> <span class="toc-text">Action 算子</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%97%A0%E8%BE%93%E5%87%BA"><span class="toc-number">4.1.</span> <span class="toc-text">无输出</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#foreach-%E7%AE%97%E5%AD%90"><span class="toc-number">4.1.1.</span> <span class="toc-text">foreach 算子</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#HDFS"><span class="toc-number">4.2.</span> <span class="toc-text">HDFS</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#saveAsTextFile-%E7%AE%97%E5%AD%90"><span class="toc-number">4.2.1.</span> <span class="toc-text">saveAsTextFile 算子</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#saveAsObjectFile-%E7%AE%97%E5%AD%90"><span class="toc-number">4.2.2.</span> <span class="toc-text">saveAsObjectFile 算子</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Scala-%E9%9B%86%E5%90%88%E5%92%8C%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B"><span class="toc-number">4.3.</span> <span class="toc-text">Scala 集合和数据类型</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#collect-%E7%AE%97%E5%AD%90"><span class="toc-number">4.3.1.</span> <span class="toc-text">collect 算子</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#collectAsMap-%E7%AE%97%E5%AD%90"><span class="toc-number">4.3.2.</span> <span class="toc-text">collectAsMap 算子</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#reduceByKeyLocally-%E7%AE%97%E5%AD%90"><span class="toc-number">4.3.3.</span> <span class="toc-text">reduceByKeyLocally 算子</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#lookup-%E7%AE%97%E5%AD%90"><span class="toc-number">4.3.4.</span> <span class="toc-text">lookup 算子</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#count-%E7%AE%97%E5%AD%90"><span class="toc-number">4.3.5.</span> <span class="toc-text">count 算子</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#top-%E7%AE%97%E5%AD%90"><span class="toc-number">4.3.6.</span> <span class="toc-text">top 算子</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#reduce-%E7%AE%97%E5%AD%90"><span class="toc-number">4.3.7.</span> <span class="toc-text">reduce 算子</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#fold-%E7%AE%97%E5%AD%90"><span class="toc-number">4.3.8.</span> <span class="toc-text">fold 算子</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#aggregate-%E7%AE%97%E5%AD%90"><span class="toc-number">4.3.9.</span> <span class="toc-text">aggregate 算子</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#takeSample-%E7%AE%97%E5%AD%90"><span class="toc-number">4.3.10.</span> <span class="toc-text">takeSample 算子</span></a></li></ol></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/post/b0188c87.html" title="ECharts 帕累托图"><img src="/images/cover/echarts_pareto.png" onerror='this.onerror=null,this.src="https://npm.elemecdn.com/eurkon-cdn/hexo/images/user/404.jpg"' alt="ECharts 帕累托图"></a><div class="content"><a class="title" href="/post/b0188c87.html" title="ECharts 帕累托图">ECharts 帕累托图</a><time datetime="2023-05-30T01:00:00.000Z" title="发表于 2023-05-30 09:00:00">2023-05-30</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/post/620d6870.html" title="ECharts 子弹图"><img src="/images/cover/echarts_bullet.png" onerror='this.onerror=null,this.src="https://npm.elemecdn.com/eurkon-cdn/hexo/images/user/404.jpg"' alt="ECharts 子弹图"></a><div class="content"><a class="title" href="/post/620d6870.html" title="ECharts 子弹图">ECharts 子弹图</a><time datetime="2023-04-27T01:00:00.000Z" title="发表于 2023-04-27 09:00:00">2023-04-27</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/post/22774ddc.html" title="ECharts 径向条形图"><img src="/images/cover/echarts_radial_bar.png" onerror='this.onerror=null,this.src="https://npm.elemecdn.com/eurkon-cdn/hexo/images/user/404.jpg"' alt="ECharts 径向条形图"></a><div class="content"><a class="title" href="/post/22774ddc.html" title="ECharts 径向条形图">ECharts 径向条形图</a><time datetime="2023-04-26T01:00:00.000Z" title="发表于 2023-04-26 09:00:00">2023-04-26</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/post/68739172.html" title="ECharts 渐变折线图"><img src="/images/cover/echarts_line_gradient.png" onerror='this.onerror=null,this.src="https://npm.elemecdn.com/eurkon-cdn/hexo/images/user/404.jpg"' alt="ECharts 渐变折线图"></a><div class="content"><a class="title" href="/post/68739172.html" title="ECharts 渐变折线图">ECharts 渐变折线图</a><time datetime="2023-03-12T01:00:00.000Z" title="发表于 2023-03-12 09:00:00">2023-03-12</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/post/1c85bfc3.html" title="数仓设计与 ETL 规范"><img src="/images/cover/etl_norm.png" onerror='this.onerror=null,this.src="https://npm.elemecdn.com/eurkon-cdn/hexo/images/user/404.jpg"' alt="数仓设计与 ETL 规范"></a><div class="content"><a class="title" href="/post/1c85bfc3.html" title="数仓设计与 ETL 规范">数仓设计与 ETL 规范</a><time datetime="2022-12-31T02:00:00.000Z" title="发表于 2022-12-31 10:00:00">2022-12-31</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/post/553238e8.html" title="ECharts 生涯彩虹图"><img src="/images/cover/echarts_career.png" onerror='this.onerror=null,this.src="https://npm.elemecdn.com/eurkon-cdn/hexo/images/user/404.jpg"' alt="ECharts 生涯彩虹图"></a><div class="content"><a class="title" href="/post/553238e8.html" title="ECharts 生涯彩虹图">ECharts 生涯彩虹图</a><time datetime="2022-11-06T01:00:00.000Z" title="发表于 2022-11-06 09:00:00">2022-11-06</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div id="footer-group-container"><div class="footer-group"><span class="footer-group-title">统计</span><a class="footer-group-item" href="/charts/">文章统计</a><a class="footer-group-item" href="/census/">博客统计</a></div><div class="footer-group"><span class="footer-group-title">导航</span><a class="footer-group-item" href="/link/#我的友链-amp-友链格式">申请友链</a><a class="footer-group-item" target="_blank" rel="noopener external nofollow noreferrer" href="https://github.com/Eurkon/hexo-theme-butterfly-eurkon">魔改源码</a><a class="footer-group-item" href="/stars/">网站收藏</a><a class="footer-group-item" href="javascript:toRandomPost();" rel="external nofollow noreferrer">随机文章</a></div><div class="footer-group"><span class="footer-group-title">分类</span><a class="footer-group-item" href="/categories/学习笔记/">学习笔记</a><a class="footer-group-item" href="/categories/魔改教程/">魔改教程</a><a class="footer-group-item" href="/categories/分享转载/">分享转载</a><a class="footer-group-item" href="/categories/作品案例/">作品案例</a></div><div class="footer-group"><span class="footer-group-title">关于</span><a class="footer-group-item" href="/notice/">网站公告</a><a class="footer-group-item" href="/update/">博客更新</a><a class="footer-group-item" href="/message/">给我留言</a><a class="footer-group-item" href="mailto:eurkon@foxmail.com" rel="external nofollow noreferrer">联系博主</a></div><div class="footer-group"><span class="footer-group-title">服务</span><a class="footer-group-item" href="/fcircle/">友链订阅</a><a class="footer-group-item" href="/rss.xml">RSS 订阅</a><a class="footer-group-item" href="/atom.xml">Atom 订阅</a><a class="footer-group-item" target="_blank" rel="noopener external nofollow noreferrer" href="https://bf.zzxworld.com/s/686">BlogFinder</a></div><div class="footer-group" id="footer-group-flink"><span class="footer-group-title">友链<i class="fas fa-sync" title="随机友链" onclick="eurkon.footerRandomFlink(flinks,3)"></i></span><a class="footer-group-item" href="" target="_blank" rel="noopener external nofollow noreferrer">加载中...</a><a class="footer-group-item" href="" target="_blank" rel="noopener external nofollow noreferrer">加载中...</a><a class="footer-group-item" href="" target="_blank" rel="noopener external nofollow noreferrer">加载中...</a><a class="footer-group-item" href="/link/">更多友链</a></div><div class="footer-group"><span class="footer-group-title">协议</span><a class="footer-group-item" href="/protocol/comment/" title="用户发言前，请认真阅读本条例。一经发言，即视为同意接受本条例；如不同意，请勿发言。">评论协议</a><a class="footer-group-item" href="/protocol/copyright/" title="本站所有原创文章采用知识共享(Creative Commons)署名—非商业性使用—相同方式共享4.0国际公共许可协议">版权协议</a></div></div><div id="footer-banner"><div id="footer-banner-container"><div class="footer-banner"><div class="copyright">Copyright &copy; 2021 - 2024 Eurkon.com All Rights Reserved.</div></div><div class="footer-banner"><div class="framework-info"><span>框架</span> <a target="_blank" rel="noopener external nofollow noreferrer" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题</span> <a target="_blank" rel="noopener external nofollow noreferrer" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div><div class="footer-banner"><a target="_blank" rel="noopener external nofollow noreferrer" href="https://beian.miit.gov.cn">粤ICP备2022108639号</a><a href="/protocol/copyright/" title="版权协议"><i class="fab fa-creative-commons"></i><i class="fab fa-creative-commons-by"></i><i class="fab fa-creative-commons-nc"></i><i class="fab fa-creative-commons-sa"></i></a></div></div></div></div></footer></div><div class="hidden" id="rightside-mask" onclick="eurkon.switchRightSide()"></div><div class="hidden" id="rightside"><div id="rightside-header"><div id="rightside-back"><i class="fas fa-chevron-left" onclick="eurkon.backRightSide()"></i></div><div id="rightside-title">设置</div><div id="rightside-close" onclick="eurkon.switchRightSide()"><i class="fas fa-xmark"></i></div></div><div id="rightside-content"><div id="card-newest-comments"><div class="item-headline"><i class="fas fa-comment-dots"></i><span>最新评论</span></div><div class="aside-list"><span>加载中...</span></div></div><div id="card-post-content"><div class="card-widget card-categories"><div class="item-headline"><i class="fas fa-folder-open"></i> <span>分类</span></div><ul class="card-category-list" id="aside-cat-list"><li class="card-category-list-item"><a class="card-category-list-link" href="/categories/%E4%BD%9C%E5%93%81%E6%A1%88%E4%BE%8B/"><span class="card-category-list-name">🖥️作品案例</span><span class="card-category-list-count">23</span></a></li><li class="card-category-list-item"><a class="card-category-list-link" href="/categories/%E5%88%86%E4%BA%AB%E8%BD%AC%E8%BD%BD/"><span class="card-category-list-name">🌐分享转载</span><span class="card-category-list-count">3</span></a></li><li class="card-category-list-item"><a class="card-category-list-link" href="/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"><span class="card-category-list-name">📚学习笔记</span><span class="card-category-list-count">24</span></a></li><li class="card-category-list-item"><a class="card-category-list-link" href="/categories/%E7%94%9F%E6%B4%BB%E9%9A%8F%E7%AC%94/"><span class="card-category-list-name">💬生活随笔</span><span class="card-category-list-count">1</span></a></li><li class="card-category-list-item"><a class="card-category-list-link" href="/categories/%E9%9D%A2%E8%AF%95%E7%B3%BB%E5%88%97/"><span class="card-category-list-name">📝面试系列</span><span class="card-category-list-count">21</span></a></li><li class="card-category-list-item"><a class="card-category-list-link" href="/categories/%E9%AD%94%E6%94%B9%E6%95%99%E7%A8%8B/"><span class="card-category-list-name">🎨魔改教程</span><span class="card-category-list-count">16</span></a></li></ul></div><div class="card-widget card-tags"><div class="item-headline"><i class="fas fa-tags"></i><span>标签</span></div><div class="card-tag-cloud"><a href="/tags/PostgreSQL/" style="font-size:1.3em;color:#99a1ac">PostgreSQL</a> <a href="/tags/Butterfly/" style="font-size:1.34em;color:#99a3b0">Butterfly</a> <a href="/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/" style="font-size:1.46em;color:#99a7bb">大数据</a> <a href="/tags/Git/" style="font-size:1.1em;color:#999">Git</a> <a href="/tags/Linux/" style="font-size:1.1em;color:#999">Linux</a> <a href="/tags/Spark/" style="font-size:1.18em;color:#999ca1">Spark</a> <a href="/tags/Hive/" style="font-size:1.18em;color:#999ca1">Hive</a> <a href="/tags/Hexo/" style="font-size:1.42em;color:#99a6b7">Hexo</a> <a href="/tags/Sqoop/" style="font-size:1.14em;color:#999b9d">Sqoop</a> <a href="/tags/Hadoop/" style="font-size:1.18em;color:#999ca1">Hadoop</a> <a href="/tags/%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93/" style="font-size:1.1em;color:#999">数据仓库</a> <a href="/tags/%E7%94%9F%E6%B4%BB%E9%9A%8F%E7%AC%94/" style="font-size:1.1em;color:#999">生活随笔</a> <a href="/tags/Kafka/" style="font-size:1.14em;color:#999b9d">Kafka</a> <a href="/tags/MySQL/" style="font-size:1.26em;color:#999fa8">MySQL</a> <a href="/tags/HTML/" style="font-size:1.1em;color:#999">HTML</a> <a href="/tags/HBase/" style="font-size:1.14em;color:#999b9d">HBase</a> <a href="/tags/%E7%AE%97%E6%B3%95/" style="font-size:1.1em;color:#999">算法</a> <a href="/tags/JavaScript/" style="font-size:1.1em;color:#999">JavaScript</a> <a href="/tags/Elasticsearch/" style="font-size:1.1em;color:#999">Elasticsearch</a> <a href="/tags/Markdown/" style="font-size:1.1em;color:#999">Markdown</a> <a href="/tags/ECharts/" style="font-size:1.5em;color:#99a9bf">ECharts</a> <a href="/tags/Flume/" style="font-size:1.14em;color:#999b9d">Flume</a> <a href="/tags/Zookeeper/" style="font-size:1.14em;color:#999b9d">Zookeeper</a> <a href="/tags/Java/" style="font-size:1.38em;color:#99a4b4">Java</a> <a href="/tags/Python/" style="font-size:1.1em;color:#999">Python</a> <a href="/tags/%E6%96%87%E6%A1%A3/" style="font-size:1.26em;color:#999fa8">文档</a> <a href="/tags/R/" style="font-size:1.22em;color:#999ea4">R</a> <a href="/tags/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/" style="font-size:1.3em;color:#99a1ac">数据分析</a></div></div></div></div><div id="rightside-config-hide"><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="translateLink" type="button" title="简繁转换">繁</button><button id="darkmode" type="button" title="日间和夜间模式切换"><i class="fas fa-sun"></i><i class="fas fa-moon"></i></button><button id="barrage-btn" type="button" title="热评开关" onclick="eurkon.switchCommentBarrage()"><i class="fas fa-message"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div id="rightmenu"><div class="rightmenu-group rightmenu-small"><div class="rightmenu-item" id="menu-backward" onclick="window.history.back()"><i class="fas fa-arrow-left"></i></div><div class="rightmenu-item" id="menu-forward" onclick="window.history.forward()"><i class="fas fa-arrow-right"></i></div><div class="rightmenu-item" id="menu-refresh" onclick="location.reload()"><i class="fas fa-arrow-rotate-right"></i></div><div class="rightmenu-item" id="menu-top" onclick="btf.scrollToDest(0,500)"><i class="fas fa-arrow-up"></i></div></div><div class="rightmenu-group rightmenu-line" id="rightmenu-text"><div class="rightmenu-item" id="menu-copy"><i class="fas fa-copy"></i><span>复制内容</span></div><div class="rightmenu-item" id="menu-comment"><i class="fas fa-comment"></i><span>引用评论</span></div><div class="rightmenu-item" id="menu-paste"><i class="fas fa-paste"></i><span>粘贴文本</span></div><div class="rightmenu-item" id="menu-search"><i class="fas fa-search"></i><span>在本站搜索</span></div><div class="rightmenu-item" id="menu-baidu"><i class="fas fa-search-plus"></i><span>去百度搜索</span></div></div><div class="rightmenu-group rightmenu-line" id="rightmenu-href"><div class="rightmenu-item" id="menu-copy-image"><i class="fas fa-copy"></i><span>复制图片</span></div><div class="rightmenu-item" id="menu-download-image"><i class="fas fa-download"></i><span>下载图片</span></div><div class="rightmenu-item" id="menu-link"><i class="fas fa-share"></i><span>分享链接</span></div><div class="rightmenu-item" id="menu-window"><i class="fas fa-window-restore"></i><span>新窗口打开</span></div></div><div class="rightmenu-group rightmenu-line" id="rightmenu-post"><a class="rightmenu-item" id="menu-random" href="/random/"><i class="fas fa-random"></i><span>随机文章</span></a><a class="rightmenu-item" id="menu-categories" href="/categories/"><i class="fas fa-shapes"></i><span>全部分类</span></a><a class="rightmenu-item" id="menu-tags" href="/tags/"><i class="fas fa-tags"></i><span>所有标签</span></a><div class="rightmenu-item" id="menu-share"><i class="fas fa-share-square"></i><span>分享本页</span></div></div><div class="rightmenu-group rightmenu-line" id="rightmenu-site"><a class="rightmenu-item" id="menu-message" href="/message/"><i class="fas fa-envelope"></i><span>留言信箱</span></a><a class="rightmenu-item" id="menu-about" href="/about/"><i class="fas fa-address-card"></i><span>关于本站</span></a></div></div><div id="rightmenu-mask"></div><div><script src="/js/utils.js?v=5.1.0"></script><script src="/js/main.js?v=5.1.0"></script><script src="/js/eurkon/color-thief.min.js"></script><script defer src="/js/eurkon/eurkon.js"></script><script defer data-pjax src="/js/eurkon/refresh.js"></script><script src="/js/tw_cn.js?v=5.1.0"></script><script src="https://cdn.jsdelivr.net/npm/instant.page@5.2.0/instantpage.min.js" type="module"></script><script src="https://cdn.jsdelivr.net/npm/vanilla-lazyload@19.1.3/dist/lazyload.iife.min.js"></script><script src="https://cdn.jsdelivr.net/npm/node-snackbar@0.1.16/dist/snackbar.min.js"></script><div class="js-pjax"><script>(() => {
  const runMermaid = ele => {
    window.loadMermaid = true
    const theme = document.documentElement.getAttribute('data-theme') === 'dark' ? 'dark' : 'default'

    ele.forEach((item, index) => {
      const mermaidSrc = item.firstElementChild
      const mermaidThemeConfig = `%%{init:{ 'theme':'${theme}'}}%%\n`
      const mermaidID = `mermaid-${index}`
      const mermaidDefinition = mermaidThemeConfig + mermaidSrc.textContent

      const renderFn = mermaid.render(mermaidID, mermaidDefinition)
      const renderMermaid = svg => {
        mermaidSrc.insertAdjacentHTML('afterend', svg)
      }

      // mermaid v9 and v10 compatibility
      typeof renderFn === 'string' ? renderMermaid(renderFn) : renderFn.then(({ svg }) => renderMermaid(svg))
    })
  }

  const codeToMermaid = () => {
    const codeMermaidEle = document.querySelectorAll('pre > code.mermaid')
    if (codeMermaidEle.length === 0) return

    codeMermaidEle.forEach(ele => {
      const preEle = document.createElement('pre')
      preEle.className = 'mermaid-src'
      preEle.hidden = true
      preEle.textContent = ele.textContent
      const newEle = document.createElement('div')
      newEle.className = 'mermaid-wrap'
      newEle.appendChild(preEle)
      ele.parentNode.replaceWith(newEle)
    })
  }

  const loadMermaid = () => {
    if (true) codeToMermaid()
    const $mermaid = document.querySelectorAll('#article-container .mermaid-wrap')
    if ($mermaid.length === 0) return

    const runMermaidFn = () => runMermaid($mermaid)
    btf.addGlobalFn('themeChange', runMermaidFn, 'mermaid')
    window.loadMermaid ? runMermaidFn() : btf.getScript('https://cdn.jsdelivr.net/npm/mermaid@11.3.0/dist/mermaid.min.js').then(runMermaidFn)
  }

  btf.addGlobalFn('encrypt', loadMermaid, 'mermaid')
  window.pjax ? loadMermaid() : document.addEventListener('DOMContentLoaded', loadMermaid)
})()</script><script>(() => {
  const getCount = () => {
    const countELement = document.getElementById('twikoo-count')
    if(!countELement) return
    twikoo.getCommentsCount({
      envId: 'https://twikoo.eurkon.com/',
      region: '',
      urls: [window.location.pathname],
      includeReply: false
    }).then(res => {
      countELement.textContent = res[0].count
    }).catch(err => {
      console.error(err)
    })
  }

  const init = () => {
    twikoo.init(Object.assign({
      el: '#twikoo-wrap',
      envId: 'https://twikoo.eurkon.com/',
      region: '',
      onCommentLoaded: () => {
        btf.loadLightbox(document.querySelectorAll('#twikoo .tk-content img:not(.tk-owo-emotion)'))
        setTimeout(function(){
          let tk_comment = document.querySelectorAll('.tk-comments-container .tk-comment')
          if (tk_comment.length > 0) {
            let html = `<div class="swiper-wrapper">`
            for (let i = 0; i < tk_comment.length; i++) {
              let tk_id = tk_comment[i].getAttribute('id') || ''
              let tk_nick = tk_comment[i].querySelector('.tk-nick')?.innerText || ''
              let tk_href = tk_comment[i].querySelector('.tk-nick')?.href || ''
              let tk_avatar = tk_comment[i].querySelector('.tk-avatar-img')?.src || ''
              let tk_time = tk_comment[i].querySelector('.tk-time')?.innerText || ''
              let tk_city = tk_comment[i].querySelector('.tk-extras .tk-extra:first-child span:last-child')?.innerText || ''
              let tk_content = tk_comment[i].querySelector('.tk-content>span:last-child')?.innerHTML || ''
              tk_content = tk_content.replace(/\n/g, '') // replace \n
              tk_content = tk_content.replace(/<blockquote>.*?<\/blockquote>/gi, '') // replace blockquote
              //- tk_content = tk_content.replace(/<a[^>]+?data-caption="image".*?<img.*?src="(.*?)"?[^\>]+><\/a>/ig, '[图片]') // replace image link
              //- tk_content = tk_content.replace(/<img.*?src="(.*?)"?[^\>]+>/ig, '[图片]') // replace image link
              //- tk_content = tk_content.replace(/<a[^>]+?href=["']?([^"']+)["']?[^>]*>([^<]+)<\/a>/gi, '[链接]') // replace url
              tk_content = tk_content.replace(/<pre.*?<\/pre>/gi, '[代码]') // replace code
              //- tk_content = tk_content.replace(/<[^>]+>/g, "") // remove html tag
              html += `
                <div class="swiper-slide">
                  <div class="comment-barrage-item">
                    <div class="barrage-info">
                      <a class="barrage-title" title="跳转至评论区" href="#post-comment">热评</a>
                      <a href="${tk_href ? tk_href + '" target="_blank" rel="noopener noreferrer" title="访问 '+ tk_nick +'"' : 'javascript:void(0);"'}>
                        <img class="barrage-avatar" src="${tk_avatar}">
                      </a>
                      <span class="barrage-nick">${tk_nick}</span>
                      <span class="barrage-city">${tk_city}</span>
                      <span class="barrage-time">${tk_time}</span>
                      <a class="barrage-close" onclick="eurkon.switchCommentBarrage()" title="隐藏热评"><i class="fa-solid fa-xmark"></i></a>
                    </div>
                    <div class="barrage-content">
                      <a title="跳转至该评论" href="#${tk_id}">${tk_content}</a>
                    </div>
                  </div>
                </div>`
            }
            html += '</div>'
            let barrageContainer = document.getElementById('comment-barrage') || document.createElement('div')
            barrageContainer.id = 'comment-barrage'
            barrageContainer.innerHTML = html
            barrageContainer.style.bottom = window.localStorage.getItem('commentBarrageDisplay') === 'false' ? '-1000px' : '1rem'
            if( document.getElementById('barrage-btn') ) document.getElementById('barrage-btn').classList.add(window.localStorage.getItem('commentBarrageDisplay') === 'false' ? 'off' : 'on')
            document.getElementById('post-comment').appendChild(barrageContainer)
            var barrageSwiper = new Swiper('#comment-barrage', {
              direction: 'vertical',
              loop: true,
              mousewheel: true,
              autoplay: {
                delay: 3000,
                disableOnInteraction: true,
              }
            })
            barrageContainer.onmouseenter = function () {
              barrageSwiper.autoplay.stop()
            };
            barrageContainer.onmouseleave = function () {
              barrageSwiper.autoplay.start()
            };
          }
        }, 1000)
      }
    }, null))

    GLOBAL_CONFIG_SITE.isPost && getCount()
  }

  const loadTwikoo = () => {
    if (typeof twikoo === 'object') setTimeout(init,0)
    else btf.getScript('https://cdn.jsdelivr.net/npm/twikoo@1.6.39/dist/twikoo.all.min.js').then(init)
  }

  if ('Twikoo' === 'Twikoo' || !false) {
    if (false) btf.loadComment(document.getElementById('twikoo-wrap'), loadTwikoo)
    else loadTwikoo()
  } else {
    window.loadOtherComment = loadTwikoo
  }
})()</script></div><script>window.newestComments = {
  changeContent: content => {
    if (content === '') return content

    content = content.replace(/<img.*?src="(.*?)"?[^\>]+>/ig, '[图片]') // replace image link
    content = content.replace(/<a[^>]+?href=["']?([^"']+)["']?[^>]*>([^<]+)<\/a>/gi, '[链接]') // replace url
    content = content.replace(/<pre><code>.*?<\/pre>/gi, '[代码]') // replace code
    content = content.replace(/<code>.*?<\/code>/gi, '[代码]') // replace code      
    content = content.replace(/<[^>]+>/g, "") // remove html tag

    if (content.length > 150) {
      content = content.substring(0, 150) + '...'
    }
    return content
  },

  generateHtml: (array, ele) => {
    let result = ''

    if (array.length) {
      for (let i = 0; i < array.length; i++) {
        result += '<div class="aside-list-item">'

        if (true && array[i].avatar) {
          const imgAttr = 'data-lazy-src'
          result += `<a href="${array[i].url}" class="thumbnail"><img ${imgAttr}="${array[i].avatar}" alt="${array[i].nick}"></a>`
        }

        result += `<div class="content">
        <a class="comment" href="${array[i].url}" title="${array[i].content}">${array[i].content}</a>
        <div class="name"><span>${array[i].nick} / </span><time datetime="${array[i].date}">${btf.diffDate(array[i].date, true)}</time></div>
        </div></div>`
      }
    } else {
      result += '暂无评论'
    }

    ele.innerHTML = result
    window.lazyLoadInstance && window.lazyLoadInstance.update()
    window.pjax && window.pjax.refresh(ele)
  },

  newestCommentInit: (name, getComment) => {
    const $dom = document.querySelector('#card-newest-comments .aside-list')
    if ($dom) {
      const data = btf.saveToLocal.get(name)
      if (data) {
        newestComments.generateHtml(JSON.parse(data), $dom)
      } else {
        getComment($dom)
      }
    }
  },

  run: (name, getComment) => {
    newestComments.newestCommentInit(name, getComment)
    btf.addGlobalFn('pjaxComplete', () => newestComments.newestCommentInit(name, getComment), name)
  }
}</script><script>window.addEventListener('load', () => {
  const keyName = 'twikoo-newest-comments'
  const { changeContent, generateHtml, run } = window.newestComments

  const getComment = ele => {
    const runTwikoo = () => {
      twikoo.getRecentComments({
        envId: 'https://twikoo.eurkon.com/',
        region: '',
        pageSize: 8,
        includeReply: true
      }).then(res => {
        const twikooArray = res.map(e => {
          return {
            'content': changeContent(e.comment),
            'avatar': e.avatar,
            'nick': e.nick,
            'url': e.url + '#' + e.id,
            'date': new Date(e.created).toISOString()
          }
        })

        btf.saveToLocal.set(keyName, JSON.stringify(twikooArray), 10/(60*24))
        generateHtml(twikooArray, ele)
      }).catch(err => {
        console.error(err)
        ele.textContent= "无法获取评论，请确认相关配置是否正确"
      })
    }

    if (typeof twikoo === 'object') {
      runTwikoo()
    } else {
      btf.getScript('https://cdn.jsdelivr.net/npm/twikoo@1.6.39/dist/twikoo.all.min.js').then(runTwikoo)
    }
  }

  run(keyName, getComment)
})</script><script defer async src="//at.alicdn.com/t/font_2358265_expoyqe85d4.js"></script><script defer src="/js/custom.js"></script><script defer data-pjax src="/js/refresh.js"></script><script src="https://cdn.jsdelivr.net/npm/pjax@0.2.8/pjax.min.js"></script><script>(() => {
  const pjaxSelectors = ["head > title","#config-diff","#body-wrap","#rightside-config-hide","#rightside-config-show",".js-pjax"]

  window.pjax = new Pjax({
    elements: 'a:not([target="_blank"])',
    selectors: pjaxSelectors,
    cacheBust: false,
    analytics: false,
    scrollRestoration: false
  })

  const triggerPjaxFn = (val) => {
    if (!val) return
    Object.values(val).forEach(fn => fn())
  }

  document.addEventListener('pjax:send', () => {
    // removeEventListener
    btf.removeGlobalFnEvent('pjaxSendOnce')
    btf.removeGlobalFnEvent('themeChange')

    // reset readmode
    const $bodyClassList = document.body.classList
    if ($bodyClassList.contains('read-mode')) $bodyClassList.remove('read-mode')

    triggerPjaxFn(window.globalFn.pjaxSend)
  })

  document.addEventListener('pjax:complete', () => {
    btf.removeGlobalFnEvent('pjaxCompleteOnce')
    document.querySelectorAll('script[data-pjax]').forEach(item => {
      const newScript = document.createElement('script')
      const content = item.text || item.textContent || item.innerHTML || ""
      Array.from(item.attributes).forEach(attr => newScript.setAttribute(attr.name, attr.value))
      newScript.appendChild(document.createTextNode(content))
      item.parentNode.replaceChild(newScript, item)
    })

    triggerPjaxFn(window.globalFn.pjaxComplete)
  })

  document.addEventListener('pjax:error', e => {
    if (e.request.status === 404) {
      pjax.loadUrl('/404.html')
    }
  })
})()</script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="text-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i> <span>数据加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"></div></div><hr><div id="local-search-results"></div><div id="local-search-stats-wrap"></div></div></div><div id="search-mask"></div><script src="/js/search/local-search.js?v=5.1.0"></script></div></div></body></html><script>var posts=[{title:"ECharts 同X轴多Y轴图表",path:"/post/acc26f11.html",categories:[{name:"作品案例",path:"/categories/作品案例/"}],tags:[{name:"ECharts",path:"/tags/ECharts/"}],cover:"/images/cover/echarts_multi_chart.png",date:"2021-08-30T01:00:00.000Z",updated:"2021-08-30T01:00:00.000Z"},{title:"ECharts 地图上显示柱状图",path:"/post/5a6784e7.html",categories:[{name:"作品案例",path:"/categories/作品案例/"}],tags:[{name:"ECharts",path:"/tags/ECharts/"}],cover:"/images/cover/echarts_map_bar.png",date:"2021-11-10T01:00:00.000Z",updated:"2021-11-10T01:00:00.000Z"},{title:"ECharts 地图上显示饼图",path:"/post/d8b77f28.html",categories:[{name:"作品案例",path:"/categories/作品案例/"}],tags:[{name:"ECharts",path:"/tags/ECharts/"}],cover:"/images/cover/echarts_map_pie.png",date:"2021-11-01T01:00:00.000Z",updated:"2021-11-01T01:00:00.000Z"},{title:"ECharts 子弹图",path:"/post/620d6870.html",categories:[{name:"作品案例",path:"/categories/作品案例/"}],tags:[{name:"ECharts",path:"/tags/ECharts/"}],cover:"/images/cover/echarts_bullet.png",date:"2023-04-27T01:00:00.000Z",updated:"2023-04-27T01:00:00.000Z"},{title:"ECharts 对比漏斗图",path:"/post/ee94ffd8.html",categories:[{name:"作品案例",path:"/categories/作品案例/"}],tags:[{name:"ECharts",path:"/tags/ECharts/"}],cover:"/images/cover/echarts_funnel.png",date:"2022-06-10T01:00:00.000Z",updated:"2022-06-10T01:00:00.000Z"},{title:"ECharts 帕累托图",path:"/post/b0188c87.html",categories:[{name:"作品案例",path:"/categories/作品案例/"}],tags:[{name:"ECharts",path:"/tags/ECharts/"}],cover:"/images/cover/echarts_pareto.png",date:"2023-05-30T01:00:00.000Z",updated:"2023-05-30T01:00:00.000Z"},{title:"ECharts 弹窗悬浮图表",path:"/post/8050767e.html",categories:[{name:"作品案例",path:"/categories/作品案例/"}],tags:[{name:"ECharts",path:"/tags/ECharts/"}],cover:"/images/cover/echarts_tooltip_chart.png",date:"2021-08-15T01:00:00.000Z",updated:"2021-08-15T01:00:00.000Z"},{title:"ECharts 径向条形图",path:"/post/22774ddc.html",categories:[{name:"作品案例",path:"/categories/作品案例/"}],tags:[{name:"ECharts",path:"/tags/ECharts/"}],cover:"/images/cover/echarts_radial_bar.png",date:"2023-04-26T01:00:00.000Z",updated:"2023-04-26T01:00:00.000Z"},{title:"ECharts 散点地图",path:"/post/e3dd705b.html",categories:[{name:"作品案例",path:"/categories/作品案例/"}],tags:[{name:"ECharts",path:"/tags/ECharts/"}],cover:"/images/cover/echarts_scatter_map.png",date:"2021-09-01T01:00:00.000Z",updated:"2021-09-01T01:00:00.000Z"},{title:"ECharts 日期旭日图",path:"/post/9bcf49c7.html",categories:[{name:"作品案例",path:"/categories/作品案例/"}],tags:[{name:"ECharts",path:"/tags/ECharts/"}],cover:"/images/cover/echarts_date_sunburst.png",date:"2022-06-21T01:00:00.000Z",updated:"2022-06-21T01:00:00.000Z"},{title:"ECharts 时序图",path:"/post/b9e0457b.html",categories:[{name:"作品案例",path:"/categories/作品案例/"}],tags:[{name:"ECharts",path:"/tags/ECharts/"}],cover:"/images/cover/echarts_timeline.png",date:"2021-08-01T01:00:00.000Z",updated:"2021-08-01T01:00:00.000Z"},{title:"ECharts 时间极坐标",path:"/post/97890f7.html",categories:[{name:"作品案例",path:"/categories/作品案例/"}],tags:[{name:"ECharts",path:"/tags/ECharts/"}],cover:"/images/cover/echarts_time_polar.png",date:"2022-07-05T01:00:00.000Z",updated:"2022-07-05T01:00:00.000Z"},{title:"ECharts 标签地图",path:"/post/19a77adb.html",categories:[{name:"作品案例",path:"/categories/作品案例/"}],tags:[{name:"ECharts",path:"/tags/ECharts/"}],cover:"/images/cover/echarts_label_map.png",date:"2021-10-01T01:00:00.000Z",updated:"2021-10-01T01:00:00.000Z"},{title:"ECharts 水球图",path:"/post/51a3160b.html",categories:[{name:"作品案例",path:"/categories/作品案例/"}],tags:[{name:"ECharts",path:"/tags/ECharts/"}],cover:"/images/cover/echarts_liquidfill.png",date:"2022-05-16T01:00:00.000Z",updated:"2022-05-16T01:00:00.000Z"},{title:"ECharts 流程图",path:"/post/b7fd4932.html",categories:[{name:"作品案例",path:"/categories/作品案例/"}],tags:[{name:"ECharts",path:"/tags/ECharts/"}],cover:"/images/cover/echarts_flowchart.png",date:"2022-05-05T01:00:00.000Z",updated:"2022-05-05T01:00:00.000Z"},{title:"ECharts 渐变折线图",path:"/post/68739172.html",categories:[{name:"作品案例",path:"/categories/作品案例/"}],tags:[{name:"ECharts",path:"/tags/ECharts/"}],cover:"/images/cover/echarts_line_gradient.png",date:"2023-03-12T01:00:00.000Z",updated:"2023-03-12T01:00:00.000Z"},{title:"ECharts 热力地图",path:"/post/85c31989.html",categories:[{name:"作品案例",path:"/categories/作品案例/"}],tags:[{name:"ECharts",path:"/tags/ECharts/"}],cover:"/images/cover/echarts_heat_map.png",date:"2021-09-15T01:00:00.000Z",updated:"2021-09-15T01:00:00.000Z"},{title:"ECharts 词云图",path:"/post/f6f4d480.html",categories:[{name:"作品案例",path:"/categories/作品案例/"}],tags:[{name:"ECharts",path:"/tags/ECharts/"}],cover:"/images/cover/echarts_word_cloud.png",date:"2022-05-13T01:00:00.000Z",updated:"2022-05-13T01:00:00.000Z"},{title:"ECharts 迁徙地图",path:"/post/165ef0d3.html",categories:[{name:"作品案例",path:"/categories/作品案例/"}],tags:[{name:"ECharts",path:"/tags/ECharts/"}],cover:"/images/cover/echarts_migration_map.png",date:"2021-10-15T01:00:00.000Z",updated:"2021-10-15T01:00:00.000Z"},{title:"Python 自建 API 合集",path:"/post/ee499a0b.html",categories:[{name:"作品案例",path:"/categories/作品案例/"}],tags:[{name:"Python",path:"/tags/Python/"}],cover:"/images/cover/python_api.jpg",date:"2021-06-07T01:00:00.000Z",updated:"2021-03-08T01:00:00.000Z"},{title:"AARRR 用户运营分析",path:"/post/fa6d499a.html",categories:[{name:"学习笔记",path:"/categories/学习笔记/"}],tags:[{name:"数据分析",path:"/tags/数据分析/"},{name:"PostgreSQL",path:"/tags/PostgreSQL/"}],cover:"/images/cover/aarrr_analysis.png",date:"2022-03-15T02:00:00.000Z",updated:"2022-03-15T02:00:00.000Z"},{title:"ABC 分类法",path:"/post/3e7451d9.html",categories:[{name:"学习笔记",path:"/categories/学习笔记/"}],tags:[{name:"数据分析",path:"/tags/数据分析/"},{name:"PostgreSQL",path:"/tags/PostgreSQL/"}],cover:"/images/cover/abc.png",date:"2022-01-15T02:00:00.000Z",updated:"2022-01-15T02:00:00.000Z"},{title:"HDFS Shell 命令",path:"/post/d1e7dfd3.html",categories:[{name:"学习笔记",path:"/categories/学习笔记/"}],tags:[{name:"大数据",path:"/tags/大数据/"},{name:"Hadoop",path:"/tags/Hadoop/"}],cover:"/images/cover/hdfs_shell.jpg",date:"2021-03-05T02:31:14.000Z",updated:"2021-03-05T02:31:14.000Z"},{title:"JavaScript 实用技巧",path:"/post/ea69450.html",categories:[{name:"学习笔记",path:"/categories/学习笔记/"}],tags:[{name:"JavaScript",path:"/tags/JavaScript/"}],cover:"/images/cover/js_skill.png",date:"2021-12-25T02:00:00.000Z",updated:"2021-12-25T02:00:00.000Z"},{title:"RFM 客户分析模型",path:"/post/97f6661d.html",categories:[{name:"学习笔记",path:"/categories/学习笔记/"}],tags:[{name:"数据分析",path:"/tags/数据分析/"},{name:"PostgreSQL",path:"/tags/PostgreSQL/"}],cover:"/images/cover/rfm.png",date:"2022-01-01T02:00:00.000Z",updated:"2022-01-01T02:00:00.000Z"},{title:"库存周转分析",path:"/post/e305ad56.html",categories:[{name:"学习笔记",path:"/categories/学习笔记/"}],tags:[{name:"数据分析",path:"/tags/数据分析/"},{name:"PostgreSQL",path:"/tags/PostgreSQL/"}],cover:"/images/cover/inventory_turnover_analysis.png",date:"2022-04-01T02:00:00.000Z",updated:"2022-04-01T02:00:00.000Z"},{title:"波士顿矩阵",path:"/post/dd96e05f.html",categories:[{name:"学习笔记",path:"/categories/学习笔记/"}],tags:[{name:"数据分析",path:"/tags/数据分析/"},{name:"PostgreSQL",path:"/tags/PostgreSQL/"}],cover:"/images/cover/bcg_matrix.png",date:"2022-02-01T02:00:00.000Z",updated:"2022-02-01T02:00:00.000Z"},{title:"电商转化漏斗模型",path:"/post/72736a6d.html",categories:[{name:"学习笔记",path:"/categories/学习笔记/"}],tags:[{name:"数据分析",path:"/tags/数据分析/"},{name:"PostgreSQL",path:"/tags/PostgreSQL/"}],cover:"/images/cover/e-commerce_conversion.png",date:"2022-02-15T02:00:00.000Z",updated:"2022-02-15T02:00:00.000Z"},{title:"购物篮分析",path:"/post/931f21f9.html",categories:[{name:"学习笔记",path:"/categories/学习笔记/"}],tags:[{name:"数据分析",path:"/tags/数据分析/"},{name:"PostgreSQL",path:"/tags/PostgreSQL/"}],cover:"/images/cover/basket_analysis.png",date:"2022-03-01T02:00:00.000Z",updated:"2022-03-01T02:00:00.000Z"},{title:"26 个字母 26 句话",path:"/post/32c40e7c.html",categories:[{name:"生活随笔",path:"/categories/生活随笔/"}],tags:[{name:"生活随笔",path:"/tags/生活随笔/"}],cover:"/images/cover/letter_proverb.png",date:"2021-02-12T00:00:00.000Z",updated:"2021-02-12T00:00:00.000Z"},{title:"HTML 特殊符号编码对照表",path:"/post/65795b97.html",categories:[{name:"分享转载",path:"/categories/分享转载/"}],tags:[{name:"HTML",path:"/tags/HTML/"},{name:"文档",path:"/tags/文档/"}],cover:"/images/cover/html_symbols.jpg",date:"2021-03-12T07:54:12.000Z",updated:"2021-03-12T07:54:12.000Z"},{title:"特殊符号",path:"/post/73bb9016.html",categories:[{name:"分享转载",path:"/categories/分享转载/"}],tags:[{name:"文档",path:"/tags/文档/"}],cover:"/images/cover/special_symbols.jpg",date:"2021-03-10T02:23:12.000Z",updated:"2021-03-10T02:23:12.000Z"},{title:"Flume 面试题解析",path:"/post/5a2a12a6.html",categories:[{name:"面试系列",path:"/categories/面试系列/"}],tags:[{name:"大数据",path:"/tags/大数据/"},{name:"Flume",path:"/tags/Flume/"}],cover:"/images/cover/bigdata_interview.png",date:"2021-03-29T01:00:00.000Z",updated:"2021-03-29T01:00:00.000Z"},{title:"Java 面试题解析",path:"/post/d2aef718.html",categories:[{name:"面试系列",path:"/categories/面试系列/"}],tags:[{name:"Java",path:"/tags/Java/"}],cover:"/images/cover/java_interview.jpg",date:"2021-03-15T01:00:00.000Z",updated:"2021-03-15T01:00:00.000Z"},{title:"Java 面试题解析（IO流）",path:"/post/af128a42.html",categories:[{name:"面试系列",path:"/categories/面试系列/"}],tags:[{name:"Java",path:"/tags/Java/"}],cover:"/images/cover/java_interview.jpg",date:"2021-03-19T01:00:00.000Z",updated:"2021-03-19T01:00:00.000Z"},{title:"Java 面试题解析（反射）",path:"/post/9fbf7373.html",categories:[{name:"面试系列",path:"/categories/面试系列/"}],tags:[{name:"Java",path:"/tags/Java/"}],cover:"/images/cover/java_interview.jpg",date:"2021-03-21T01:00:00.000Z",updated:"2021-03-21T01:00:00.000Z"},{title:"Java 面试题解析（容器）",path:"/post/d07acd09.html",categories:[{name:"面试系列",path:"/categories/面试系列/"}],tags:[{name:"Java",path:"/tags/Java/"}],cover:"/images/cover/java_interview.jpg",date:"2021-03-17T01:00:00.000Z",updated:"2021-03-17T01:00:00.000Z"},{title:"Sqoop 面试题解析",path:"/post/420614eb.html",categories:[{name:"面试系列",path:"/categories/面试系列/"}],tags:[{name:"大数据",path:"/tags/大数据/"},{name:"Sqoop",path:"/tags/Sqoop/"}],cover:"/images/cover/bigdata_interview.png",date:"2021-04-13T01:00:00.000Z",updated:"2021-04-13T01:00:00.000Z"},{title:"Zookeeper 面试题解析",path:"/post/2f1ea7f2.html",categories:[{name:"面试系列",path:"/categories/面试系列/"}],tags:[{name:"大数据",path:"/tags/大数据/"},{name:"Zookeeper",path:"/tags/Zookeeper/"}],cover:"/images/cover/bigdata_interview.png",date:"2021-03-27T01:00:00.000Z",updated:"2021-03-27T01:00:00.000Z"},{title:"大数据面试题解析",path:"/post/7e24cf66.html",categories:[{name:"面试系列",path:"/categories/面试系列/"}],tags:[{name:"大数据",path:"/tags/大数据/"},{name:"Hadoop",path:"/tags/Hadoop/"},{name:"Flume",path:"/tags/Flume/"},{name:"Sqoop",path:"/tags/Sqoop/"},{name:"Zookeeper",path:"/tags/Zookeeper/"},{name:"Kafka",path:"/tags/Kafka/"},{name:"Hive",path:"/tags/Hive/"},{name:"HBase",path:"/tags/HBase/"},{name:"MySQL",path:"/tags/MySQL/"},{name:"Spark",path:"/tags/Spark/"}],cover:"/images/cover/bigdata_interview.png",date:"2021-03-25T01:00:00.000Z",updated:"2021-03-25T01:00:00.000Z"},{title:"Butterffly 分类页和标签页隐藏侧栏",path:"/post/d498d8b1.html",categories:[{name:"魔改教程",path:"/categories/魔改教程/"}],tags:[{name:"Hexo",path:"/tags/Hexo/"},{name:"Butterfly",path:"/tags/Butterfly/"}],cover:"/images/cover/butterfly_hide_side.png",date:"2022-07-20T01:00:00.000Z",updated:"2022-08-04T01:00:00.000Z"},{title:"Butterfly Twikoo 评论热评",path:"/post/364efc10.html",categories:[{name:"魔改教程",path:"/categories/魔改教程/"}],tags:[{name:"Hexo",path:"/tags/Hexo/"},{name:"Butterfly",path:"/tags/Butterfly/"}],cover:"/images/cover/twikoo_comment_barrage.png",date:"2022-09-13T01:00:00.000Z",updated:"2022-09-13T01:00:00.000Z"},{title:"Butterfly 分类标签导航栏",path:"/post/65b72006.html",categories:[{name:"魔改教程",path:"/categories/魔改教程/"}],tags:[{name:"Hexo",path:"/tags/Hexo/"},{name:"Butterfly",path:"/tags/Butterfly/"}],cover:"/images/post/butterfly/butterfly_categories_list.png",date:"2022-05-23T02:00:00.000Z",updated:"2023-03-21T02:00:00.000Z"},{title:"Butterfly 分类标签归档页增加文章索引",path:"/post/27df86b.html",categories:[{name:"魔改教程",path:"/categories/魔改教程/"}],tags:[{name:"Hexo",path:"/tags/Hexo/"},{name:"Butterfly",path:"/tags/Butterfly/"}],cover:"/images/cover/butterfly_post_index_eurkon.png",date:"2022-07-28T01:00:00.000Z",updated:"2022-07-28T01:00:00.000Z"},{title:"Butterfly 微博热搜侧边栏",path:"/post/38b005e1.html",categories:[{name:"魔改教程",path:"/categories/魔改教程/"}],tags:[{name:"Hexo",path:"/tags/Hexo/"},{name:"Butterfly",path:"/tags/Butterfly/"}],cover:"/images/cover/butterfly_weibo.jpg",date:"2021-06-03T01:00:00.000Z",updated:"2023-03-20T01:00:00.000Z"},{title:"Butterfly 推荐文章增加文章描述",path:"/post/3d2664bb.html",categories:[{name:"魔改教程",path:"/categories/魔改教程/"}],tags:[{name:"Hexo",path:"/tags/Hexo/"},{name:"Butterfly",path:"/tags/Butterfly/"}],cover:"/images/cover/butterfly_related_post.png",date:"2022-08-16T02:00:00.000Z",updated:"2022-08-16T02:00:00.000Z"},{title:"Butterfly 文章增加段落序号",path:"/post/70e521c2.html",categories:[{name:"魔改教程",path:"/categories/魔改教程/"}],tags:[{name:"Hexo",path:"/tags/Hexo/"},{name:"Butterfly",path:"/tags/Butterfly/"}],cover:"/images/cover/butterfly_toc_number.png",date:"2022-10-31T01:00:00.000Z",updated:"2022-10-31T01:00:00.000Z"},{title:"Butterfly 标签云增加文章数上下标",path:"/post/6687849c.html",categories:[{name:"魔改教程",path:"/categories/魔改教程/"}],tags:[{name:"Hexo",path:"/tags/Hexo/"},{name:"Butterfly",path:"/tags/Butterfly/"}],cover:"/images/cover/butterfly_tags_cloud.png",date:"2021-07-15T01:00:00.000Z",updated:"2021-07-15T01:00:00.000Z"},{title:"Front-matter",path:"/post/31e4c77c.html",categories:[{name:"魔改教程",path:"/categories/魔改教程/"}],tags:[{name:"Hexo",path:"/tags/Hexo/"},{name:"Butterfly",path:"/tags/Butterfly/"}],cover:"/images/cover/hexo.png",date:"2021-01-02T13:59:56.000Z",updated:"2021-01-02T13:59:56.000Z"},{title:"Hello Hexo",path:"/post/a1751c09.html",categories:[{name:"魔改教程",path:"/categories/魔改教程/"}],tags:[{name:"Hexo",path:"/tags/Hexo/"}],cover:"/images/cover/hexo.png",date:"2021-01-01T00:00:00.000Z",updated:"2021-01-01T00:00:00.000Z"},{title:"在 Hexo 中插入 Chart 动态图表",path:"/post/a6e75a2b.html",categories:[{name:"魔改教程",path:"/categories/魔改教程/"}],tags:[{name:"Hexo",path:"/tags/Hexo/"}],cover:"/images/cover/hexo_chartjs.svg",date:"2021-01-04T01:38:32.000Z",updated:"2021-01-04T01:38:32.000Z"},{title:"ECharts 地图上显示折线图",path:"/post/e83030eb.html",categories:[{name:"作品案例",path:"/categories/作品案例/"}],tags:[{name:"ECharts",path:"/tags/ECharts/"}],cover:"/images/cover/echarts_map_line.png",date:"2021-11-20T01:00:00.000Z",updated:"2021-11-20T01:00:00.000Z"},{title:"ECharts 生涯彩虹图",path:"/post/553238e8.html",categories:[{name:"作品案例",path:"/categories/作品案例/"}],tags:[{name:"ECharts",path:"/tags/ECharts/"}],cover:"/images/cover/echarts_career.png",date:"2022-11-06T01:00:00.000Z",updated:"2022-11-06T01:00:00.000Z"},{title:"Git 使用教程",path:"/post/c3cf24c7.html",categories:[{name:"学习笔记",path:"/categories/学习笔记/"}],tags:[{name:"Git",path:"/tags/Git/"}],cover:"/images/cover/git.png",date:"2021-02-21T05:16:02.000Z",updated:"2021-02-21T05:16:02.000Z"},{title:"Linux 常用命令",path:"/post/817c7d82.html",categories:[{name:"学习笔记",path:"/categories/学习笔记/"}],tags:[{name:"Linux",path:"/tags/Linux/"}],cover:"/images/cover/linux_command.png",date:"2021-04-19T01:00:00.000Z",updated:"2021-04-19T01:00:00.000Z"},{title:"Markdown 基本语法",path:"/post/c894e39a.html",categories:[{name:"学习笔记",path:"/categories/学习笔记/"}],tags:[{name:"Markdown",path:"/tags/Markdown/"}],cover:"/images/cover/markdown_grammar.jpg",date:"2021-01-03T06:14:53.000Z",updated:"2021-01-03T06:14:53.000Z"},{title:"MySQL 优化",path:"/post/d7961cf0.html",categories:[{name:"学习笔记",path:"/categories/学习笔记/"}],tags:[{name:"大数据",path:"/tags/大数据/"},{name:"MySQL",path:"/tags/MySQL/"}],cover:"/images/cover/mysql_optimization.jpg",date:"2021-01-14T05:32:11.000Z",updated:"2021-01-14T05:32:11.000Z"},{title:"MySQL 常用命令行",path:"/post/4bd4f98e.html",categories:[{name:"学习笔记",path:"/categories/学习笔记/"}],tags:[{name:"大数据",path:"/tags/大数据/"},{name:"MySQL",path:"/tags/MySQL/"}],cover:"/images/cover/mysql_command.png",date:"2021-01-13T01:24:44.000Z",updated:"2021-01-13T01:24:44.000Z"},{title:"R 语言图表",path:"/post/b35ac98a.html",categories:[{name:"学习笔记",path:"/categories/学习笔记/"}],tags:[{name:"大数据",path:"/tags/大数据/"},{name:"R",path:"/tags/R/"}],cover:"/images/cover/r_chart.jpg",date:"2021-01-20T08:04:45.000Z",updated:"2021-01-20T08:04:45.000Z"},{title:"排序算法",path:"/post/735e5788.html",categories:[{name:"学习笔记",path:"/categories/学习笔记/"}],tags:[{name:"算法",path:"/tags/算法/"}],cover:"/images/cover/sort_algorithm.jpg",date:"2021-03-13T05:16:02.000Z",updated:"2021-03-13T05:16:02.000Z"},{title:"数仓设计与 ETL 规范",path:"/post/1c85bfc3.html",categories:[{name:"学习笔记",path:"/categories/学习笔记/"}],tags:[{name:"文档",path:"/tags/文档/"},{name:"数据仓库",path:"/tags/数据仓库/"}],cover:"/images/cover/etl_norm.png",date:"2022-12-31T02:00:00.000Z",updated:"2022-12-31T02:00:00.000Z"},{title:"Elasticsearch 面试题解析",path:"/post/fae3ec89.html",categories:[{name:"面试系列",path:"/categories/面试系列/"}],tags:[{name:"大数据",path:"/tags/大数据/"},{name:"Elasticsearch",path:"/tags/Elasticsearch/"}],cover:"/images/cover/bigdata_interview.png",date:"2021-06-25T01:00:00.000Z",updated:"2021-06-25T01:00:00.000Z"},{title:"HBase 面试题解析",path:"/post/47457d03.html",categories:[{name:"面试系列",path:"/categories/面试系列/"}],tags:[{name:"大数据",path:"/tags/大数据/"},{name:"HBase",path:"/tags/HBase/"}],cover:"/images/cover/bigdata_interview.png",date:"2021-04-02T01:00:00.000Z",updated:"2021-04-02T01:00:00.000Z"},{title:"Hive 面试题解析",path:"/post/62c9bbde.html",categories:[{name:"面试系列",path:"/categories/面试系列/"}],tags:[{name:"大数据",path:"/tags/大数据/"},{name:"Hive",path:"/tags/Hive/"}],cover:"/images/cover/bigdata_interview.png",date:"2021-03-31T01:00:00.000Z",updated:"2021-03-31T01:00:00.000Z"},{title:"Java 面试题解析（并发）",path:"/post/32cf50db.html",categories:[{name:"面试系列",path:"/categories/面试系列/"}],tags:[{name:"Java",path:"/tags/Java/"}],cover:"/images/cover/java_interview.jpg",date:"2021-03-18T01:00:00.000Z",updated:"2021-03-18T01:00:00.000Z"},{title:"Java 面试题解析（数据库）",path:"/post/73adfcb0.html",categories:[{name:"面试系列",path:"/categories/面试系列/"}],tags:[{name:"Java",path:"/tags/Java/"}],cover:"/images/cover/java_interview.jpg",date:"2021-03-20T01:00:00.000Z",updated:"2021-03-20T01:00:00.000Z"},{title:"Java 面试题解析（设计模式）",path:"/post/1cfbd3b3.html",categories:[{name:"面试系列",path:"/categories/面试系列/"}],tags:[{name:"Java",path:"/tags/Java/"}],cover:"/images/cover/java_interview.jpg",date:"2021-03-21T04:00:00.000Z",updated:"2021-03-21T04:00:00.000Z"},{title:"Kafka 面试题解析",path:"/post/89cabcb1.html",categories:[{name:"面试系列",path:"/categories/面试系列/"}],tags:[{name:"大数据",path:"/tags/大数据/"},{name:"Kafka",path:"/tags/Kafka/"}],cover:"/images/cover/bigdata_interview.png",date:"2021-03-30T01:00:00.000Z",updated:"2021-03-30T01:00:00.000Z"},{title:"Hexo 博客实时访问统计图",path:"/post/61763977.html",categories:[{name:"魔改教程",path:"/categories/魔改教程/"}],tags:[{name:"ECharts",path:"/tags/ECharts/"},{name:"Hexo",path:"/tags/Hexo/"}],cover:"/images/cover/hexo.png",date:"2021-05-17T01:00:00.000Z",updated:"2022-03-29T01:00:00.000Z"},{title:"Hexo 博客访问日历图",path:"/post/1a169b5a.html",categories:[{name:"魔改教程",path:"/categories/魔改教程/"}],tags:[{name:"Hexo",path:"/tags/Hexo/"}],cover:"/images/cover/hexo.png",date:"2021-05-17T04:00:00.000Z",updated:"2022-03-29T04:00:00.000Z"},{title:"Hexo 博客访问统计图（弃用）",path:"/post/ef1da941.html",categories:[{name:"魔改教程",path:"/categories/魔改教程/"}],tags:[{name:"ECharts",path:"/tags/ECharts/"},{name:"Hexo",path:"/tags/Hexo/"}],cover:"/images/cover/hexo.png",date:"2021-04-01T04:00:00.000Z",updated:"2022-03-29T01:00:00.000Z"},{title:"在 Hexo 中插入 ECharts 动态图表",path:"/post/6f565d8c.html",categories:[{name:"魔改教程",path:"/categories/魔改教程/"}],tags:[{name:"ECharts",path:"/tags/ECharts/"},{name:"Hexo",path:"/tags/Hexo/"}],cover:"/images/cover/hexo_echarts.png",date:"2021-01-05T03:51:01.000Z",updated:"2021-01-05T03:51:01.000Z"},{title:"ECharts 流域图",path:"/post/364f4c67.html",categories:[{name:"作品案例",path:"/categories/作品案例/"}],tags:[{name:"ECharts",path:"/tags/ECharts/"}],cover:"/images/cover/echarts_river.png",date:"2022-05-10T01:00:00.000Z",updated:"2022-05-10T01:00:00.000Z"},{title:"R 语言数据接口",path:"/post/996a1090.html",categories:[{name:"学习笔记",path:"/categories/学习笔记/"}],tags:[{name:"大数据",path:"/tags/大数据/"},{name:"R",path:"/tags/R/"}],cover:"/images/cover/r_data_interface.png",date:"2021-01-21T05:52:32.000Z",updated:"2021-01-21T05:52:32.000Z"},{title:"R 语言统计分析",path:"/post/741c153c.html",categories:[{name:"学习笔记",path:"/categories/学习笔记/"}],tags:[{name:"大数据",path:"/tags/大数据/"},{name:"R",path:"/tags/R/"}],cover:"/images/cover/r_statistics.jpg",date:"2021-01-22T02:10:41.000Z",updated:"2021-01-22T02:10:41.000Z"},{title:"Emoji 表情大全",path:"/post/f349e1f0.html",categories:[{name:"分享转载",path:"/categories/分享转载/"}],tags:[{name:"文档",path:"/tags/文档/"}],cover:"/images/cover/emoji.png",date:"2021-06-22T01:00:00.000Z",updated:"2021-06-22T01:00:00.000Z"},{title:"Hadoop 面试题解析",path:"/post/2b822834.html",categories:[{name:"面试系列",path:"/categories/面试系列/"}],tags:[{name:"大数据",path:"/tags/大数据/"},{name:"Hadoop",path:"/tags/Hadoop/"}],cover:"/images/cover/bigdata_interview.png",date:"2021-03-26T01:00:00.000Z",updated:"2021-03-26T01:00:00.000Z"},{title:"MySQL 面试题解析",path:"/post/54dbb40b.html",categories:[{name:"面试系列",path:"/categories/面试系列/"}],tags:[{name:"大数据",path:"/tags/大数据/"},{name:"MySQL",path:"/tags/MySQL/"}],cover:"/images/cover/bigdata_interview.png",date:"2021-04-14T01:00:00.000Z",updated:"2021-04-14T01:00:00.000Z"},{title:"Hexo 博客文章统计图",path:"/post/1213ef82.html",categories:[{name:"魔改教程",path:"/categories/魔改教程/"}],tags:[{name:"ECharts",path:"/tags/ECharts/"},{name:"Hexo",path:"/tags/Hexo/"}],cover:"/images/cover/hexo.png",date:"2021-04-01T01:00:00.000Z",updated:"2022-08-15T01:00:00.000Z"},{title:"Spark RDD 常用算子",path:"/post/c55e5115.html",categories:[{name:"学习笔记",path:"/categories/学习笔记/"}],tags:[{name:"大数据",path:"/tags/大数据/"},{name:"Spark",path:"/tags/Spark/"}],cover:"/images/cover/spark_rdd.jpg",date:"2021-05-07T01:00:00.000Z",updated:"2021-05-07T01:00:00.000Z"},{title:"Java 面试题解析（Java Web）",path:"/post/d24a315e.html",categories:[{name:"面试系列",path:"/categories/面试系列/"}],tags:[{name:"Java",path:"/tags/Java/"}],cover:"/images/cover/java_interview.jpg",date:"2021-03-22T01:00:00.000Z",updated:"2021-03-22T01:00:00.000Z"},{title:"Java 面试题解析（基础）",path:"/post/11ea51ea.html",categories:[{name:"面试系列",path:"/categories/面试系列/"}],tags:[{name:"Java",path:"/tags/Java/"}],cover:"/images/cover/java_interview.jpg",date:"2021-03-16T01:00:00.000Z",updated:"2021-03-16T01:00:00.000Z"},{title:"Spark 面试题解析",path:"/post/cccf27af.html",categories:[{name:"面试系列",path:"/categories/面试系列/"}],tags:[{name:"大数据",path:"/tags/大数据/"},{name:"Spark",path:"/tags/Spark/"}],cover:"/images/cover/bigdata_interview.png",date:"2021-05-26T01:00:00.000Z",updated:"2021-05-26T01:00:00.000Z"},{title:"R 语言教程",path:"/post/de0e67e.html",categories:[{name:"学习笔记",path:"/categories/学习笔记/"}],tags:[{name:"大数据",path:"/tags/大数据/"},{name:"R",path:"/tags/R/"}],cover:"/images/cover/r_course.png",date:"2021-01-18T08:20:11.000Z",updated:"2021-01-18T08:20:11.000Z"},{title:"Hive SQL 大全",path:"/post/7891b2e6.html",categories:[{name:"学习笔记",path:"/categories/学习笔记/"}],tags:[{name:"大数据",path:"/tags/大数据/"},{name:"Hive",path:"/tags/Hive/"}],cover:"/images/cover/hive.jpg",date:"2021-04-07T01:00:00.000Z",updated:"2021-04-07T01:00:00.000Z"},{title:"大数据精选清单",path:"/post/fc3d946f.html",categories:[{name:"学习笔记",path:"/categories/学习笔记/"}],tags:[{name:"大数据",path:"/tags/大数据/"},{name:"文档",path:"/tags/文档/"}],cover:"/images/cover/bigdata_list.jpg",date:"2021-01-07T02:35:46.000Z",updated:"2021-01-07T02:35:46.000Z"},{title:"Java 面试题解析（Java EE）",path:"/post/dc04fa32.html",categories:[{name:"面试系列",path:"/categories/面试系列/"}],tags:[{name:"Java",path:"/tags/Java/"}],cover:"/images/cover/java_interview.jpg",date:"2021-03-23T01:00:00.000Z",updated:"2021-03-23T01:00:00.000Z"},{title:"MySQL 教程",path:"/post/7f59cefa.html",categories:[{name:"学习笔记",path:"/categories/学习笔记/"}],tags:[{name:"大数据",path:"/tags/大数据/"},{name:"MySQL",path:"/tags/MySQL/"}],cover:"/images/cover/mysql_course.jpg",date:"2021-01-09T02:35:46.000Z",updated:"2021-01-09T02:35:46.000Z"}];function toRandomPost(){window.pjax?pjax.loadUrl(posts[Math.floor(Math.random()*posts.length)].path):window.open(posts[Math.floor(Math.random()*posts.length)].path,"_self")}</script><script>var flinks=[{name:"Eurkon",link:"https://blog.eurkon.com",avatar:"https://blog.eurkon.com/images/user/avatar.jpg",descr:"及时当勉励，岁月不待人。"},{name:"MYW",link:"https://crazywong.com/",avatar:"https://crazywong.com/img/avatar.png",descr:"今日事,今日毕"},{name:"Akilar",link:"https://akilar.top/",avatar:"https://npm.elemecdn.com/akilar-friends@latest/avatar/akilar.top.jpg",descr:"期待您的光临！",siteshot:null},{name:"小冰博客",link:"https://zfe.space",avatar:"https://zfe.space/images/headimage.png",descr:"做个有梦想的人！"},{name:"Heo",link:"https://blog.zhheo.com/",avatar:"https://blog.zhheo.com/img/avatar.png",descr:"爱折腾的设计师"},{name:"Leonus",link:"https://blog.leonus.cn/",avatar:"https://q1.qlogo.cn/g?b=qq&nk=553344777&s=5",descr:"进一寸有进一寸的欢喜。"},{name:"Maxbit",link:"https://cakepanit.com/",avatar:"https://cakepanit.com/img/avatar.jpg",descr:"寻找属于自己的彩虹海",siteshot:"https://fastly.jsdelivr.net/gh/zhangyazhuang/cdn/img/bei.jpg"},{name:"FF",link:"https://foolishfox.cn/",avatar:"https://asset.foolishfox.cn/static/avatar.jpg",descr:"foolish fox"},{name:"Harris",link:"https://blog.harriswong.top/",avatar:"https://cdn.jsdelivr.net/npm/hassan-assets/img/avatar_blog.jpg",descr:"时不我待，只争朝夕"},{name:"Tianli",link:"https://tianli-blog.club",avatar:"https://q2.qlogo.cn/headimg_dl?dst_uin=507249007&spec=640",descr:"惟其不可能，所以才相信。"},{name:"慕木",link:"https://iori-yimaga.top",avatar:"https://avatars.githubusercontent.com/u/33000237?v=4",descr:"当程序运行的那一刻，我知道是编译器对我的温柔",siteshot:"https://fastly.jsdelivr.net/gh/Iori-yimaga/ScreenShot@gh-pages/iori-yimaga.top.jpg"},{name:"沐印小站",link:"https://c.undf.top/",avatar:"https://c.undf.top/icon/android-chrome-144x144.png",descr:"时间不在于你拥有多少，而在于你如何使用!"},{name:"MJ",link:"https://blog.justlovesmile.top",avatar:"https://blog.justlovesmile.top/img/avatar.jpg",descr:"醒亦念卿，梦亦念卿"},{name:"Gahotx",link:"https://gahotx.cn/",avatar:"https://pub.gahotx.cn/photo/cat.jpg",descr:"Don’t repeat yourself"},{name:"小孙同学",link:"https://blog.sunguoqi.com/",avatar:"https://blog.sunguoqi.com/images/avatar.jpg",descr:"热爱可抵漫长岁月！"},{name:"星空下的YZY",link:"https://226yzy.com",avatar:"https://226yzy.com/medias/avatar.jpg",descr:"记录一枚菜鸟的征程"},{name:"DoraKika",link:"https://blog.dorakika.cn",avatar:"https://thirdqq.qlogo.cn/g?b=sdk&nk=1633198089&s=140",descr:"热爱漫无边际，生活自有分寸！"},{name:"ImCaO",link:"https://www.imcao.cn",avatar:"https://www.imcao.cn/avatar.png",descr:"花有重开日，人无再少年。"},{name:"btwoa",link:"https://blog.btwoa.com",avatar:"https://ovo.btwoa.com/img/gif/btwoa.gif",descr:"我仍相信人间滚烫"},{name:"小曹同学",link:"https://cgq.suduhulian.top/",avatar:"http://q1.qlogo.cn/g?b=qq&nk=3514332263&s=640",descr:"一个学Py的人"},{name:"欢乐小王",link:"https://happyking.top/",avatar:"https://happyking.top/img/avatar.gif",descr:"聚散无常,别来无恙."},{name:"EmoryHuang",link:"https://emoryhuang.cn/",avatar:"https://static.emoryhuang.cn/img/emoryhuang-avatar.png",descr:"Learning everything"},{name:"LanYun",link:"https://lanyundev.com/",avatar:"https://lanyundev.com/img/logo.jpg.webp",descr:"Share Technology."},{name:"Bore",link:"https://bore.vip",avatar:"https://bore.vip/img/avatar.jpg",descr:"博观而约取，厚积而薄发。"},{name:"JayHrn",link:"https://blog.lvhrn.cn/",avatar:"https://npm.onmicrosoft.cn/hrn-img@1.0.0/img/avatar.jpg",descr:"念念不忘，必有回响"},{name:"枫叶",link:"https://blog.aqcoder.cn",avatar:"https://blog.aqcoder.cn/img/avatar.png",descr:"分享知识，认识世界"},{name:"liferecords",link:"https://nav.liferecords.top/",avatar:"https://cdn.liferecords.top/person/logo.jpg",descr:"从私域转到公域的助益者"},{name:"Fomalhaut🥝",link:"https://www.fomal.cc/",avatar:"https://www.fomal.cc/assets/avatar.webp",descr:"Future is now 🍭🍭🍭",siteshot:"https://source.fomal.cc/siteshot/www.fomal.cc.webp"},{name:"Mycpen",link:"https://blog.cpen.top/",avatar:"https://image.cpen.top/image/avatar.jpg",descr:"这是一个有趣的博客"},{name:"小城故事",link:"https://www.webxc.ml/",avatar:"https://npm.elemecdn.com/webxc/logo/logo.jpg",descr:"欢迎光临小城故事!"},{name:"Xlenco",link:"https://xlenco.eu.org",avatar:"https://ik.imagekit.io/nicexl/head.jpg",descr:"最好的地方是没去过的地方，最好的时光，是回不来的时光。"},{name:"ichika",link:"https://ichika.cc",avatar:"https://ichika.cc/img/Page/HeadIcon.jpg",descr:"Hello,gamer!",siteshot:"https://cos.ichika.cc/link/ichikashot.png"},{name:"九九九感冒绫",link:"https://miku-39.love/",avatar:"https://s2.loli.net/2022/10/18/soq82lvxakjeHB1.jpg",descr:"这是我的梦想,我会慢慢的完成它",siteshot:"https://s2.loli.net/2022/10/18/9KaSTU7OrWHkyEq.png"},{name:"丘卡饮品店",link:"https://blog.zerolacqua.top",avatar:"https://unpkg.com/zerolacqua-assets/images/avatar.png",descr:"要来点喝的吗？"},{name:"张时贰",link:"https://zhsher.cn",avatar:"https://q1.qlogo.cn/g?b=qq&nk=1310446718&s=5",descr:"环转码，爱敲代码的小张！"},{name:"Heyiki",link:"https://www.heyiki.top",avatar:"https://npm.elemecdn.com/heyiki-cdn/img/1.jpg",descr:"梦在旅途，永不止步。"},{name:"小华同学927",link:"https://blog.xiaohua927.top/",avatar:"https://i.imgtg.com/2022/12/01/DM501.jpg",descr:"行而不辍，未来可期！"},{name:"竹山一叶",link:"https://zsyyblog.com",avatar:"https://img.zsyyblog.com/favicon.jpg",descr:"来了就不想走的小家"},{name:"云野生SRE",link:"https://www.xadocker.cn",avatar:"https://www.xadocker.cn/wp-content/uploads/2022/04/2082e818343d236c1e5268eae30480bb-96x96.jpeg",descr:"云野生SRE"},{name:"SLOVER",link:"https://678777.xyz",avatar:"https://s1.vika.cn/space/2022/11/06/9e4c4d54cff74c70b1a4abe37d4bd6e8",descr:"诱导已亮，前方净空，祝君武运昌隆",siteshot:"https://s1.vika.cn/space/2023/01/03/ed2f8872abc64ea18af2fbbd6a1120c7"},{name:"ReCclay🖥️",link:"https://www.recclay.cc/",siteshot:"https://www.recclay.cc/img/2023-01-02.png",avatar:"https://www.recclay.cc/img/recclay.png",descr:"芯片硅农，别忘无恙🧐"},{name:"Shine",link:"https://blog.shineyu.cn/",avatar:"https://s3.bmp.ovh/imgs/2022/11/23/129c19d56d22c637.png",descr:"Let’s go! Target: The Vast Stars!",siteshot:"https://s3.bmp.ovh/imgs/2022/12/28/fe2452f7c4ff48ee.png"},{name:"小码博客",link:"https://blog.hikki.site",avatar:"https://bu.dusays.com/2022/11/04/636511250b21b.jpg",descr:"喜欢的东西就努力去追求，万一成功了呢!"},{name:"南方嘉木",link:"https://gavin-chen.top/",avatar:"https://i.imgtg.com/2023/01/06/GZRKN.jpg",descr:"不畏将来, 不念过往。"},{name:"Prong",link:"https://prong.ltd",avatar:"https://prong-1316442664.cos.ap-nanjing.myqcloud.com/picgo/202301242359645.webp",descr:"尖头叉子在霍格沃茨的休息室~",siteshot:"https://prong-1316442664.cos.ap-nanjing.myqcloud.com/picgo/202301252110840.webp"},{name:"满心记",link:"https://blog.lovelu.top",avatar:"https://cdn.lovelu.top/img/logo.png",descr:"追求让人充实，分享让人快乐"},{name:"怕冷爱上雪",link:"https://blog.4t.pw/",avatar:"https://blog.4t.pw/img/favicon.webp",descr:"千里之行，始于足下。"},{name:"雷雷屋头",link:"https://ll.sc.cn",avatar:"https://ll.sc.cn/img/avatar.png",descr:"爱生活，爱工作，爱折腾。",siteshot:"https://ll.sc.cn/img/siteshot.webp"},{name:"小吉崽汁の窝",link:"https://wuxingzzz.top",avatar:"https://www.wuxingzzz.top/hexo/IMG_3969.JPG",siteshot:"https://www.wuxingzzz.top/article/1592180893591904258.jpg",descr:"A programmer of vegetable chicken"},{name:"龙儿之家",link:"https://blog.huangge1199.cn",avatar:"https://blog.huangge1199.cn/upload/favicon.png",descr:"一个热衷于做小码农的程序媛！！！"},{name:"小朋同学",link:"https://blog.vip88.email",avatar:"https://blog.vip88.email/img/default_avatar.webp",descr:"朝着诗和远方慢慢走去",siteshot:"https://img.vip88.email/img/999.png"},{name:"王同学",link:"https://demo.wxz666.icu/",avatar:"http://www.wxz666.icu/img/favicon.ico.jpg",descr:"须知少时凌云志，曾许人间第一流"},{name:"李程ic",link:"https://www.licic.net/",avatar:"https://admin.licic.net/favicon.png",descr:"坚持很难；但是很酷！",siteshot:"https://admin.licic.net/screenshot.png"},{name:"回忆航线",link:"https://moony.la/",avatar:"https://moony.la/upload/logo.png",descr:"喜欢捣鼓的博主"},{name:"爱吃肉的猫",link:"https://meuicat.com/",avatar:"https://s1.ax1x.com/2023/05/26/p9qChjI.jpg",descr:"有肉有猫有生活."},{name:"虎了吧唧",link:"https://hulebaji.me",avatar:"https://cravatar.cn/avatar/c126bb295caa6f29cbbd32083708cda4?d=identicon",descr:"研墨成浆，提笔思量"},{name:"毕少侠",link:"https://hexo.geekswg.top/",avatar:"https://hexo.geekswg.top/imgs/avatar.webp",descr:"毕少侠也在江湖",siteshot:"https://hexo.geekswg.top/imgs/default-cover.webp"},{name:"猫四叔",link:"https://blog.hieroglyphs.top/",avatar:"https://npm.elemecdn.com/hieroglyphs.files/images/others/logo.png",descr:"一生俯首拜阳明"},{name:"铭心石刻",link:"https://blog.kouseki.cn/",avatar:"https://blog.kouseki.cn/imgs/avatar.webp",descr:"愿岁并谢，与友长兮"},{name:"xhang",link:"https://xhablog.online/",avatar:"https://i.postimg.cc/VNTPknVj/avatar.webp",descr:"一切都值得期待"},{name:"海拥",link:"https://haiyong.site",avatar:"https://haiyong.site/img/favicon.png",descr:"一枚乐于分享技术与快乐的博主"},{name:"虹色轨迹🌠",link:"https://ovoz.cn",avatar:"https://ovoz.cn/assets/avatar.webp",descr:"做一颗星星，有棱有角，黑暗中闪闪发光🍭🍭🍭",siteshot:"https://ovoz.cn/assets/ovoz.cn.jpg"},{name:"SuYi-宿仪",link:"https://www.thotz.top/",avatar:"https://pic.imgdb.cn/item/6497c3401ddac507ccd9334c.jpg",descr:"随心写作，随缘阅读"},{name:"神经蛙",link:"https://hexo.sjava.cn/",avatar:"https://hexo.sjava.cn/img/pic.png",descr:"种一棵树最好的时间是十年前，其次是现在。",siteshot:"https://hexo.sjava.cn/img/sjw.png"},{name:"小嗷犬的技术小站",link:"https://blog.marquis.eu.org/",avatar:"https://blog.marquis.eu.org/img/avatar/2.png",descr:"为天地立心，为生民立命，为往圣继绝学，为万世开太平"},{name:"Cisyam",link:"https://manamn.space/",avatar:"https://gaoziman.oss-cn-hangzhou.aliyuncs.com/img/202307151545455.jpg",descr:"分享思想，留下痕迹",siteshot:"https://gaoziman.oss-cn-hangzhou.aliyuncs.com/img/202307151545874.png"},{name:"杀死一只知更鸟",link:"https://www.shangjidong.com",avatar:"https://www.shangjidong.com/usr/uploads/2023/07/1002399499.gif",descr:"前端技术分享、前端学习记录"},{name:"棋の小站",link:"https://blog.qi1.zone/",avatar:"https://blog.qi1.zone/avatar.png",descr:"记录生活与心得。"},{name:"qxdn",link:"https://qianxu.run",avatar:"https://qianxu.run/images/avatar.jpg",descr:"蓬生麻中，不扶自直"},{name:"阳小楊",link:"https://blog.yxyang.top",avatar:"https://pic.imgdb.cn/item/65708f75c458853aefa8c951.jpg",descr:"无人了解你的灵魂．",siteshot:"https://pic.imgdb.cn/item/65709596c458853aefc6469c.png"},{name:"云深不知处",link:"https://www.lanzlz.cn",avatar:"https://oss.lanzlz.cn/private/hIwTot.png",descr:"不食人间烟火 且饮半杯风霜"},{name:"虹色轨迹🌠",link:"https://dil.illlli.com",avatar:"https://dil.illlli.com/assets/avatar.webp",descr:"做一颗星星，有棱有角，黑暗中闪闪发光🍭🍭🍭",siteshot:"https://dil.illlli.com/assets/dil.webp"},{name:"小鹿",link:"https://siena.zone",avatar:"https://siena.zone/favicon_compressed.png",descr:"跳吧，在无比宏大的星系！"},{name:"Calyee",link:"https://blog.calyee.top/",avatar:"https://blog.calyee.top/img/avatar.jpg",descr:"追求充实，分享快乐",siteshot:"https://blog.calyee.top/img/siteshot.png"},{name:"琅環书生",link:"https://www.zlog.us.kg",avatar:"https://images.zlog.us.kg/hexo/琅環书生头像.webp",descr:"无远弗届，皆有可能",siteshot:"https://images.zlog.us.kg/hexo/琅環书生站点.webp"},{name:"SeaEpoch",link:"https://www.seayj.cn",avatar:"https://www.seayj.cn/img/avatar.png",descr:"她站在那里，就像一个小小的永恒！",siteshot:"https://www.seayj.cn/img/siteshoot.jpg"},{name:"彬红茶栈",link:"https://resource.redcha.cn",avatar:"https://cn-sy1.rains3.com/binhongtea/studio2.png",descr:"彬红茶栈"}];function toRandomFlink(){window.open(flinks[Math.floor(Math.random()*flinks.length)].link)}</script>