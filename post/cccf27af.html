<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1,viewport-fit=cover"><title>Spark 面试题解析</title><meta name="author" content="Eurkon,eurkon@foxmail.com"><meta name="copyright" content="Eurkon"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="ffffff"><meta name="description" content="Spark 内核Spark 的有几种部署模式，每种模式特点？ 本地模式：Spark 不一定非要跑在 Hadoop 集群，可以在本地，起多个线程的方式来指定。将 Spark 应用以多线程的方式直接运行在本地，一般都是为了方便调试，本地模式分三类： local：只启动一个 Executor local[k]:启动 k 个 Executor local[*]：启动跟 CPU 数目相同的 Executor"><meta property="og:type" content="article"><meta property="og:title" content="Spark 面试题解析"><meta property="og:url" content="https://blog.eurkon.com/post/cccf27af.html"><meta property="og:site_name" content="Eurkon"><meta property="og:description" content="Spark 内核Spark 的有几种部署模式，每种模式特点？ 本地模式：Spark 不一定非要跑在 Hadoop 集群，可以在本地，起多个线程的方式来指定。将 Spark 应用以多线程的方式直接运行在本地，一般都是为了方便调试，本地模式分三类： local：只启动一个 Executor local[k]:启动 k 个 Executor local[*]：启动跟 CPU 数目相同的 Executor"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="https://blog.eurkon.com/images/cover/bigdata_interview.png"><meta property="article:published_time" content="2021-05-26T01:00:00.000Z"><meta property="article:modified_time" content="2021-05-26T01:00:00.000Z"><meta property="article:author" content="Eurkon"><meta property="article:tag" content="大数据"><meta property="article:tag" content="Spark"><meta name="twitter:card" content="summary"><meta name="twitter:image" content="https://blog.eurkon.com/images/cover/bigdata_interview.png"><link rel="shortcut icon" href="https://npm.elemecdn.com/eurkon-cdn/hexo/images/user/favicon.jpg"><link rel="canonical" href="https://blog.eurkon.com/post/cccf27af.html"><link rel="preconnect" href="//cdn.jsdelivr.net"><link rel="preconnect" href="//hm.baidu.com"><link rel="preconnect" href="//busuanzi.ibruce.info"><meta name="google-site-verification" content="rClKrjtCYPsDaynvUNmfe2YGPxb7ehnuwEF9aMdG7no"><meta name="msvalidate.01" content="F299EA4E7AD0E2B28FDF4E0EA94879BA"><meta name="baidu-site-verification" content="code-GmAI2TORJk"><meta name="360-site-verification" content="ac410c1012e6f0acc65b5c0805c91f01"><meta name="yandex-verification" content="ac410c1012e6f0acc65b5c0805c91f01"><meta name="bytedance-verification-code" content="D4gz9gUv9Wh0pS4d20uQ"><meta name="sogou_site_verification" content="uYYKpHOGXl"><link rel="stylesheet" href="/css/index.css?v=5.1.0"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.6.0/css/all.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/node-snackbar@0.1.16/dist/snackbar.min.css" media="print" onload='this.media="all"'><script>(() => {
      
    const saveToLocal = {
      set: (key, value, ttl) => {
        if (!ttl) return
        const expiry = Date.now() + ttl * 86400000
        localStorage.setItem(key, JSON.stringify({ value, expiry }))
      },
      get: key => {
        const itemStr = localStorage.getItem(key)
        if (!itemStr) return undefined
        const { value, expiry } = JSON.parse(itemStr)
        if (Date.now() > expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return value
      }
    }

    window.btf = {
      saveToLocal,
      getScript: (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        Object.entries(attr).forEach(([key, val]) => script.setAttribute(key, val))
        script.onload = script.onreadystatechange = () => {
          if (!script.readyState || /loaded|complete/.test(script.readyState)) resolve()
        }
        script.onerror = reject
        document.head.appendChild(script)
      }),
      getCSS: (url, id) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onload = link.onreadystatechange = () => {
          if (!link.readyState || /loaded|complete/.test(link.readyState)) resolve()
        }
        link.onerror = reject
        document.head.appendChild(link)
      }),
      addGlobalFn: (key, fn, name = false, parent = window) => {
        if (!true && key.startsWith('pjax')) return
        const globalFn = parent.globalFn || {}
        globalFn[key] = globalFn[key] || {}
        if (name && globalFn[key][name]) return
        globalFn[key][name || Object.keys(globalFn[key]).length] = fn
        parent.globalFn = globalFn
      }
    }
  
      
      const activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      const activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', 'ffffff')
        }
      }

      btf.activateDarkMode = activateDarkMode
      btf.activateLightMode = activateLightMode

      const theme = saveToLocal.get('theme')
    
          theme === 'dark' ? activateDarkMode() : theme === 'light' ? activateLightMode() : null
        
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        document.documentElement.classList.toggle('hide-aside', asideStatus === 'hide')
      }
    
      
    const detectApple = () => {
      if (/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)) {
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
  
    })()</script><script>var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?ca4902422e728abe0603d52ce2e7757a";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
btf.addGlobalFn('pjaxComplete', () => {
  _hmt.push(['_trackPageview',window.location.pathname])
}, 'baidu_analytics')</script><script>!function(a){"use strict";!function(t){var e=window,s=document,c=a,i="".concat("https:"===s.location.protocol?"https://":"http://","sdk.51.la/js-sdk-pro.min.js"),n=s.createElement("script"),r=s.getElementsByTagName("script")[0];n.type="text/javascript",n.setAttribute("charset","UTF-8"),n.async=!0,n.src=i,n.id="LA_COLLECT",c.d=n;var o=function(){e.LA.ids.push(c)};e.LA?e.LA.ids&&o():(e.LA=a,e.LA.ids=[],o()),r.parentNode.insertBefore(n,r)}()}({id:"Je3G46ggxUPbVh1P",ck:"Je3G46ggxUPbVh1P"})</script><script>!function(e,t,n,i){var r=t.createElement("script"),s=t.getElementsByTagName("script")[0];r.type="text/javascript",r.crossorigin=!0,r.onload=function(){(new e.LingQue.Monitor).init({id:"Je3HZw0g4jpQRh3f"})},s.parentNode.insertBefore(r,s),r.src="https://sdk.51.la/perf/js-sdk-perf.min.js"}(window,document)</script><script>const GLOBAL_CONFIG = {
  root: '/',
  emoji: {"categories":{"面试系列":"📝","魔改教程":"🎨","生活随笔":"💬","学习笔记":"📚","分享转载":"🌐","作品案例":"🖥️"},"tags":null},
  algolia: undefined,
  localSearch: {"path":"/search.xml","preload":false,"top_n_per_article":1,"unescape":false,"languages":{"hits_empty":"未找到符合您查询的内容：${query}","hits_stats":"共找到 ${hits} 篇文章"}},
  translate: {"defaultEncoding":2,"translateDelay":0,"msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"簡"},
  noticeOutdate: undefined,
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":250,"highlightFullpage":false,"highlightMacStyle":false},
  copy: {
    success: '复制成功',
    error: '复制失败',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'null',
  Snackbar: {"chs_to_cht":"已切换为繁体中文","cht_to_chs":"已切换为简体中文","day_to_night":"已切换为深色模式","night_to_day":"已切换为浅色模式","bgLight":"#1677B3","bgDark":"#1f1f1f","position":"top-right"},
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid@4.12.0/dist/infinitegrid.min.js',
    buttonText: '加载更多'
  },
  isPhotoFigcaption: false,
  islazyload: true,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE={title:"Spark 面试题解析",isPost:!0,isHome:!1,isHighlightShrink:!1,isToc:!0,postUpdate:"2021-05-26 09:00:00"}</script><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/custom.css"><link rel="stylesheet" href="https://lf3-cdn-tos.bytecdntp.com/cdn/expire-1-M/Swiper/8.0.6/swiper-bundle.min.css"><script src="https://lf3-cdn-tos.bytecdntp.com/cdn/expire-1-M/Swiper/8.0.6/swiper-bundle.min.js"></script><script src="https://npm.elemecdn.com/echarts/dist/echarts.js"></script><script src="https://npm.elemecdn.com/echarts@4.9.0/map/js/china.js"></script><script src="https://npm.elemecdn.com/echarts-wordcloud/dist/echarts-wordcloud.js"></script><script src="https://npm.elemecdn.com/echarts-liquidfill/dist/echarts-liquidfill.js"></script><script src="/js/Lately.min.js"></script><meta name="generator" content="Hexo 5.4.0"><link rel="alternate" href="/atom.xml" title="Eurkon" type="application/atom+xml"><link rel="alternate" href="/rss.xml" title="Eurkon" type="application/rss+xml"></head><body><div id="loading-box"><div class="loading-left-bg"></div><div class="loading-right-bg"></div><i class="fa fas fa-spinner fa-spin load-spinner"></i></div><script>const preloader = {
  endLoading: () => {
    document.body.style.overflow = 'auto';
    document.getElementById('loading-box').style.transition = 'opacity 1s';
    document.getElementById('loading-box').style.opacity = '0';
    setTimeout(function () { document.getElementById('loading-box').classList.add("loaded") }, 1000)
    document.body.classList.remove("hidden-y")
  },
  initLoading: () => {
    document.body.style.overflow = '';
    document.getElementById('loading-box').style.transition = '';
    document.getElementById('loading-box').style.opacity = '1'; 
    document.getElementById('loading-box').classList.remove("loaded")
    document.body.classList.add("hidden-y")
  }
}
window.addEventListener('load',()=> { preloader.endLoading() })

if (true) {
  document.addEventListener('pjax:send', () => { preloader.initLoading() })
  document.addEventListener('pjax:complete', () => { preloader.endLoading() })
}

setTimeout(function () { preloader.endLoading() }, 3000)
document.getElementById('loading-box').addEventListener('click', () => { preloader.endLoading() })</script><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img text-center"><img src="https://npm.elemecdn.com/eurkon-cdn/hexo/images/user/avatar.jpg" onerror='onerror=null,src="https://npm.elemecdn.com/eurkon-cdn/hexo/images/user/loading.gif"' alt="avatar"></div><div class="site-data text-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">88</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">28</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">6</div></a></div><div class="menus_items"><div class="menus_item"><span class="site-page group"><i class="fa-fw fas fa-book-open"></i> <span>文章</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="/archives/"><i class="fa-fw fas fa-archive"></i> <span>文章列表</span></a></li><li><a class="site-page child" href="/categories/"><i class="fa-fw fas fa-shapes"></i> <span>全部分类</span></a></li><li><a class="site-page child" href="/tags/"><i class="fa-fw fas fa-tags"></i> <span>所有标签</span></a></li><li><a class="site-page child" href="javascript:toRandomPost();" rel="external nofollow noreferrer"><i class="fa-fw fas fa-random"></i> <span>随便看看</span></a></li></ul></div><div class="menus_item"><span class="site-page group"><i class="fa-fw fas fa-chart-bar"></i> <span>统计</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="/charts/"><i class="fa-fw fas fa-chart-area"></i> <span>文章统计</span></a></li><li><a class="site-page child" href="/census/"><i class="fa-fw fas fa-chart-line"></i> <span>博客统计</span></a></li></ul></div><div class="menus_item"><span class="site-page group"><i class="fa-fw fas fa-link"></i> <span>导航</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="/fcircle/"><i class="fa-fw fas fa-blog"></i> <span>友链订阅</span></a></li><li><a class="site-page child" href="/link/"><i class="fa-fw fas fa-user-friends"></i> <span>友情链接</span></a></li><li><a class="site-page child" href="/stars/"><i class="fa-fw fas fa-star"></i> <span>网站收藏</span></a></li></ul></div><div class="menus_item"><span class="site-page group"><i class="fa-fw fas fa-laptop"></i> <span>博客</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="/about/"><i class="fa-fw fas fa-address-card"></i> <span>关于本站</span></a></li><li><a class="site-page child" href="/notice/"><i class="fa-fw fas fa-bullhorn"></i> <span>网站公告</span></a></li><li><a class="site-page child" href="/message/"><i class="fa-fw fas fa-envelope"></i> <span>留言信箱</span></a></li><li><a class="site-page child" href="/update/"><i class="fa-fw fas fa-cloud-upload-alt"></i> <span>博客更新</span></a></li></ul></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image:url(/images/cover/bigdata_interview.png)"><nav id="nav"><div id="nav-group"><span id="blog-info"><a class="site-page" href="/" title="Eurkon"><span class="site-name">Eurkon</span><i class="fas fa-home"></i></a></span><a class="nav-page-title" title="回到顶部" onclick="btf.scrollToDest(0,500)"><span class="site-name" id="page-title">Spark 面试题解析</span></a><div id="menus"><div class="menus_items"><div class="menus_item"><span class="site-page group"><i class="fa-fw fas fa-book-open"></i> <span>文章</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="/archives/"><i class="fa-fw fas fa-archive"></i> <span>文章列表</span></a></li><li><a class="site-page child" href="/categories/"><i class="fa-fw fas fa-shapes"></i> <span>全部分类</span></a></li><li><a class="site-page child" href="/tags/"><i class="fa-fw fas fa-tags"></i> <span>所有标签</span></a></li><li><a class="site-page child" href="javascript:toRandomPost();" rel="external nofollow noreferrer"><i class="fa-fw fas fa-random"></i> <span>随便看看</span></a></li></ul></div><div class="menus_item"><span class="site-page group"><i class="fa-fw fas fa-chart-bar"></i> <span>统计</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="/charts/"><i class="fa-fw fas fa-chart-area"></i> <span>文章统计</span></a></li><li><a class="site-page child" href="/census/"><i class="fa-fw fas fa-chart-line"></i> <span>博客统计</span></a></li></ul></div><div class="menus_item"><span class="site-page group"><i class="fa-fw fas fa-link"></i> <span>导航</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="/fcircle/"><i class="fa-fw fas fa-blog"></i> <span>友链订阅</span></a></li><li><a class="site-page child" href="/link/"><i class="fa-fw fas fa-user-friends"></i> <span>友情链接</span></a></li><li><a class="site-page child" href="/stars/"><i class="fa-fw fas fa-star"></i> <span>网站收藏</span></a></li></ul></div><div class="menus_item"><span class="site-page group"><i class="fa-fw fas fa-laptop"></i> <span>博客</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="/about/"><i class="fa-fw fas fa-address-card"></i> <span>关于本站</span></a></li><li><a class="site-page child" href="/notice/"><i class="fa-fw fas fa-bullhorn"></i> <span>网站公告</span></a></li><li><a class="site-page child" href="/message/"><i class="fa-fw fas fa-envelope"></i> <span>留言信箱</span></a></li><li><a class="site-page child" href="/update/"><i class="fa-fw fas fa-cloud-upload-alt"></i> <span>博客更新</span></a></li></ul></div></div></div><div id="hotkey"><div id="search-button"><span class="site-page social-icon search" href="javascript:void(0);" title="搜索"><i class="fas fa-search fa-fw"></i> <span>搜索</span></span></div><div id="comment-button"><a class="site-page" href="#post-comment" title="前往评论"><i class="fas fa-comments fa-fw"></i></a></div><div id="setting-button" onclick="eurkon.switchRightSide()"><a class="site-page" href="javascript:void(0);" rel="external nofollow noreferrer" title="设置"><i class="fas fa-screwdriver-wrench fa-fw"></i></a></div><div id="top-button"><a class="site-page" href="javascript:void(0);" rel="external nofollow noreferrer" title="回到顶部" onclick="btf.scrollToDest(0,500)"><span class="scroll-percent"></span><i class="fas fa-arrow-up fa-fw"></i></a></div><div id="toggle-menu"><a class="site-page" href="javascript:void(0);" rel="external nofollow noreferrer"><i class="fas fa-bars fa-fw"></i></a></div></div></div></nav><div id="post-cover"><img class="cover" id="post-cover-img" src="/images/cover/bigdata_interview.png" alt="cover"></div><div id="post-info"><div id="post-meta"><div class="meta-firstline"><span class="post-meta-categories"><i class="fas fa-shapes fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E9%9D%A2%E8%AF%95%E7%B3%BB%E5%88%97/">📝面试系列</a></span><span class="post-meta-tags"><span class="post-meta-separator">|</span><i class="fas fa-tags fa-fw post-meta-icon"></i><a class="post-meta-tags" href="/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/">大数据</a><span class="post-meta-separator">•</span><a class="post-meta-tags" href="/tags/Spark/">Spark</a></span></div><h1 class="post-title">Spark 面试题解析</h1><div class="meta-secondline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2021-05-26T01:00:00.000Z" title="发表于 2021-05-26 09:00:00">2021-05-26</time></span><span class="post-meta-separator">|</span><span class="post-meta-date"><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2021-05-26T01:00:00.000Z" title="更新于 2021-05-26 09:00:00">2021-05-26</time></span><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">总字数:</span><span class="word-count">20,921</span><span class="post-meta-separator">|</span></span><span class="post-meta-min2read"><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>77分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" data-flag-title=""><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">浏览量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span><span class="post-meta-separator">|</span><span class="post-meta-commentcount"><i class="far fa-comments fa-fw post-meta-icon"></i><span class="post-meta-label">评论数:</span><a href="/post/cccf27af.html#post-comment"><span id="twikoo-count"><i class="fa-solid fa-spinner fa-spin"></i></span></a></span></div></div></div><section class="main-hero-waves-area waves-area"><svg class="waves-svg" xmlns="http://www.w3.org/2000/svg" xlink="http://www.w3.org/1999/xlink" viewBox="0 24 150 28" preserveAspectRatio="none" shape-rendering="auto"><defs><path id="gentle-wave" d="M-160 44c30 0 58-18 88-18s58 18 88 18 58-18 88-18 58 18 88 18v44h-352Z"></path></defs><g class="parallax"><use href="#gentle-wave" x="48" y="0"></use><use href="#gentle-wave" x="48" y="3"></use><use href="#gentle-wave" x="48" y="5"></use><use href="#gentle-wave" x="48" y="7"></use></g></svg></section></header><main class="layout" id="content-inner"><div><div id="post"><article class="post-content" id="article-container"><h2 id="Spark-内核"><a href="#Spark-内核" class="headerlink" title="Spark 内核"></a>Spark 内核</h2><h3 id="Spark-的有几种部署模式，每种模式特点？"><a href="#Spark-的有几种部署模式，每种模式特点？" class="headerlink" title="Spark 的有几种部署模式，每种模式特点？"></a>Spark 的有几种部署模式，每种模式特点？</h3><ul><li><strong>本地模式</strong>：Spark 不一定非要跑在 Hadoop 集群，可以在本地，起多个线程的方式来指定。将 Spark 应用以多线程的方式直接运行在本地，一般都是为了方便调试，本地模式分三类：<ul><li><code>local</code>：只启动一个 Executor</li><li><code>local[k]</code>:启动 k 个 Executor</li><li><code>local[*]</code>：启动跟 CPU 数目相同的 Executor</li></ul></li><li><strong>standalone 模式</strong>：分布式部署集群，自带完整的服务，资源管理和任务监控是 Spark 自己监控，这个模式也是其他模式的基础。</li><li><strong>Spark on Yarn 模式</strong>：分布式部署集群，资源和任务监控交给 YARN 管理，但是目前仅支持粗粒度资源分配方式，包含 cluster 和 client 运行模式，cluster 适合生产，Driver 运行在集群子节点，具有容错功能，client 适合调试，Driver 运行在客户端。</li><li><strong>Spark On Mesos 模式</strong>：官方推荐这种模式（当然，原因之一是血缘关系）。正是由于 Spark 开发之初就考虑到支持 Mesos，因此，目前而言，Spark 运行在 Mesos 上会比运行在 YARN 上更加灵活，更加自然。用户可选择两种调度模式之一运行自己的应用程序：<ul><li>粗粒度模式（Coarse-grained Mode）：每个应用程序的运行环境由一个 Driver 和若干个 Executor 组成，其中，每个 Executor 占用若干资源，内部可运行多个 Task（对应多少个“slot”）。应用程序的各个任务正式运行之前，需要将运行环境中的资源全部申请好，且运行过程中要一直占用这些资源，即使不用，最后程序运行结束后，回收这些资源。</li><li>细粒度模式（Fine-grained Mode）：鉴于粗粒度模式会造成大量资源浪费，Spark On Mesos 还提供了另外一种调度模式：细粒度模式，这种模式类似于现在的云计算，思想是按需分配。</li></ul></li></ul><h3 id="Spark-为什么比-MapReduce-快？"><a href="#Spark-为什么比-MapReduce-快？" class="headerlink" title="Spark 为什么比 MapReduce 快？"></a>Spark 为什么比 MapReduce 快？</h3><ul><li>基于内存计算，减少低效的磁盘交互；</li><li>高效的调度算法，基于 DAG；</li><li>容错机制 Lineage，精华部分就是 DAG 和 Lineage。</li></ul><h3 id="简单说一下-Hadoop-和-Spark-的-shuffle-相同和差异？"><a href="#简单说一下-Hadoop-和-Spark-的-shuffle-相同和差异？" class="headerlink" title="简单说一下 Hadoop 和 Spark 的 shuffle 相同和差异？"></a>简单说一下 Hadoop 和 Spark 的 shuffle 相同和差异？</h3><ul><li>从 high-level 的角度来看，两者并没有大的差别。都是将 mapper（Spark 里是 ShuffleMapTask）的输出进行 partition，不同的 partition 送到不同的 reducer（Spark 里 reducer 可能是下一个 stage 里的 ShuffleMapTask，也可能是 ResultTask）。Reducer 以内存作缓冲区，边 shuffle 边 aggregate 数据，等到数据 aggregate 好以后进行 reduce（Spark 里可能是后续的一系列操作）。</li><li>从 low-level 的角度来看，两者差别不小。Hadoop MapReduce 是 sort-based，进入 combine 和 reduce 的 records 必须先 sort。这样的好处在于 combine/reduce 可以处理大规模的数据，因为其输入数据可以通过外排得到（mapper 对每段数据先做排序，reducer 的 shuffle 对排好序的每段数据做归并）。目前的 Spark 默认选择的是 hash-based，通常使用 HashMap 来对 shuffle 来的数据进行 aggregate，不会对数据进行提前排序。如果用户需要经过排序的数据，那么需要自己调用类似 sortByKey 的操作；如果你是 Spark 1.1 的用户，可以将 <code>spark.shuffle.manager</code> 设置为 sort，则会对数据进行排序。在 Spark 1.2 中，sort 将作为默认的 Shuffle 实现。</li><li>从实现角度来看，两者也有不少差别。Hadoop MapReduce 将处理流程划分出明显的几个阶段：map，spill，merge，shuffle，sort，reduce 等。每个阶段各司其职，可以按照过程式的编程思想来逐一实现每个阶段的功能。在 Spark 中，没有这样功能明确的阶段，只有不同的 stage 和一系列的 transformation，所以 spill，merge，aggregate 等操作需要蕴含在 transformation 中。</li></ul><p>如果我们将 map 端划分数据、持久化数据的过程称为 shuffle write，而将 reducer 读入数据、aggregate 数据的过程称为 shuffle read。那么在 Spark 中，问题就变为怎么在 job 的逻辑或者物理执行图中加入 shuffle write 和 shuffle read 的处理逻辑？以及两个处理逻辑应该怎么高效实现？</p><p>shuffle write 由于不要求数据有序，shuffle write 的任务很简单：将数据 partition 好，并持久化。之所以要持久化，一方面是要减少内存存储空间压力，另一方面也是为了 fault-tolerance。</p><h3 id="Spark-工作机制？Spark-应用程序的执行过程？"><a href="#Spark-工作机制？Spark-应用程序的执行过程？" class="headerlink" title="Spark 工作机制？Spark 应用程序的执行过程？"></a>Spark 工作机制？Spark 应用程序的执行过程？</h3><ol><li>构建 Application 的运行环境，Driver 创建一个 SparkContext；</li><li>SparkContext 向资源管理器（Standalone、Mesos、Yarn）申请 Executor 资源，资源管理器启动 StandaloneExecutorBackend（Executor）;</li><li>Executor 向 SparkContext 申请 Task;</li><li>SparkContext 将应用程序分发给 Executor;</li><li>SparkContext 就建成 DAG 图，DAG Scheduler 将 DAG 图解析成 Stage，每个 Stage 有多个 Task，形成 TaskSet 发送给 Task Scheduler，由 Task Scheduler 将 Task 发送给 Executor 运行；</li><li>Task 在 Executor 上运行，运行完释放所有资源。</li></ol><h3 id="Spark-的优化怎么做？"><a href="#Spark-的优化怎么做？" class="headerlink" title="Spark 的优化怎么做？"></a>Spark 的优化怎么做？</h3><p>Spark 调优比较复杂，但是大体可以分为三个方面来进行</p><ul><li>平台层面的调优：防止不必要的 jar 包分发，提高数据的本地性，选择高效的存储格式如 parquet；</li><li>应用程序层面的调优：过滤操作符的优化降低过多小任务，降低单条记录的资源开销，处理数据倾斜，复用 RDD 进行缓存，作业并行化执行等等；</li><li>JVM 层面的调优：设置合适的资源量，设置合理的 JVM，启用高效的序列化方法如 Kyro，增大 off-heap 内存等等；</li></ul><h3 id="数据本地性是在哪个环节确定的？"><a href="#数据本地性是在哪个环节确定的？" class="headerlink" title="数据本地性是在哪个环节确定的？"></a>数据本地性是在哪个环节确定的？</h3><p>具体的 Task 运行的那台机器上，DAG 划分 Stage 的时候确定的。</p><h3 id="RDD-的弹性表现在哪几点？"><a href="#RDD-的弹性表现在哪几点？" class="headerlink" title="RDD 的弹性表现在哪几点？"></a>RDD 的弹性表现在哪几点？</h3><ul><li>自动的进行内存和磁盘的存储切换；</li><li>基于 Lineage 的高效容错；</li><li>Task 如果失败会自动进行特定次数的重试；</li><li>Stage 如果失败会自动进行特定次数的重试，而且只会计算失败的分片；</li><li>checkpoint 和 persist，数据计算之后持久化缓存；</li><li>数据调度弹性，DAG TASK 调度和资源无关；</li><li>数据分片的高度弹性。</li></ul><h3 id="RDD-有哪些缺陷？"><a href="#RDD-有哪些缺陷？" class="headerlink" title="RDD 有哪些缺陷？"></a>RDD 有哪些缺陷？</h3><ul><li>不支持细粒度的写和更新操作，Spark 写数据是粗粒度的。所谓粗粒度，就是批量写入数据，为了提高效率。但是读数据是细粒度的也就是说可以一条条的读。</li><li>不支持增量迭代计算，Flink 支持</li></ul><h3 id="Spark-的-shuffle-过程？"><a href="#Spark-的-shuffle-过程？" class="headerlink" title="Spark 的 shuffle 过程？"></a>Spark 的 shuffle 过程？</h3><p>从下面三点去展开</p><ul><li>shuffle 过程的划分</li><li>shuffle 的中间结果如何存储</li><li>shuffle 的数据如何拉取过来</li></ul><h3 id="Spark-的数据本地性有哪几种？"><a href="#Spark-的数据本地性有哪几种？" class="headerlink" title="Spark 的数据本地性有哪几种？"></a>Spark 的数据本地性有哪几种？</h3><p>Spark 中的数据本地性有三种：</p><ul><li>PROCESS_LOCAL 是指读取缓存在本地节点的数据</li><li>NODE_LOCAL 是指读取本地节点硬盘数据</li><li>ANY 是指读取非本地节点数据</li></ul><p>通常读取数据 PROCESS_LOCAL &gt; NODE_LOCAL &gt; ANY，尽量使数据以 PROCESS_LOCAL 或 NODE_LOCAL 方式读取。其中 PROCESS_LOCAL 还和 cache 有关，如果 RDD 经常用的话将该 RDD cache 到内存中，注意，由于 cache 是 lazy 的，所以必须通过一个 action 的触发，才能真正的将该 RDD cache 到内存中。</p><h3 id="Spark-为什么要持久化，一般什么场景下要进行-persist-操作？"><a href="#Spark-为什么要持久化，一般什么场景下要进行-persist-操作？" class="headerlink" title="Spark 为什么要持久化，一般什么场景下要进行 persist 操作？"></a>Spark 为什么要持久化，一般什么场景下要进行 persist 操作？</h3><p>Spark 所有复杂一点的算法都会有 persist 身影，Spark 默认数据放在内存，Spark 很多内容都是放在内存的，非常适合高速迭代，1000 个步骤只有第一个输入数据，中间不产生临时数据，但分布式系统风险很高，所以容易出错，就要容错，RDD 出错或者分片可以根据血统算出来，如果没有对父 RDD 进行 persist 或者 cache 的话，就需要重头做。以下场景会使用 persist：</p><ul><li>某个步骤计算非常耗时，需要进行 persist 持久化；</li><li>计算链条非常长，重新恢复要算很多步骤；</li><li>checkpoint 所在的 RDD 要持久化 persist。checkpoint 前要持久化，写个 rdd.cache 或者 rdd.persist，将结果保存起来，再写 checkpoint 操作，这样执行起来会非常快，不需要重新计算 RDD 链条了。checkpoint 之前一定会进行 persist；</li><li>shuffle 之后要 persist，shuffle 要进行网络传输，风险很大，数据丢失重来，恢复代价很大；</li><li>shuffle 之前进行 persist，框架默认将数据持久化到磁盘，这个是框架自动做的。</li></ul><h3 id="介绍一下-join-操作优化经验？"><a href="#介绍一下-join-操作优化经验？" class="headerlink" title="介绍一下 join 操作优化经验？"></a>介绍一下 join 操作优化经验？</h3><p>join 其实常见的就分为两类：<strong>map-side join</strong> 和 <strong>reduce-side join</strong>。当大表和小表 join 时，用 map-side join 能显著提高效率。将多份数据进行关联是数据处理过程中非常普遍的用法，不过在分布式计算系统中，这个问题往往会变的非常麻烦，因为框架提供的 join 操作一般会将所有数据根据 key 发送到所有的 reduce 分区中去，也就是 shuffle 的过程。造成大量的网络以及磁盘 IO 消耗，运行效率极其低下，这个过程一般被称为 reduce-side-join。如果其中有张表较小的话，我们则可以自己实现在 map 端实现数据关联，跳过大量数据进行 shuffle 的过程，运行时间得到大量缩短，根据不同数据可能会有几倍到数十倍的性能提升。</p><h3 id="描述-Yarn-执行一个任务的过程？"><a href="#描述-Yarn-执行一个任务的过程？" class="headerlink" title="描述 Yarn 执行一个任务的过程？"></a>描述 Yarn 执行一个任务的过程？</h3><p><img src="https://npm.elemecdn.com/eurkon-cdn/hexo/images/user/loading.gif" data-lazy-src="/images/post/bigdata_interview/spark_yarn_workflow.png" alt="Yarn 工作流"></p><ol><li>客户端 client 向 ResourceManager 提交 Application，ResourceManager 接受 Application 并根据集群资源状况选取一个 node 来启动 Application 的任务调度器 Driver（ApplicationMaster）。</li><li>ResourceManager 找到那个 node，命令其该 node 上的 nodeManager 来启动一个新的 JVM 进程运行程序的 Driver（ApplicationMaster）部分，Driver（ApplicationMaster）启动时会首先向 ResourceManager 注册，说明由自己来负责当前程序的运行。</li><li>Driver（ApplicationMaster）开始下载相关 jar 包等各种资源，基于下载的 jar 等信息决定向 ResourceManager 申请具体的资源内容。</li><li>ResourceManager 接受到 Driver（ApplicationMaster）提出的申请后，会最大化的满足资源分配请求，并发送资源的元数据信息给 Driver（ApplicationMaster）。</li><li>Driver（ApplicationMaster）收到发过来的资源元数据信息后会根据元数据信息发指令给具体机器上的 NodeManager，让其启动具体的 Container。</li><li>NodeManager 收到 Driver 发来的指令，启动 Container，Container 启动后必须向 Driver（ApplicationMaster）注册。</li><li>Driver（ApplicationMaster）收到 Container 的注册，开始进行任务的调度和计算，直到任务完成。</li></ol><p>注意：如果 ResourceManager 第一次没有能够满足 Driver（ApplicationMaster）的资源请求 ，后续发现有空闲的资源，会主动向 Driver（ApplicationMaster）发送可用资源的元数据信息以提供更多的资源用于当前程序的运行。</p><h3 id="Spark-on-Yarn-模式有哪些优点？"><a href="#Spark-on-Yarn-模式有哪些优点？" class="headerlink" title="Spark on Yarn 模式有哪些优点？"></a>Spark on Yarn 模式有哪些优点？</h3><ul><li>与其他计算框架共享集群资源（Spark 框架与 MapReduce 框架同时运行，如果不用 Yarn 进行资源分配，MapReduce 分到的内存资源会很少，效率低下）；资源按需分配，进而提高集群资源利用等。</li><li>相较于 Spark 自带的 Standalone 模式，Yarn 的资源分配更加细致。</li><li>Application 部署简化，例如 Spark，Storm 等多种框架的应用由客户端提交后，由 Yarn 负责资源的管理和调度，利用 Container 作为资源隔离的单位，以它为单位去使用内存、CPU 等。</li><li>Yarn 通过队列的方式，管理同时运行在 Yarn 集群中的多个服务，可根据不同类型的应用程序负载情况，调整对应的资源使用量，实现资源弹性管理。</li></ul><h3 id="谈谈你对-Container-的理解？"><a href="#谈谈你对-Container-的理解？" class="headerlink" title="谈谈你对 Container 的理解？"></a>谈谈你对 Container 的理解？</h3><ul><li>Container 作为资源分配和调度的基本单位，其中封装了的资源如内存，CPU，磁盘，网络带宽等。目前 YARN 仅仅封装内存和 CPU；</li><li>Container 由 ApplicationMaster 向 ResourceManager 申请的，由 ResourceManager 中的资源调度器异步分配给 ApplicationMaster；</li><li>Container 的运行是由 ApplicationMaster 向资源所在的 NodeManager 发起的，Container 运行时需提供内部执行的任务命令。</li></ul><h3 id="Spark-使用-parquet-文件存储格式能带来哪些好处？"><a href="#Spark-使用-parquet-文件存储格式能带来哪些好处？" class="headerlink" title="Spark 使用 parquet 文件存储格式能带来哪些好处？"></a>Spark 使用 parquet 文件存储格式能带来哪些好处？</h3><ul><li>如果说 HDFS 是大数据时代分布式文件系统首选标准，那么 parquet 则是整个大数据时代文件存储格式实时首选标准。</li><li>速度更快：从使用 Spark SQL 操作普通文件 CSV 和 parquet 文件速度对比上看，绝大多数情况会比使用 csv 等普通文件速度提升 10 倍左右，在一些普通文件系统无法在 Spark 上成功运行的情况下，使用 parquet 很多时候可以成功运行。</li><li>parquet 的压缩技术非常稳定出色，在 Spark SQL 中对压缩技术的处理可能无法正常的完成工作（例如会导致 lost task，lost executor）但是此时如果使用 parquet 就可以正常的完成。</li><li>极大的减少磁盘 IO，通常情况下能够减少 75% 的存储空间，由此可以极大的减少 Spark SQL 处理数据的时候的数据输入内容，尤其是在 Spark1.6x 中有个下推过滤器在一些情况下可以极大的减少磁盘的 IO 和内存的占用。</li><li>Spark 1.6x parquet 方式极大的提升了扫描的吞吐量，极大提高了数据的查找速度 Spark1.6x 和 Spark1.5x 相比而言，提升了大约 1 倍的速度，在 Spark1.6x 中，操作 parquet 时候 CPU 也进行了极大的优化，有效的降低了 CPU 消耗。</li><li>采用 parquet 可以极大的优化 Spark 的调度和执行。我们测试 Spark 如果用 parquet 可以有效的减少 Stage 的执行消耗，同时可以优化执行路径。</li></ul><h3 id="介绍-partition-和-block-有什么关联关系？"><a href="#介绍-partition-和-block-有什么关联关系？" class="headerlink" title="介绍 partition 和 block 有什么关联关系？"></a>介绍 partition 和 block 有什么关联关系？</h3><ul><li>HDFS 中的 block 是分布式存储的最小单元，等分，可设置冗余，这样设计有一部分磁盘空间的浪费，但是整齐的 block 大小，便于快速找到、读取对应的内容；</li><li>Spark 中的 partition 是弹性分布式数据集 RDD 的最小单元，RDD 是由分布在各个节点上的 partition 组成的。partition 是指的 Spark 在计算过程中，生成的数据在计算空间内最小单元，同一份数据（RDD）的 partition 大小不一，数量不定，是根据 application 里的算子和最初读入的数据分块数量决定；</li><li>block 位于存储空间、partition 位于计算空间，block 的大小是固定的、partition 大小是不固定的，是从 2 个不同的角度去看数据。</li></ul><h3 id="不需要排序的-hash-shuffle-是否一定比需要排序的-sort-shuffle-速度快？"><a href="#不需要排序的-hash-shuffle-是否一定比需要排序的-sort-shuffle-速度快？" class="headerlink" title="不需要排序的 hash shuffle 是否一定比需要排序的 sort shuffle 速度快？"></a>不需要排序的 hash shuffle 是否一定比需要排序的 sort shuffle 速度快？</h3><p>不一定，当数据规模小，hash shuffle 快于 sorted shuffle，数据规模大的时候；当数据量大，sorted shuffle 会比 hash shuffle 快很多，因为数量大的有很多小文件，不均匀，甚至出现数据倾斜，消耗内存大，1.x 之前 Spark 使用 hash，适合处理中小规模，1.x 之后，增加了 sorted shuffle，Spark 更能胜任大规模处理了。</p><h3 id="Sort-based-shuffle-的缺陷？"><a href="#Sort-based-shuffle-的缺陷？" class="headerlink" title="Sort-based shuffle 的缺陷？"></a>Sort-based shuffle 的缺陷？</h3><ul><li>如果 mapper 中 task 的数量过大，依旧会产生很多小文件，此时在 shuffle 传递数据到 reducer 的过程中，reduce 会需要同时大量的记录进行反序列化，导致大量的内存消耗和 GC 的巨大负担，造成系统缓慢甚至崩溃。</li><li>如果需要在分片内也进行排序，此时需要进行 mapper 和 reducer 的两次排序。</li></ul><h3 id="spark-storage-memoryFraction-参数的含义，实际生产中如何调优？"><a href="#spark-storage-memoryFraction-参数的含义，实际生产中如何调优？" class="headerlink" title="spark.storage.memoryFraction 参数的含义，实际生产中如何调优？"></a>spark.storage.memoryFraction 参数的含义，实际生产中如何调优？</h3><ul><li><p>用于设置 RDD 持久化数据在 Executor 内存中能占的比例，默认是 0.6，默认 Executor 60% 的内存，可以用来保存持久化的 RDD 数据。根据你选择的不同的持久化策略，如果内存不够时，可能数据就不会持久化，或者数据会写入磁盘；</p></li><li><p>如果持久化操作比较多，可以提高 <code>spark.storage.memoryFraction</code> 参数，使得更多的持久化数据保存在内存中，提高数据的读取性能，如果 shuffle 的操作比较多，有很多的数据读写操作到 JVM 中，那么应该调小一点，节约出更多的内存给 JVM，避免过多的 JVM GC 发生。在 Web UI 中观察如果发现 GC 时间很长，可以设置 <code>spark.storage.memoryFraction</code> 更小一点。</p></li></ul><h3 id="介绍一下你对-Unified-Memory-Management-内存管理模型的理解？"><a href="#介绍一下你对-Unified-Memory-Management-内存管理模型的理解？" class="headerlink" title="介绍一下你对 Unified Memory Management 内存管理模型的理解？"></a>介绍一下你对 Unified Memory Management 内存管理模型的理解？</h3><p>Spark 中的内存使用分为两部分：执行（execution）与存储（storage）。执行内存主要用于 shuffles、joins、sorts 和 aggregations，存储内存则用于缓存或者跨节点的内部数据传输。1.6 之前，对于一个 Executor，内存都由以下部分构成：</p><ul><li>ExecutionMemory：这片内存区域是为了解决 shuffles，joins，sorts 和 aggregations 过程中为了避免频繁 IO 需要的 buffer。通过 <code>spark.shuffle.memoryFraction</code>（默认 0.2）配置。</li><li>StorageMemory：这片内存区域是为了解决 block cache（就是你显示调用 rdd.cache，rdd.persist 等方法），还有就是 broadcasts 以及 task results 的存储。可以通过参数 <code>spark.storage.memoryFraction</code>（默认 0.6）设置。</li><li>OtherMemory：给系统预留的，因为程序本身运行也是需要内存的（默认为 0.2）。</li></ul><p>传统内存管理的不足：</p><ul><li>Shuffle 占用内存 0.2*0.8，内存分配这么少，可能会将数据 spill 到磁盘，频繁的磁盘 IO 是很大的负担，Storage 内存占用 0.6，主要是为了迭代处理。传统的 Spark 内存分配对操作人的要求非常高。（Shuffle 分配内存：ShuffleMemoryManager，TaskMemoryManager，ExecutorMemoryManager）一个 Task 获得全部的 Execution 的 Memory，其他 Task 过来就没有内存了，只能等待；</li><li>默认情况下，Task 在线程中可能会占满整个内存，分片数据特别大的情况下就会出现这种情况，其他 Task 没有内存了，剩下的 cores 就空闲了，这是巨大的浪费。这也是人为操作的不当造成的；</li><li>MEMORY_AND_DISK_SER 的 storage 方式，获得 RDD 的数据是一条条获取，iterator 的方式。如果内存不够（spark.storage.unrollFraction），unroll 的读取数据过程，就是看内存是否足够，如果足够，就下一条。unroll 的 space 是从 Storage 的内存空间中获得的。unroll 的方式失败，就会直接放磁盘；</li><li>默认情况下，Task 在 spill 到磁盘之前，会将部分数据存放到内存上，如果获取不到内存，就不会执行。永无止境的等待，消耗 CPU 和内存；</li></ul><p>​在此基础上，Spark 提出了 UnifiedMemoryManager，不再分 ExecutionMemory 和 Storage Memory，实际上还是分的，只不过是 Execution Memory 访问 Storage Memory，Storage Memory 也可以访问 Execution Memory，如果内存不够，就会去借。</p><h3 id="Spark-有哪两种算子？"><a href="#Spark-有哪两种算子？" class="headerlink" title="Spark 有哪两种算子？"></a>Spark 有哪两种算子？</h3><p>​Transformation（转化）算子和 Action（执行）算子。</p><h3 id="Spark-有哪些聚合类的算子，我们应该尽量避免什么类型的算子？"><a href="#Spark-有哪些聚合类的算子，我们应该尽量避免什么类型的算子？" class="headerlink" title="Spark 有哪些聚合类的算子，我们应该尽量避免什么类型的算子？"></a>Spark 有哪些聚合类的算子，我们应该尽量避免什么类型的算子？</h3><p>​在我们的开发过程中，能避免则尽可能避免使用 reduceByKey、join、distinct、repartition 等会进行 shuffle 的算子，尽量使用 map 类的非 shuffle 算子。这样的话，没有 shuffle 操作或者仅有较少 shuffle 操作的 Spark 作业，可以大大减少性能开销。</p><h3 id="如何从-Kafka-中获取数据？"><a href="#如何从-Kafka-中获取数据？" class="headerlink" title="如何从 Kafka 中获取数据？"></a>如何从 Kafka 中获取数据？</h3><ul><li><p>基于 Receiver 的方式</p><p>这种方式使用 Receiver 来获取数据。Receiver 是使用 Kafka 的高层次 Consumer API 来实现的。receiver 从 Kafka 中获取的数据都是存储在 Spark Executor 的内存中的，然后 Spark Streaming 启动的 job 会去处理那些数据。</p></li><li><p>基于 Direct 的方式</p><p>​这种新的不基于 Receiver 的直接方式，是在 Spark 1.3 中引入的，从而能够确保更加健壮的机制。替代掉使用 Receiver 来接收数据后，这种方式会周期性地查询 Kafka，来获得每个 topic + partition 的最新的 offset，从而定义每个 batch 的 offset 的范围。当处理数据的 job 启动时，就会使用 Kafka 的简单 Consumer API 来获取 Kafka 指定 offset 范围的数据。</p></li></ul><h3 id="RDD-创建有哪几种方式？"><a href="#RDD-创建有哪几种方式？" class="headerlink" title="RDD 创建有哪几种方式？"></a>RDD 创建有哪几种方式？</h3><ul><li>使用程序中的集合创建 RDD</li><li>使用本地文件系统创建 RDD</li><li>使用 HDFS 创建 RDD</li><li>基于数据库 db 创建 RDD</li><li>基于 NoSQL 创建 RDD，如 HBase</li><li>基于 s3 创建 RDD</li><li>基于数据流，如 socket 创建 RDD</li></ul><h3 id="Spark-并行度怎么设置比较合适？"><a href="#Spark-并行度怎么设置比较合适？" class="headerlink" title="Spark 并行度怎么设置比较合适？"></a>Spark 并行度怎么设置比较合适？</h3><p>​Spark 并行度，每个 core 承载 2~4 个 partition，如 32 个 core，那么 64~128 之间的并行度，也就是设置 64~128 个 partition，并行读和数据规模无关，只和内存使用量和 CPU 使用时间有关。</p><h3 id="Spark-如何处理不能被序列化的对象？"><a href="#Spark-如何处理不能被序列化的对象？" class="headerlink" title="Spark 如何处理不能被序列化的对象？"></a>Spark 如何处理不能被序列化的对象？</h3><p>​将不能序列化的内容封装成 object。</p><h3 id="collect-功能是什么，其底层是怎么实现的？"><a href="#collect-功能是什么，其底层是怎么实现的？" class="headerlink" title="collect 功能是什么，其底层是怎么实现的？"></a>collect 功能是什么，其底层是怎么实现的？</h3><p>​Driver 通过 collect 把集群中各个节点的内容收集过来汇总成结果，collect 返回结果是 Array 类型的，collect 把各个节点上的数据抓过来，抓过来数据是 Array 型，collect 对 Array 抓过来的结果进行合并，合并后 Array 中只有一个元素，是 tuple 类型（K-V 类型）的。</p><h3 id="为什么-Spark-Application-在没有获得足够的资源，job-就开始执行了，可能会导致什么什么问题发生？"><a href="#为什么-Spark-Application-在没有获得足够的资源，job-就开始执行了，可能会导致什么什么问题发生？" class="headerlink" title="为什么 Spark Application 在没有获得足够的资源，job 就开始执行了，可能会导致什么什么问题发生？"></a>为什么 Spark Application 在没有获得足够的资源，job 就开始执行了，可能会导致什么什么问题发生？</h3><p>​会导致执行该 job 的时候集群资源不足，导致执行 job 结束也没有分配足够的资源，分配了部分 Executor，该 job 就开始执行 task，应该是 task 的调度线程和 Executor 资源申请是异步的；如果想等待申请完所有的资源再执行 job 的，​需要将 ​<code>spark.scheduler.maxRegisteredResourcesWaitingTime</code> 设置的很大；​<code>spark.scheduler.minRegisteredResourcesRatio</code> 设置为 1，但是应该结合实际考虑，​否则很容易出现长时间分配不到资源，job 一直不能运行的情况。</p><h3 id="map-与-flatMap-的区别？"><a href="#map-与-flatMap-的区别？" class="headerlink" title="map 与 flatMap 的区别？"></a>map 与 flatMap 的区别？</h3><ul><li>map：对 RDD 每个元素转换，文件中的每一行数据返回一个数组对象。</li><li>flatMap：对 RDD 每个元素转换，然后再扁平化。</li></ul><p>​将所有的对象合并为一个对象，文件中的所有行数据仅返回一个数组对象，会抛弃值为 null 的值。</p><h3 id="Spark-on-Mesos-中，什么是的粗粒度分配，什么是细粒度分配，各自的优点和缺点是什么？"><a href="#Spark-on-Mesos-中，什么是的粗粒度分配，什么是细粒度分配，各自的优点和缺点是什么？" class="headerlink" title="Spark on Mesos 中，什么是的粗粒度分配，什么是细粒度分配，各自的优点和缺点是什么？"></a>Spark on Mesos 中，什么是的粗粒度分配，什么是细粒度分配，各自的优点和缺点是什么？</h3><ul><li>粗粒度：启动时就分配好资源，程序启动，后续具体使用就使用分配好的资源，不需要再分配资源；好处：作业特别多时，资源复用率高，适合粗粒度；不好：容易资源浪费，假如一个 job 有 1000 个 Task，完成了 999 个，还有一个没完成，那么使用粗粒度，999 个资源就会闲置在那里，资源浪费。</li><li>细粒度分配：用资源的时候分配，用完了就立即回收资源，启动会麻烦一点，启动一次分配一次，会比较麻烦。</li></ul><h3 id="Driver-的功能是什么？"><a href="#Driver-的功能是什么？" class="headerlink" title="Driver 的功能是什么？"></a>Driver 的功能是什么？</h3><ul><li>一个 Spark 作业运行时包括一个 Driver 进程，也是作业的主进程，具有 main 函数，并且有 SparkContext 的实例，是程序的入口点；</li><li>功能：负责向集群申请资源，向 master 注册信息，负责了作业的调度，负责作业的解析、生成 Stage 并调度 Task 到 Executor 上。包括 DAG Scheduler，Task Scheduler。</li></ul><h3 id="Spark-技术栈有哪些组件，每个组件都有什么功能，适合什么应用场景？"><a href="#Spark-技术栈有哪些组件，每个组件都有什么功能，适合什么应用场景？" class="headerlink" title="Spark 技术栈有哪些组件，每个组件都有什么功能，适合什么应用场景？"></a>Spark 技术栈有哪些组件，每个组件都有什么功能，适合什么应用场景？</h3><p>​可以画一个技术栈图先，然后分别解释下每个组件的功能和场景</p><ul><li>Spark Core：是其它组件的基础，Spark 的内核，主要包含：DAG、RDD、Lineage、Cache、broadcast 等，并封装了底层通讯框架，是 Spark 的基础。</li><li>Spark Streaming：是一个对实时数据流进行高通量、容错处理的流式处理系统，可以对多种数据源（如 Kafka、Flume、Twitter、Zero 和 TCP Socket）进行类似 Map、Reduce 和 Join 等复杂操作，将流式计算分解成一系列短小的批处理作业。</li><li>Spark SQL：Shark 是 SparkSQL 的前身，Spark SQL 的一个重要特点是其能够统一处理关系表和 RDD，使得开发人员可以轻松地使用 SQL 命令进行外部查询，同时进行更复杂的数据分析。</li><li>BlinkDB：是一个用于在海量数据上运行交互式 SQL 查询的大规模并行查询引擎，它允许用户通过权衡数据精度来提升查询响应时间，其数据的精度被控制在允许的误差范围内。</li><li>MLBase：是 Spark 生态圈的一部分专注于机器学习，让机器学习的门槛更低，让一些可能并不了解机器学习的用户也能方便地使用 MLBase。MLBase 分为四部分：MLlib、MLI、ML Optimizer 和 MLRuntime。</li><li>GraphX：是 Spark 中用于图和图并行计算。</li></ul><h3 id="Spark-中-Worker-的主要工作是什么？"><a href="#Spark-中-Worker-的主要工作是什么？" class="headerlink" title="Spark 中 Worker 的主要工作是什么？"></a>Spark 中 Worker 的主要工作是什么？</h3><p>​主要功能：管理当前节点内存，CPU 的使用状况，接收 master 分配过来的资源指令，通过 ExecutorRunner 启动程序分配任务，Worker 就类似于包工头，管理分配新进程，做计算的服务，相当于 process 服务。</p><p>​需要注意的是：</p><ul><li>Worker 不会汇报当前信息给 master，worker 心跳给 master 主要只有 workid，它不会发送资源信息以心跳的方式给 mater，master 分配的时候就知道 Worker，只有出现故障的时候才会发送资源。</li><li>Worker 不会运行代码，具体运行的是 Executor 是可以运行具体 Application 写的业务逻辑代码，操作代码的节点，它不会运行程序的代码的。</li></ul><h3 id="MapReduce-和-Spark-的都是并行计算，那么他们有什么相同和区别？"><a href="#MapReduce-和-Spark-的都是并行计算，那么他们有什么相同和区别？" class="headerlink" title="MapReduce 和 Spark 的都是并行计算，那么他们有什么相同和区别？"></a>MapReduce 和 Spark 的都是并行计算，那么他们有什么相同和区别？</h3><p>​两者都是用 MR 模型来进行并行计算:：</p><ul><li>Hadoop 的一个作业称为 job，job 里面分为 map task 和 reduce task，每个 task 都是在自己的进程中运行的，当 task 结束时，进程也会结束。</li><li>Spark 用户提交的任务成为 Application，一个 Application 对应一个 SparkContext，Application 中存在多个 job，每触发一次 action 操作就会产生一个 job。这些 job 可以并行或串行执行，每个 job 中有多个 Stage，Stage 是 shuffle 过程中 DAG Scheduler 通过 RDD 之间的依赖关系划分 job 而来的，每个 Stage 里面有多个 Task，组成 TaskSet 由 Task Scheduler 分发到各个 Executor 中执行，Executor 的生命周期是和 Application 一样的，即使没有 job 运行也是存在的，所以 Task 可以快速启动读取内存进行计算。</li><li>Hadoop 的 job 只有 map 和 reduce 操作，表达能力比较欠缺而且在 MR 过程中会重复的读写 HDFS，造成大量的 IO 操作，多个 job 需要自己管理关系。</li><li>Spark 的迭代计算都是在内存中进行的，API 中提供了大量的 RDD 操作如 join，groupBy 等，而且通过 DAG 图可以实现良好的容错。</li></ul><h3 id="RDD-机制？"><a href="#RDD-机制？" class="headerlink" title="RDD 机制？"></a>RDD 机制？</h3><p>​RDD 分布式弹性数据集，简单的理解成一种数据结构，是 Spark 框架上的通用货币。所有算子都是基于 RDD 来执行的，不同的场景会有不同的 RDD 实现类，但是都可以进行互相转换。RDD 执行过程中会形成 DAG 图，然后形成 Lineage 保证容错性等。从物理的角度来看 RDD 存储的是 block 和 node 之间的映射。</p><h3 id="什么是-RDD-宽依赖和窄依赖？"><a href="#什么是-RDD-宽依赖和窄依赖？" class="headerlink" title="什么是 RDD 宽依赖和窄依赖？"></a>什么是 RDD 宽依赖和窄依赖？</h3><p>​RDD 和它依赖的 parent RDD(s) 的关系有两种不同的类型，即窄依赖（narrow dependency）和宽依赖（wide dependency）。</p><ul><li>窄依赖指的是每一个 parent RDD 的 Partition 最多被子 RDD 的一个 Partition 使用</li><li>宽依赖指的是多个子 RDD 的 Partition 会依赖同一个 parent RDD 的 Partition。</li></ul><h3 id="cache-和-persist-的区别？"><a href="#cache-和-persist-的区别？" class="headerlink" title="cache 和 persist 的区别？"></a>cache 和 persist 的区别？</h3><p>​cache 和 persist 都是用于将一个 RDD 进行缓存的，这样在之后使用的过程中就不需要重新计算了，可以大大节省程序运行时间</p><ul><li>cache 只有一个默认的缓存级别 <code>MEMORY_ONLY</code>，cache 调用了 persist，而 persist 可以根据情况设置其它的缓存级别；</li><li>Executor 执行的时候，默认 60% 做 cache，40% 做 task 操作，persist 是最根本的函数，最底层的函数。</li></ul><h3 id="cache-后面能不能接其他算子，它是不是-action-操作？"><a href="#cache-后面能不能接其他算子，它是不是-action-操作？" class="headerlink" title="cache 后面能不能接其他算子，它是不是 action 操作？"></a>cache 后面能不能接其他算子，它是不是 action 操作？</h3><ul><li>cache 可以接其他算子，但是接了算子之后，起不到缓存应有的效果，因为会重新触发 cache。</li><li>cache 不是 action 操作</li></ul><h3 id="reduceByKey-是不是-action？"><a href="#reduceByKey-是不是-action？" class="headerlink" title="reduceByKey 是不是 action？"></a>reduceByKey 是不是 action？</h3><p>​不是，很多人都会以为是 action，reduce 是 action。</p><h3 id="RDD-通过-Lineage（记录数据更新）的方式为何很高效？"><a href="#RDD-通过-Lineage（记录数据更新）的方式为何很高效？" class="headerlink" title="RDD 通过 Lineage（记录数据更新）的方式为何很高效？"></a>RDD 通过 Lineage（记录数据更新）的方式为何很高效？</h3><ul><li>lazy 记录了数据的来源，RDD 是不可变的，且是 lazy 级别的，且 RDD 之间构成了链条，lazy 是弹性的基石。由于 RDD 不可变，所以每次操作就产生新的 RDD，不存在全局修改的问题，控制难度下降，所有有计算链条将复杂计算链条存储下来，计算的时候从后往前回溯是上一个 Stage 的结束，要么就 checkpoint。</li><li>记录原数据，是每次修改都记录，代价很大如果修改一个集合，代价就很小，官方说 RDD 是粗粒度的操作，是为了效率，为了简化，每次都是操作数据集合，写或者修改操作，都是基于集合的 RDD 的写操作是粗粒度的，RDD 的读操作既可以是粗粒度的也可以是细粒度，读可以读其中的一条条的记录。</li><li>简化复杂度，是高效率的一方面，写的粗粒度限制了使用场景如网络爬虫，现实世界中，大多数写是粗粒度的场景。</li></ul><h3 id="为什么要进行序列化序列化？"><a href="#为什么要进行序列化序列化？" class="headerlink" title="为什么要进行序列化序列化？"></a>为什么要进行序列化序列化？</h3><p>​可以减少数据的体积，减少存储空间，高效存储和传输数据，不好的是在使用的时候要反序列化，非常消耗 CPU。</p><h3 id="Yarn-中的-Container-是由谁负责销毁的，在-Hadoop-MapReduce-中-Container-可以复用么？"><a href="#Yarn-中的-Container-是由谁负责销毁的，在-Hadoop-MapReduce-中-Container-可以复用么？" class="headerlink" title="Yarn 中的 Container 是由谁负责销毁的，在 Hadoop MapReduce 中 Container 可以复用么？"></a>Yarn 中的 Container 是由谁负责销毁的，在 Hadoop MapReduce 中 Container 可以复用么？</h3><p>​ApplicationMaster 负责销毁，在 Hadoop MapReduce 不可以复用，在 Spark on Yarn 程序 Container 可以复用。</p><h3 id="提交任务时，如何指定-Spark-Application-的运行模式？"><a href="#提交任务时，如何指定-Spark-Application-的运行模式？" class="headerlink" title="提交任务时，如何指定 Spark Application 的运行模式？"></a>提交任务时，如何指定 Spark Application 的运行模式？</h3><ul><li>cluster 模式：<code>./spark-submit --class xx.xx.xx --master yarn --deploy-mode cluster xx.jar</code></li><li>client 模式：<code>./spark-submit --class xx.xx.xx --master yarn --deploy-mode client xx.jar</code></li></ul><h3 id="不启动-Spark-集群-Master-和-Worker-服务，可不可以运行-Spark-程序？"><a href="#不启动-Spark-集群-Master-和-Worker-服务，可不可以运行-Spark-程序？" class="headerlink" title="不启动 Spark 集群 Master 和 Worker 服务，可不可以运行 Spark 程序？"></a>不启动 Spark 集群 Master 和 Worker 服务，可不可以运行 Spark 程序？</h3><p>​可以，只要资源管理器第三方管理就可以，如由 Yarn 管理，Spark 集群不启动也可以使用 Spark；Spark 集群启动的是 Worker 和 Master，这个其实就是资源管理框架，Yarn 中的 ResourceManager 相当于 Master，NodeManager 相当于 Worker，做计算是 Executor，和 Spark 集群的 Worker 和 Manager 可以没关系，归根接底还是 JVM 的运行，只要所在的 JVM 上安装了 Spark 就可以。</p><h3 id="Spark-on-Yarn-Cluster-模式下，ApplicationMaster-和-Driver-是在同一个进程么？"><a href="#Spark-on-Yarn-Cluster-模式下，ApplicationMaster-和-Driver-是在同一个进程么？" class="headerlink" title="Spark on Yarn Cluster 模式下，ApplicationMaster 和 Driver 是在同一个进程么？"></a>Spark on Yarn Cluster 模式下，ApplicationMaster 和 Driver 是在同一个进程么？</h3><p>​是，Driver 位于 ApplicationMaster 进程中。该进程负责申请资源，还负责监控程序、资源的动态情况。</p><h3 id="运行在-Yarn-中-Application-有几种类型的-Container？"><a href="#运行在-Yarn-中-Application-有几种类型的-Container？" class="headerlink" title="运行在 Yarn 中 Application 有几种类型的 Container？"></a>运行在 Yarn 中 Application 有几种类型的 Container？</h3><ul><li>运行 ApplicationMaster 的 Container：这是由 ResourceManager（向内部的资源调度器）申请和启动的，用户提交应用程序时，可指定唯一的 ApplicationMaster 所需的资源；</li><li>运行各类任务的 Container：这是由 ApplicationMaster 向 ResourceManager 申请的，并由 ApplicationMaster 与 NodeManager 通信以启动之。</li></ul><h3 id="Executor-启动时，资源通过哪几个参数指定？"><a href="#Executor-启动时，资源通过哪几个参数指定？" class="headerlink" title="Executor 启动时，资源通过哪几个参数指定？"></a>Executor 启动时，资源通过哪几个参数指定？</h3><ul><li><code>num-executors</code>：Executor 的数量；</li><li><code>executor-memory</code>：每个 Executor 使用的内存；</li><li><code>executor-cores</code>：每个 Executor 分配的 CPU。</li></ul><h3 id="列出你所知道的调度器，说明其工作原理"><a href="#列出你所知道的调度器，说明其工作原理" class="headerlink" title="列出你所知道的调度器，说明其工作原理"></a>列出你所知道的调度器，说明其工作原理</h3><ul><li>FIFO Schedular：默认的调度器，先进先出；</li><li>Capacity Schedular：计算能力调度器，选择占用内存小，优先级高的；</li><li>Fair Schedular：公平调度器，所有 job 占用相同资源。</li></ul><h3 id="导致-Executor-产生-FULL-GC-的原因，可能导致什么问题？"><a href="#导致-Executor-产生-FULL-GC-的原因，可能导致什么问题？" class="headerlink" title="导致 Executor 产生 FULL GC 的原因，可能导致什么问题？"></a>导致 Executor 产生 FULL GC 的原因，可能导致什么问题？</h3><p>​可能导致 Executor 僵死问题，海量数据的 shuffle 和数据倾斜等都可能导致 FULL GC。以 shuffle 为例，伴随着大量的 shuffle 写操作，JVM 的新生代不断 GC，Eden Space 写满了就往 Survivor Space 写，同时超过一定大小的数据会直接写到老生代，当新生代写满了之后，也会把老的数据搞到老生代，如果老生代空间不足了，就触发 FULL GC，还是空间不够，那就 OOM 错误了，此时线程被 Blocked，导致整个 Executor 处理数据的进程被卡住。</p><h3 id="Spark-累加器有哪些特点？"><a href="#Spark-累加器有哪些特点？" class="headerlink" title="Spark 累加器有哪些特点？"></a>Spark 累加器有哪些特点？</h3><ul><li>累加器在全局唯一的，只增不减，记录全局集群的唯一状态；</li><li>在 Executor 中修改它，在 Driver 读取；</li><li>Executor 级别共享的，广播变量是 task 级别的共享，两个 Application 不可以共享累加器，但是同一个 Application 不同的 job 可以共享。</li></ul><h3 id="HashPartitioner-的弊端是什么？"><a href="#HashPartitioner-的弊端是什么？" class="headerlink" title="HashPartitioner 的弊端是什么？"></a>HashPartitioner 的弊端是什么？</h3><p>​HashPartitioner 分区的原理很简单，对于给定的 key，计算其 HashCode，并除于分区的个数取余，如果余数小于 0，则用余数 + 分区的个数，最后返回的值就是这个 key 所属的分区 ID；弊端是数据不均匀，容易导致数据倾斜，极端情况下某几个分区会拥有 RDD 的所有数据。</p><h3 id="RangePartitioner-分区的原理？"><a href="#RangePartitioner-分区的原理？" class="headerlink" title="RangePartitioner 分区的原理？"></a>RangePartitioner 分区的原理？</h3><p>​RangePartitioner 分区则尽量保证每个分区中数据量的均匀，而且分区与分区之间是有序的，也就是说一个分区中的元素肯定都是比另一个分区内的元素小或者大；但是分区内的元素是不能保证顺序的。简单的说就是将一定范围内的数映射到某一个分区内。其原理是水塘抽样。RangePartitioner 作用：将一定范围内的数映射到某一个分区内，在实现中，分界的算法尤为重要。算法对应的函数是 rangeBounds。</p><h3 id="如何理解-Standalone-模式下，Spark-资源分配是粗粒度的？"><a href="#如何理解-Standalone-模式下，Spark-资源分配是粗粒度的？" class="headerlink" title="如何理解 Standalone 模式下，Spark 资源分配是粗粒度的？"></a>如何理解 Standalone 模式下，Spark 资源分配是粗粒度的？</h3><p>Spark 默认情况下资源分配是粗粒度的，也就是说程序在提交时就分配好资源，后面执行的时候使用分配好的资源，除非资源出现了故障才会重新分配。比如 Spark shell 启动，已提交，一注册，哪怕没有任务，Worker 都会分配资源给 Executor。</p><h3 id="union-操作是产生宽依赖还是窄依赖？"><a href="#union-操作是产生宽依赖还是窄依赖？" class="headerlink" title="union 操作是产生宽依赖还是窄依赖？"></a>union 操作是产生宽依赖还是窄依赖？</h3><p>​产生窄依赖。</p><h3 id="窄依赖父-RDD-的-partition-和子-RDD-的-partition-是不是都是一对一的关系？"><a href="#窄依赖父-RDD-的-partition-和子-RDD-的-partition-是不是都是一对一的关系？" class="headerlink" title="窄依赖父 RDD 的 partition 和子 RDD 的 partition 是不是都是一对一的关系？"></a>窄依赖父 RDD 的 partition 和子 RDD 的 partition 是不是都是一对一的关系？</h3><p>​不一定，除了一对一的窄依赖，还包含一对固定个数的窄依赖（就是对父 RDD 的依赖的 Partition 的数量不会随着 RDD 数量规模的改变而改变），比如 join 操作的每个 partition 仅仅和已知的 partition 进行 join，这个 join 操作是窄依赖，依赖固定数量的父 RDD，因为是确定的 partition 关系。</p><h3 id="Hadoop-中，MapReduce-操作的-mapper-和-reducer-阶段相当于-Spark-中的哪几个算子？"><a href="#Hadoop-中，MapReduce-操作的-mapper-和-reducer-阶段相当于-Spark-中的哪几个算子？" class="headerlink" title="Hadoop 中，MapReduce 操作的 mapper 和 reducer 阶段相当于 Spark 中的哪几个算子？"></a>Hadoop 中，MapReduce 操作的 mapper 和 reducer 阶段相当于 Spark 中的哪几个算子？</h3><p>​相当于 Spark 中的 map 算子和 reduceByKey 算子，当然还是有点区别的，MR 会自动进行排序的，Spark 要看你用的是什么 Partitioner。</p><h3 id="什么是-shuffle，以及为什么需要-shuffle？"><a href="#什么是-shuffle，以及为什么需要-shuffle？" class="headerlink" title="什么是 shuffle，以及为什么需要 shuffle？"></a>什么是 shuffle，以及为什么需要 shuffle？</h3><p>​shuffle 中文翻译为洗牌，需要 shuffle 的原因是：某种具有共同特征的数据汇聚到一个计算节点上进行计算。</p><h3 id="Spark-中的-HashShuffle-的有哪些不足？"><a href="#Spark-中的-HashShuffle-的有哪些不足？" class="headerlink" title="Spark 中的 HashShuffle 的有哪些不足？"></a>Spark 中的 HashShuffle 的有哪些不足？</h3><ul><li>shuffle 产生海量的小文件在磁盘上，此时会产生大量耗时的、低效的 IO 操作；</li><li>容易导致内存不够用，由于内存需要保存海量的文件操作句柄和临时缓存信息，如果数据处理规模比较大的话，容易出现 OOM；</li><li>容易出现数据倾斜，导致 OOM。</li></ul><h3 id="consolidate-是如何优化-Hash-shuffle-时在-map-端产生的小文件？"><a href="#consolidate-是如何优化-Hash-shuffle-时在-map-端产生的小文件？" class="headerlink" title="consolidate 是如何优化 Hash shuffle 时在 map 端产生的小文件？"></a>consolidate 是如何优化 Hash shuffle 时在 map 端产生的小文件？</h3><ul><li>consolidate 为了解决 Hash Shuffle 同时打开过多文件导致 Writer handler 内存使用过大以及产生过多文件导致大量的随机读写带来的低效磁盘 IO；</li><li>consolidate 根据 CPU 的个数来决定每个 task shuffle map 端产生多少个文件，假设原来有 10 个 task，100 个 reduce，每个节点有 10 个 CPU，那么使用 hash shuffle 会产生 <code>10*100=1000</code> 个文件，consolidate 产生 <code>10*10=100</code> 个文件</li></ul><p>​注意：consolidate 部分减少了文件和文件句柄，并行读很高的情况下（task 很多时）还是会很多文件。</p><h3 id="spark-default-parallelism-这个参数有什么意义，实际生产中如何设置？"><a href="#spark-default-parallelism-这个参数有什么意义，实际生产中如何设置？" class="headerlink" title="spark.default.parallelism 这个参数有什么意义，实际生产中如何设置？"></a>spark.default.parallelism 这个参数有什么意义，实际生产中如何设置？</h3><ul><li>参数用于设置每个 Stage 的默认 Task 数量。这个参数极为重要，如果不设置可能会直接影响你的 Spark 作业性能；</li><li>很多人都不会设置这个参数，会使得集群非常低效，你的 CPU，内存再多，如果 Task 始终为 1，那也是浪费，Spark 官网建议 Task 个数为 <code>CPU 的核数 * Executor 的个数的 2~3 倍</code>。</li></ul><h3 id="spark-shuffle-memoryFraction-参数的含义，以及优化经验？"><a href="#spark-shuffle-memoryFraction-参数的含义，以及优化经验？" class="headerlink" title="spark.shuffle.memoryFraction 参数的含义，以及优化经验？"></a>spark.shuffle.memoryFraction 参数的含义，以及优化经验？</h3><ul><li><code>spark.shuffle.memoryFraction</code> 是 shuffle 调优中 重要参数，shuffle 从上一个 task 拉去数据过来，要在 Executor 进行聚合操作，聚合操作时使用 Executor 内存的比例由该参数决定，默认是 20%，如果聚合时数据超过了该大小，那么就会 spill 到磁盘，极大降低性能；</li><li>如果 Spark 作业中的 RDD 持久化操作较少，shuffle 操作较多时，建议降低持久化操作的内存占比，提高 shuffle 操作的内存占比比例，避免 shuffle 过程中数据过多时内存不够用，必须溢写到磁盘上，降低了性能。此外，如果发现作业由于频繁的 GC 导致运行缓慢，意味着 task 执行用户代码的内存不够用，那么同样建议调低这个参数的值。</li></ul><h3 id="Spark-中-Standalone-模式特点，有哪些优点和缺点？"><a href="#Spark-中-Standalone-模式特点，有哪些优点和缺点？" class="headerlink" title="Spark 中 Standalone 模式特点，有哪些优点和缺点？"></a>Spark 中 Standalone 模式特点，有哪些优点和缺点？</h3><ul><li>特点：<ul><li>Standalone 是 Master/Slave 架构，集群由 Master 与 Worker 节点组成，程序通过与 Master 节点交互申请资源，Worker 节点启动 Executor 运行；</li><li>Standalone 调度模式使用 FIFO 调度方式；</li><li>无依赖任何其他资源管理系统，Master 负责管理集群资源</li></ul></li><li>优点：<ul><li>部署简单；</li><li>不依赖其他资源管理系统。</li></ul></li><li>缺点：<ul><li>默认每个应用程序会独占所有可用节点的资源，当然可以通过 <code>spark.cores.max</code> 来决定一个应用可以申请的 CPU cores 个数；</li><li>可能有单点故障，需要自己配置 master HA。</li></ul></li></ul><h3 id="FIFO-调度模式的基本原理、优点和缺点？"><a href="#FIFO-调度模式的基本原理、优点和缺点？" class="headerlink" title="FIFO 调度模式的基本原理、优点和缺点？"></a>FIFO 调度模式的基本原理、优点和缺点？</h3><p>​基本原理：按照先后顺序决定资源的使用，资源优先满足最先来的 job。第一个 job 优先获取所有可用的资源，接下来第二个 job 再获取剩余资源。以此类推，如果第一个 job 没有占用所有的资源，那么第二个 job 还可以继续获取剩余资源，这样多个 job 可以并行运行，如果第一个 job 很大，占用所有资源，则第二个 job 就需要等待，等到第一个 job 释放所有资源。</p><p>​优点和缺点：</p><ul><li>适合长作业，不适合短作业；</li><li>适合 CPU 繁忙型作业（计算时间长，相当于长作业），不利于 IO 繁忙型作业（计算时间短，相当于短作业）。</li></ul><h3 id="FAIR-调度模式的优点和缺点？"><a href="#FAIR-调度模式的优点和缺点？" class="headerlink" title="FAIR 调度模式的优点和缺点？"></a>FAIR 调度模式的优点和缺点？</h3><p>​所有的任务拥有大致相当的优先级来共享集群资源，Spark 多以轮询的方式为任务分配资源，不管长任务还是短任务都可以获得资源，并且获得不错的响应时间，对于短任务，不会像 FIFO 那样等待较长时间了，通过参数 <code>spark.scheduler.mode</code> 为 FAIR 指定。</p><h3 id="CAPACITY-调度模式的优点和缺点？"><a href="#CAPACITY-调度模式的优点和缺点？" class="headerlink" title="CAPACITY 调度模式的优点和缺点？"></a>CAPACITY 调度模式的优点和缺点？</h3><ul><li><p>原理：</p><p>计算能力调度器支持多个队列，每个队列可配置一定的资源量，每个队列采用 FIFO 调度策略，为了防止同一个用户的作业独占队列中的资源，该调度器会对同一用户提交的作业所占资源量进行限定。调度时，首先按以下策略选择一个合适队列：计算每个队列中正在运行的任务数与其应该分得的计算资源之间的比值（即比较空闲的队列），选择一个该比值最小的队列；然后按以下策略选择该队列中一个作业：按照作业优先级和提交时间顺序选择，同时考虑用户资源量限制和内存限制</p></li><li>优点：<ul><li>计算能力保证：支持多个队列，某个作业可被提交到某一个队列中。每个队列会配置一定比例的计算资源，且所有提交到队列中的作业共享该队列中的资源；</li><li>灵活性：空闲资源会被分配给那些未达到资源使用上限的队列，当某个未达到资源的队列需要资源时，一旦出现空闲资源资源，便会分配给他们；</li><li>支持优先级：队列支持作业优先级调度（默认是 FIFO）；</li><li>多重租赁：综合考虑多种约束防止单个作业、用户或者队列独占队列或者集群中的资源；</li><li>基于资源的调度：支持资源密集型作业，允许作业使用的资源量高于默认值，进而可容纳不同资源需求的作业。不过，当前仅支持内存资源的调度。</li></ul></li></ul><h3 id="常见的数据压缩方式，你们生产集群采用了什么压缩方式，提升了多少效率？"><a href="#常见的数据压缩方式，你们生产集群采用了什么压缩方式，提升了多少效率？" class="headerlink" title="常见的数据压缩方式，你们生产集群采用了什么压缩方式，提升了多少效率？"></a>常见的数据压缩方式，你们生产集群采用了什么压缩方式，提升了多少效率？</h3><ul><li>数据压缩，大片连续区域进行数据存储并且存储区域中数据重复性高的状况下，可以使用适当的压缩算法。数组，对象序列化后都可以使用压缩，数更紧凑，减少空间开销。常见的压缩方式有 snappy，LZO，gz 等</li><li>Hadoop 生产环境常用的是 snappy 压缩方式（使用压缩，实际上是 CPU 换 IO 吞吐量和磁盘空间，所以如果 CPU 利用率不高，不忙的情况下，可以大大提升集群处理效率）。snappy 压缩比一般 20%~30% 之间，并且压缩和解压缩效率也非常高：<ul><li>GZIP 的压缩率最高，但是其实 CPU 密集型的，对 CPU 的消耗比其他算法要多，压缩和解压速度也慢；</li><li>LZO 的压缩率居中，比 GZIP 要低一些，但是压缩和解压速度明显要比 GZIP 快很多，其中解压速度快的更多；</li><li>Zippy/Snappy 的压缩率最低，而压缩和解压速度要稍微比 LZO 要快一些。</li></ul></li><li>提升了多少效率可以从两个方面回答：<ul><li>数据存储节约多少存储，</li><li>任务执行消耗时间节约了多少，可以举个实际例子展开描述。</li></ul></li></ul><h3 id="使用-scala-代码实现-WordCount？"><a href="#使用-scala-代码实现-WordCount？" class="headerlink" title="使用 scala 代码实现 WordCount？"></a>使用 scala 代码实现 WordCount？</h3><p></p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">​<span class="keyword">val</span> conf = <span class="keyword">new</span> <span class="type">SparkConf</span>()</span><br><span class="line">​<span class="keyword">val</span> sc = <span class="keyword">new</span> <span class="type">SparkContext</span>(conf)</span><br><span class="line">​<span class="keyword">val</span> line = sc.textFile(<span class="string">&quot;xxxx.txt&quot;</span>)</span><br><span class="line">line.flatMap(_.split(<span class="string">&quot; &quot;</span>)).map((_,<span class="number">1</span>)).reduceByKey(_+_).collect().foreach(println)</span><br><span class="line">sc.stop()</span><br></pre></td></tr></table></figure><p></p><h3 id="Spark-RDD-和-MapReduce2-的区别？"><a href="#Spark-RDD-和-MapReduce2-的区别？" class="headerlink" title="Spark RDD 和 MapReduce2 的区别？"></a>Spark RDD 和 MapReduce2 的区别？</h3><ul><li>MR2 只有 2 个阶段，数据需要大量访问磁盘，数据来源相对单一，Spark RDD，可以无数个阶段进行迭代计算，数据来源非常丰富，数据落地介质也非常丰富 Spark 计算基于内存；</li><li>MR2 需要频繁操作磁盘 IO，需要大家明确的是，如果是 SparkRDD 的话，你要知道每一种数据来源对应的是什么，RDD 从数据源加载数据，将数据放到不同的 partition 针对这些 partition 中的数据进行迭代式计算计算完成之后，落地到不同的介质当中。</li></ul><h3 id="Spark-和-MapReduce-快？为什么快呢？快在哪里呢？"><a href="#Spark-和-MapReduce-快？为什么快呢？快在哪里呢？" class="headerlink" title="Spark 和 MapReduce 快？为什么快呢？快在哪里呢？"></a>Spark 和 MapReduce 快？为什么快呢？快在哪里呢？</h3><p>​Spark 更加快的主要原因有几点：</p><ul><li>基于内存计算，减少低效的磁盘交互；</li><li>高效的调度算法，基于 DAG；</li><li>容错机制 Lineage，主要是 DAG 和 Lineage，即使 Spark 不使用内存技术，也大大快于 MapReduce。</li></ul><h3 id="Spark-SQL-为什么比-Hive-快呢？"><a href="#Spark-SQL-为什么比-Hive-快呢？" class="headerlink" title="Spark SQL 为什么比 Hive 快呢？"></a>Spark SQL 为什么比 Hive 快呢？</h3><p>​计算引擎不一样，一个是 Spark 计算模型，一个是 MapReduce 计算模型。</p><h3 id="RDD-的数据结构是怎么样的？"><a href="#RDD-的数据结构是怎么样的？" class="headerlink" title="RDD 的数据结构是怎么样的？"></a>RDD 的数据结构是怎么样的？</h3><p>一个 RDD 对象，包含如下 5 个核心属性。</p><ul><li>一个分区列表，每个分区里是 RDD 的部分数据（或称数据块）。</li><li>一个依赖列表，存储依赖的其他 RDD。</li><li>一个名为 compute 的计算函数，用于计算 RDD 各分区的值。</li><li>分区器（可选），用于键/值类型的 RDD，比如某个 RDD 是按散列来分区。</li><li>计算各分区时优先的位置列表（可选），比如从 HDFS 上的文件生成 RDD 时，RDD 分区的位置优先选择数据所在的节点，这样可以避免数据移动带来的开销。</li></ul><h3 id="RDD-算子里操作一个外部-map，比如往里面-put-数据，然后算子外再遍历-map，会有什么问题吗？"><a href="#RDD-算子里操作一个外部-map，比如往里面-put-数据，然后算子外再遍历-map，会有什么问题吗？" class="headerlink" title="RDD 算子里操作一个外部 map，比如往里面 put 数据，然后算子外再遍历 map，会有什么问题吗？"></a>RDD 算子里操作一个外部 map，比如往里面 put 数据，然后算子外再遍历 map，会有什么问题吗？</h3><p>​频繁创建额外对象，容易 OOM。</p><h3 id="HBase-region-多大会分区，Spark-读取-HBase-数据是如何划分-partition-的？"><a href="#HBase-region-多大会分区，Spark-读取-HBase-数据是如何划分-partition-的？" class="headerlink" title="HBase region 多大会分区，Spark 读取 HBase 数据是如何划分 partition 的？"></a>HBase region 多大会分区，Spark 读取 HBase 数据是如何划分 partition 的？</h3><p>​region 超过了 <code>hbase.hregion.max.filesize</code> 这个参数配置的大小就会自动裂分，默认值是 1G。</p><p>​默认情况下，HBase 有多少个 region，Spark 读取时就会有多少个 partition</p><h2 id="Spark-调优"><a href="#Spark-调优" class="headerlink" title="Spark 调优"></a>Spark 调优</h2><h3 id="数据倾斜"><a href="#数据倾斜" class="headerlink" title="数据倾斜"></a>数据倾斜</h3><h3 id="什么是数据倾斜？"><a href="#什么是数据倾斜？" class="headerlink" title="什么是数据倾斜？"></a>什么是数据倾斜？</h3><p>数据倾斜指的是，并行处理的数据集中，某一部分（如 Spark 或 Kafka 的一个 Partition）的数据显著多于其它部分，从而使得该部分的处理速度成为整个数据集处理的瓶颈。</p><p>数据倾斜俩大直接致命后果。</p><ul><li>数据倾斜直接会导致一种情况：Out Of Memory。</li><li>运行速度慢。</li></ul><p>主要是发生在 Shuffle 阶段。同样 Key 的数据条数太多了。导致了某个 Key（下图中的 80 亿条）所在的 Task 数据量太大了。远远超过其他 Task 所处理的数据量。</p><p>一个经验结论是：<strong>一般情况下，OOM 的原因都是数据倾斜</strong></p><p><img src="https://npm.elemecdn.com/eurkon-cdn/hexo/images/user/loading.gif" data-lazy-src="/images/post/bigdata_interview/spark_skew.png" alt="数据倾斜"></p><h3 id="如何定位数据倾斜？"><a href="#如何定位数据倾斜？" class="headerlink" title="如何定位数据倾斜？"></a>如何定位数据倾斜？</h3><p>数据倾斜一般会发生在 shuffle 过程中。很大程度上是你使用了可能会触发 shuffle 操作的算子：distinct、groupByKey、reduceByKey、aggregateByKey、join、cogroup、repartition 等。</p><p>原因：查看任务 -&gt; 查看 Stage -&gt; 查看代码</p><ul><li>某个 task 执行特别慢的情况</li><li>某个 task 莫名其妙内存溢出的情况</li><li>查看导致数据倾斜的 key 的数据分布情况</li><li>是不是有 OOM 情况出现，一般是少数内存溢出的问题</li><li>是不是应用运行时间差异很大，总体时间很长</li><li>需要了解你所处理的数据 Key 的分布情况，如果有些 Key 有大量的条数，那么就要小心数据倾斜的问题</li><li>一般需要通过 Spark Web UI 和其他一些监控方式出现的异常来综合判断</li><li>看看代码里面是否有一些导致 Shuffle 的算子出现</li></ul><h3 id="数据倾斜的几种典型情况？"><a href="#数据倾斜的几种典型情况？" class="headerlink" title="数据倾斜的几种典型情况？"></a>数据倾斜的几种典型情况？</h3><ol><li>数据源中的数据分布不均匀，Spark 需要频繁交互</li><li>数据集中的不同 Key 由于分区方式，导致数据倾斜</li><li>JOIN 操作中，一个数据集中的数据分布不均匀，另一个数据集较小（主要）</li><li>聚合操作中，数据集中的数据分布不均匀（主要）</li><li>JOIN 操作中，两个数据集都比较大，其中只有几个 Key 的数据分布不均匀</li><li>JOIN 操作中，两个数据集都比较大，有很多 Key 的数据分布不均匀</li><li>数据集中少数几个 key 数据量很大，不重要，其他数据均匀</li></ol><p><strong>注意：</strong></p><ul><li>需要处理的数据倾斜问题就是 Shuffle 后数据的分布是否均匀问题</li><li>只要保证最后的结果是正确的，可以采用任何方式来处理数据倾斜，只要保证在处理过程中不发生数据倾斜就可以</li></ul><h3 id="数据倾斜的处理方法？"><a href="#数据倾斜的处理方法？" class="headerlink" title="数据倾斜的处理方法？"></a>数据倾斜的处理方法？</h3><ol><li><p>数据源中的数据分布不均匀，Spark 需要频繁交互</p><p>解决方案：避免数据源的数据倾斜。</p><p>实现原理：通过在 Hive 中对倾斜的数据进行预处理，以及在进行 Kafka 数据分发时尽量进行平均分配。这种方案从根源上解决了数据倾斜，彻底避免了在 Spark 中执行 shuffle 类算子，那么肯定就不会有数据倾斜的问题了。</p><p>方案优点：实现起来简单便捷，效果还非常好，完全规避掉了数据倾斜，Spark 作业的性能会大幅度提升。</p><p>方案缺点：治标不治本，Hive 或者 Kafka 中还是会发生数据倾斜。</p><p>适用情况：在一些 Java 系统与 Spark 结合使用的项目中，会出现 Java 代码频繁调用 Spark 作业的场景，而且对 Spark 作业的执行性能要求很高，就比较适合使用这种方案。将数据倾斜提前到上游的 Hive ETL，每天仅执行一次，只有那一次是比较慢的，而之后每次 Java 调用 Spark 作业时，执行速度都会很快，能够提供更好的用户体验。</p><p>总结：前台的 Java 系统和 Spark 有很频繁的交互，这个时候如果 Spark 能够在最短的时间内处理数据，往往会给前端有非常好的体验。这个时候可以将数据倾斜的问题抛给数据源端，在数据源端进行数据倾斜的处理。但是这种方案没有真正的处理数据倾斜问题。</p></li><li><p>数据集中的不同 Key 由于分区方式，导致数据倾斜</p><p>解决方案一：调整并行度。</p><p>实现原理：增加 shuffle read task 的数量，可以让原本分配给一个 task 的多个 key 分配给多个 task，从而让每个 task 处理比原来更少的数据。</p><p>方案优点：实现起来比较简单，可以有效缓解和减轻数据倾斜的影响。</p><p>方案缺点：只是缓解了数据倾斜而已，没有彻底根除问题，根据实践经验来看，其效果有限。</p><p>实践经验：该方案通常无法彻底解决数据倾斜，因为如果出现一些极端情况，比如某个 key 对应的数据量有 100 万，那么无论你的 task 数量增加到多少，都无法处理。</p><p>总结：调整并行度：适合于有大量 key 由于分区算法或者分区数的问题，将 key 进行了不均匀分区，可以通过调大或者调小分区数来试试是否有效。</p><p><img src="https://npm.elemecdn.com/eurkon-cdn/hexo/images/user/loading.gif" data-lazy-src="/images/post/bigdata_interview/spark_shuffle_read_task.png" alt="shuffle read task"></p><p>解决方案二：缓解数据倾斜（自定义 Partitioner）。</p><p>适用场景：大量不同的 Key 被分配到了相同的 Task 造成该 Task 数据量过大。</p><p>解决方案：使用自定义的 Partitioner 实现类代替默认的 HashPartitioner，尽量将所有不同的 Key 均匀分配到不同的 Task 中。</p><p>方案优点：不影响原有的并行度设计。如果改变并行度，后续 Stage 的并行度也会默认改变，可能会影响后续 Stage。</p><p>方案缺点：适用场景有限，只能将不同 Key 分散开，对于同一 Key 对应数据集非常大的场景不适用。效果与调整并行度类似，只能缓解数据倾斜而不能完全消除数据倾斜。而且需要根据数据特点自定义专用的 Partitioner，不够灵活。</p></li><li><p>JOIN 操作中，一个数据集中的数据分布不均匀，另一个数据集较小（主要）</p><p>解决方案：Reduce side Join 转变为 Map side Join。</p><p>适用场景：在对 RDD 使用 join 类操作，或者是在 Spark SQL 中使用 join 语句时，而且 join 操作中的一个 RDD 或表的数据量比较小（比如几百兆），比较适用此方案。</p><p>实现原理：普通的 join 是会走 shuffle 过程的，而一旦 shuffle，就相当于会将相同 key 的数据拉取到一个 shuffle read task 中再进行 join，此时就是 reduce join。但是如果一个 RDD 是比较小的，则可以采用广播小 RDD 全量数据 + map 算子来实现与 join 同样的效果，也就是 map join，此时就不会发生 shuffle 操作，也就不会发生数据倾斜。</p><p>方案优点：对 join 操作导致的数据倾斜，效果非常好，因为根本就不会发生 shuffle，也就根本不会发生数据倾斜。</p><p>方案缺点：适用场景较少，因为这个方案只适用于一个大表和一个小表的情况。</p></li><li><p>聚合操作中，数据集中的数据分布不均匀（主要）</p><p>解决方案：两阶段聚合（局部聚合 + 全局聚合）。</p><p>适用场景：对 RDD 执行 reduceByKey 等聚合类 shuffle 算子或者在 Spark SQL 中使用 group by 语句进行分组聚合时，比较适用这种方案。</p><p>实现原理：将原本相同的 key 通过附加随机前缀的方式，变成多个不同的 key，就可以让原本被一个 task 处理的数据分散到多个 task 上去做局部聚合，进而解决单个 task 处理数据量过多的问题。接着去除掉随机前缀，再次进行全局聚合，就可以得到最终的结果。具体原理见下图。</p><p><img src="https://npm.elemecdn.com/eurkon-cdn/hexo/images/user/loading.gif" data-lazy-src="/images/post/bigdata_interview/spark_prefix.png" alt="附加随机前缀两阶段聚合"></p><p>方案优点：对于聚合类的 shuffle 操作导致的数据倾斜，效果是非常不错的。通常都可以解决掉数据倾斜，或者至少是大幅度缓解数据倾斜，将 Spark 作业的性能提升数倍以上。</p><p>方案缺点：仅仅适用于聚合类的 shuffle 操作，适用范围相对较窄。如果是 join 类的 shuffle 操作，还得用其他的解决方案，将相同 key 的数据分拆处理。</p></li><li><p>JOIN 操作中，两个数据集都比较大，其中只有几个 Key 的数据分布不均匀</p><p>解决方案：为倾斜 key 增加随机前/后缀。</p><p>适用场景：两张表都比较大，无法使用 Map 侧 Join。其中一个 RDD 有少数几个 Key 的数据量过大，另外一个 RDD 的 Key 分布较为均匀。</p><p>解决方案：将有数据倾斜的 RDD 中倾斜 Key 对应的数据集单独抽取出来加上随机前缀，另外一个 RDD 每条数据分别与随机前缀结合形成新的 RDD（笛卡尔积，相当于将其数据增到到原来的 N 倍，N 即为随机前缀的总个数），然后将二者 Join 后去掉前缀。然后将不包含倾斜 Key 的剩余数据进行 Join。最后将两次 Join 的结果集通过 union 合并，即可得到全部 Join 结果。</p><p>方案优点：相对于 Map 侧 Join，更能适应大数据集的 Join。如果资源充足，倾斜部分数据集与非倾斜部分数据集可并行进行，效率提升明显。且只针对倾斜部分的数据做数据扩展，增加的资源消耗有限。</p><p>方案缺点：如果倾斜 Key 非常多，则另一侧数据膨胀非常大，此方案不适用。而且此时对倾斜 Key 与非倾斜 Key 分开处理，需要扫描数据集两遍，增加了开销。</p><p>注意：具有倾斜 Key 的 RDD 数据集中，key 的数量比较少。</p><p><img src="https://npm.elemecdn.com/eurkon-cdn/hexo/images/user/loading.gif" data-lazy-src="/images/post/bigdata_interview/spark_prefix_suffix.png" alt="为倾斜 key 增加随机前/后缀"></p></li><li><p>JOIN 操作中，两个数据集都比较大，有很多 Key 的数据分布不均匀</p><p>解决方案：随机前缀和扩容 RDD 进行 join。</p><p>适用场景：如果在进行 join 操作时，RDD 中有大量的 key 导致数据倾斜，那么进行分拆 key 也没什么意义。</p><p>实现思路：将该 RDD 的每条数据都打上一个 N 以内的随机前缀。同时对另外一个正常的 RDD 进行扩容，将每条数据都扩容成 N 条数据，扩容出来的每条数据都依次打上一个 1~N 的前缀。最后将两个处理后的 RDD 进行 join 即可。和上一种方案是尽量只对少数倾斜 key 对应的数据进行特殊处理，由于处理过程需要扩容 RDD，因此上一种方案扩容 RDD 后对内存的占用并不大；而这一种方案是针对有大量倾斜 key 的情况，没法将部分 key 拆分出来进行单独处理，因此只能对整个 RDD 进行数据扩容，对内存资源要求很高。</p><p>方案优点：对 join 类型的数据倾斜基本都可以处理，而且效果也相对比较显著，性能提升效果非常不错。</p><p>方案缺点：该方案更多的是缓解数据倾斜，而不是彻底避免数据倾斜。而且需要对整个 RDD 进行扩容，对内存资源要求很高。</p><p>实践经验：曾经开发一个数据需求的时候，发现一个 join 导致了数据倾斜。优化之前，作业的执行时间大约是 60 分钟左右；使用该方案优化之后，执行时间缩短到 10 分钟左右，性能提升了 6 倍。</p><p>注意：将倾斜 Key 添加 1-N 的随机前缀，并将被 Join 的数据集相应的扩大 N 倍（需要将 1-N 数字添加到每一条数据上作为前缀）</p><p><img src="https://npm.elemecdn.com/eurkon-cdn/hexo/images/user/loading.gif" data-lazy-src="/images/post/bigdata_interview/spark_prefix_join.png" alt="随机前缀和扩容 RDD 进行 join"></p></li><li><p>数据集中少数几个 key 数据量很大，不重要，其他数据均匀</p><p>解决方案：过滤少数倾斜 Key。</p><p>适用场景：如果发现导致倾斜的 key 就少数几个，而且对计算本身的影响并不大的话，那么很适合使用这种方案。比如 99% 的 key 就对应 10 条数据，但是只有一个 key 对应了 100 万数据，从而导致了数据倾斜。</p><p>方案优点：实现简单，而且效果也很好，可以完全规避掉数据倾斜。</p><p>方案缺点：适用场景不多，大多数情况下，导致倾斜的 key 还是很多的，并不是只有少数几个。</p><p>实践经验：在项目中我们也采用过这种方案解决数据倾斜。有一次发现某一天 Spark 作业在运行的时候突然 OOM 了，追查之后发现，是 Hive 表中的某一个 key 在那天数据异常，导致数据量暴增。因此就采取每次执行前先进行采样，计算出样本中数据量最大的几个 key 之后，直接在程序中将那些 key 给过滤掉。</p></li></ol><h3 id="资源调优"><a href="#资源调优" class="headerlink" title="资源调优"></a>资源调优</h3><h3 id="资源运行中的集中情况"><a href="#资源运行中的集中情况" class="headerlink" title="资源运行中的集中情况"></a>资源运行中的集中情况</h3><ul><li>实践中跑的 Spark job，有的特别慢，查看 CPU 利用率很低，可以尝试减少每个 executor 占用 CPU core 的数量，增加并行的 executor 数量，同时配合增加分片，整体上增加了 CPU 的利用率，加快数据处理速度。</li><li>发现某 job 很容易发生内存溢出，我们就增大分片数量，从而减少了每片数据的规模，同时还减少并行的 executor 数量，这样相同的内存资源分配给数量更少的 executor，相当于增加了每个 task 的内存分配，这样运行速度可能慢了些，但是总比 OOM 强。</li><li>数据量特别少，有大量的小文件生成，就减少文件分片，没必要创建那么多 task，这种情况，如果只是最原始的 input 比较小，一般都能被注意到；但是，如果是在运算过程中，比如应用某个 reduceBy 或者某个 filter 以后，数据大量减少，这种低效情况就很少被留意到。</li></ul><h3 id="运行资源优化配置"><a href="#运行资源优化配置" class="headerlink" title="运行资源优化配置"></a>运行资源优化配置</h3><p>一个 CPU core 同一时间只能执行一个线程。而每个 Executor 进程上分配到的多个 task，都是以每个 task 一条线程的方式，多线程并发运行的。</p><p>一个应用提交的时候设置多大的内存？设置多少 Core？ 设置几个 Executor？</p><p></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">./bin/spark-submit \</span><br><span class="line">  --master yarn-cluster \</span><br><span class="line">  --num-executors 100 \</span><br><span class="line">  --executor-memory 6G \</span><br><span class="line">  --executor-cores 4 \</span><br><span class="line">  --driver-memory 1G \</span><br><span class="line">  --conf spark.default.parallelism=1000 \</span><br><span class="line">  --conf spark.storage.memoryFraction=0.5 \</span><br><span class="line">  --conf spark.shuffle.memoryFraction=0.3</span><br></pre></td></tr></table></figure><p></p><ol><li><p><code>-num-executors</code></p><ul><li><p>参数说明：该参数用于设置 Spark 作业总共要用多少个 Executor 进程来执行。Driver 在向 YARN 集群管理器申请资源时，YARN 集群管理器会尽可能按照你的设置来在集群的各个工作节点上，启动相应数量的 Executor 进程。这个参数非常之重要，如果不设置的话，默认只会给你启动少量的 Executor 进程，此时你的 Spark 作业的运行速度是非常慢的。</p></li><li><p>调优建议：每个 Spark 作业的运行一般设置 50~100 个左右的 Executor 进程比较合适，设置太少或太多的 Executor 进程都不好。设置的太少，无法充分利用集群资源；设置的太多的话，大部分队列可能无法给予充分的资源。</p></li></ul></li><li><p><code>-executor-memory</code></p><ul><li><p>参数说明：该参数用于设置每个 Executor 进程的内存。Executor 内存的大小，很多时候直接决定了 Spark 作业的性能，而且跟常见的 JVM OOM 异常，也有直接的关联。</p></li><li><p>调优建议：每个 Executor 进程的内存设置 4G~8G 较为合适。但是这只是一个参考值，具体的设置还是得根据不同部门的资源队列来定。可以看看自己团队的资源队列的最大内存限制是多少，<code>num-executors * executor-memory</code>，是不能超过队列的最大内存量的。此外，如果你是跟团队里其他人共享这个资源队列，那么申请的内存量最好不要超过资源队列最大总内存的 1/3~1/2，避免你自己的 Spark 作业占用了队列所有的资源，导致别的同事的作业无法运行。</p></li></ul></li><li><p><code>-executor-cores</code></p><ul><li><p>参数说明：该参数用于设置每个 Executor 进程的 CPU core 数量。这个参数决定了每个 Executor 进程并行执行 task 线程的能力。因为每个 CPU core 同一时间只能执行一个 task 线程，因此每个 Executor 进程的 CPU core 数量越多，越能够快速地执行完分配给自己的所有 task 线程。</p></li><li><p>调优建议：Executor 的 CPU core 数量设置为 2~4 个较为合适。同样得根据不同部门的资源队列来定，可以看看自己的资源队列的最大 CPU core 限制是多少，再依据设置的 Executor 数量，来决定每个 Executor 进程可以分配到几个 CPU core。同样建议，如果是跟他人共享这个队列，那么 <code>num-executors * executor-cores</code> 不要超过队列总 CPU core 的 1/3~1/2 左右比较合适，也是避免影响其他同事的作业运行。</p></li></ul></li><li><p><code>-driver-memory</code></p><ul><li><p>参数说明：该参数用于设置 Driver 进程的内存。</p></li><li><p>调优建议：Driver 的内存通常来说不设置，或者设置 1G 左右应该就够了。唯一需要注意的一点是，如果需要使用 collect 算子将 RDD 的数据全部拉取到 Driver 上进行处理（或者是用 map side join 操作），那么必须确保 Driver 的内存足够大，否则会出现 OOM 内存溢出的问题。</p></li></ul></li><li><p><code>-spark.default.parallelism</code></p><ul><li><p>参数说明：该参数用于设置每个 stage 的默认 task 数量，也可以认为是分区数。这个参数极为重要，如果不设置可能会直接影响你的 Spark 作业性能。</p></li><li><p>调优建议：Spark 作业的默认 task 数量为 500~1000 个较为合适。很多人常犯的一个错误就是不去设置这个参数，那么此时就会导致 Spark 自己根据底层 HDFS 的 block 数量来设置 task 的数量，默认是一个 HDFS block 对应一个 task。通常来说，Spark 默认设置的数量是偏少的（比如就几十个 task），如果 task 数量偏少的话，就会导致你前面设置好的 Executor 的参数都前功尽弃。试想一下，无论你的 Executor 进程有多少个，内存和 CPU 有多大，但是 task 只有 1 个或者 10 个，那么 90% 的 Executor 进程可能根本就没有 task 执行，也就是白白浪费了资源！因此 Spark 官网建议的设置原则是，设置该参数为 <code>num-executors * executor-cores</code> 的 2~3 倍较为合适，比如 Executor 的总 CPU core 数量为 300 个，那么设置 1000 个 task 是可以的，此时可以充分地利用 Spark 集群的资源。</p></li></ul></li><li><p><code>-spark.storage.memoryFraction</code></p><ul><li><p>参数说明：该参数用于设置 RDD 持久化数据在 Executor 内存中能占的比例，默认是 0.6。也就是说，默认 Executor 60% 的内存，可以用来保存持久化的 RDD 数据。根据你选择的不同的持久化策略，如果内存不够时，可能数据就不会持久化，或者数据会写入磁盘。</p></li><li><p>调优建议：如果 Spark 作业中，有较多的 RDD 持久化操作，该参数的值可以适当提高一些，保证持久化的数据能够容纳在内存中。避免内存不够缓存所有的数据，导致数据只能写入磁盘中，降低了性能。但是如果 Spark 作业中的 shuffle 类操作比较多，而持久化操作比较少，那么这个参数的值适当降低一些比较合适。此外，如果发现作业由于频繁的 GC 导致运行缓慢（通过 spark web ui 可以观察到作业的 GC 耗时），意味着 task 执行用户代码的内存不够用，那么同样建议调低这个参数的值。</p></li></ul></li><li><p><code>-spark.shuffle.memoryFraction</code></p><ul><li><p>参数说明：该参数用于设置 shuffle 过程中一个 task 拉取到上个 stage 的 task 的输出后，进行聚合操作时能够使用的 Executor 内存的比例，默认是 0.2。也就是说，Executor 默认只有 20% 的内存用来进行该操作。shuffle 操作在进行聚合时，如果发现使用的内存超出了这个 20% 的限制，那么多余的数据就会溢写到磁盘文件中去，此时就会极大地降低性能。</p></li><li><p>调优建议：如果 Spark 作业中的 RDD 持久化操作较少，shuffle 操作较多时，建议降低持久化操作的内存占比，提高 shuffle 操作的内存占比比例，避免 shuffle 过程中数据过多时内存不够用，必须溢写到磁盘上，降低了性能。此外，如果发现作业由于频繁的 GC 导致运行缓慢，意味着 task 执行用户代码的内存不够用，那么同样建议调低这个参数的值。</p></li></ul></li></ol><p>总结：</p><ul><li><code>num-executors</code>：应用运行时 executor 的数量，推荐 50-100 左右比较合适</li><li><code>executor-memory</code>：应用运行时 executor 的内存，推荐 4-8G 比较合适</li><li><code>executor-cores</code>：应用运行时 executor 的 CPU 核数，推荐 2-4 个比较合适</li><li><code>driver-memory</code>：应用运行时 driver 的内存量，主要考虑如果使用 map side join 或者一些类似于 collect 的操作，那么要相应调大内存量</li><li><code>spark.default.parallelism</code>：每个 stage 默认的 task 数量，推荐参数为 <code>num-executors * executor-cores</code> 的 2~3 倍较为合适</li><li><code>spark.storage.memoryFraction</code>：每一个 executor 中用于 RDD 缓存的内存比例，如果程序中有大量的数据缓存，可以考虑调大整个的比例，默认为 60%</li><li><code>spark.shuffle.memoryFraction</code>：每一个 executor 中用于 Shuffle 操作的内存比例，默认是 20%，如果程序中有大量的 Shuffle 类算子，那么可以考虑其它的比例</li></ul><h3 id="程序开发调优"><a href="#程序开发调优" class="headerlink" title="程序开发调优"></a>程序开发调优</h3><h3 id="避免创建重复的-RDD"><a href="#避免创建重复的-RDD" class="headerlink" title="避免创建重复的 RDD"></a>避免创建重复的 RDD</h3><p>需要对名为 <code>hello.txt</code> 的 HDFS 文件进行一次 map 操作，再进行一次 reduce 操作。也就是说，需要对一份数据执行两次算子操作。</p><p>错误的做法：对于同一份数据执行多次算子操作时，创建多个 RDD。这里执行了两次 textFile 方法，针对同一个 HDFS 文件，创建了两个 RDD 出来，然后分别对每个 RDD 都执行了一个算子操作。这种情况下，Spark 需要从 HDFS 上两次加载 <code>hello.txt</code> 文件的内容，并创建两个单独的 RDD；// 第二次加载 HDFS 文件以及创建 RDD 的性能开销，很明显是白白浪费掉的。</p><p></p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> rdd1 = sc.textFile(<span class="string">&quot;hdfs://master:9000/hello.txt&quot;</span>)</span><br><span class="line">rdd1.map(...)</span><br><span class="line"><span class="keyword">val</span> rdd2 = sc.textFile(<span class="string">&quot;hdfs://master:9000/hello.txt&quot;</span>)</span><br><span class="line">rdd2.reduce(...)</span><br></pre></td></tr></table></figure><p></p><p>正确的用法：对于一份数据执行多次算子操作时，只使用一个 RDD。</p><h3 id="尽可能复用同一个-RDD"><a href="#尽可能复用同一个-RDD" class="headerlink" title="尽可能复用同一个 RDD"></a>尽可能复用同一个 RDD</h3><p>错误的做法：有一个 <code>&lt;long , String&gt;</code> 格式的 RDD，即 rdd1。接着由于业务需要，对 rdd1 执行了一个 map 操作，创建了一个 rdd2，而 rdd2 中的数据仅仅是 rdd1 中的 value 值而已，也就是说，rdd2 是 rdd1 的子集。</p><p></p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">JavaPairRDD</span>&lt;long , <span class="type">String</span>&gt; rdd1 = ...</span><br><span class="line"><span class="type">JavaRDD</span>&lt;string&gt; rdd2 = rdd1.map(...)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 分别对 rdd1 和 rdd2 执行了不同的算子操作。</span></span><br><span class="line">rdd1.reduceByKey(...)</span><br><span class="line">rdd2.map(...)</span><br></pre></td></tr></table></figure><p></p><p>正确的做法：rdd2 的数据完全就是 rdd1 的子集而已，却创建了两个 rdd，并对两个 rdd 都执行了一次算子操作。此时会因为对 rdd1 执行 map 算子来创建 rdd2，而多执行一次算子操作，进而增加性能开销。其实在这种情况下完全可以复用同一个 RDD。我们可以使用 rdd1，既做 reduceByKey 操作，也做 map 操作。</p><p></p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">JavaPairRDD</span>&lt;long , <span class="type">String</span>&gt; </span><br><span class="line">rdd1 = ...rdd1.reduceByKey(...)</span><br><span class="line">rdd1.map(tuple._2...)</span><br></pre></td></tr></table></figure><p></p><h3 id="对多次使用的-RDD-进行持久化"><a href="#对多次使用的-RDD-进行持久化" class="headerlink" title="对多次使用的 RDD 进行持久化"></a>对多次使用的 RDD 进行持久化</h3><p>正确的做法：cache 方法表示：使用非序列化的方式将 RDD 中的数据全部尝试持久化到内存中。此时再对 rdd1 执行两次算子操作时，只有在第一次执行 map 算子时，才会将这个 rdd1 从源头处计算一次。第二次执行 reduce 算子时，就会直接从内存中提取数据进行计算，不会重复计算一个 rdd。</p><p></p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> rdd1 = sc.textFile(<span class="string">&quot;hdfs://192.168.0.1:9000/hello.txt&quot;</span>).cache()</span><br><span class="line">rdd1.map(...)</span><br><span class="line">rdd1.reduce(...)</span><br></pre></td></tr></table></figure><p></p><p>序列化的方式可以减少持久化的数据对内存/磁盘的占用量，进而避免内存被持久化数据占用过多，从而发生频繁 GC。</p><p></p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> rdd1 = sc.textFile(<span class="string">&quot;hdfs://192.168.0.1:9000/hello.txt&quot;</span>).persist(<span class="type">StorageLevel</span>.<span class="type">MEMORY_AND_DISK_SER</span>)</span><br><span class="line">rdd1.map(...)</span><br><span class="line">rdd1.reduce(...)</span><br></pre></td></tr></table></figure><p></p><p>注意：通常不建议使用 <code>DISK_ONLY</code> 和后缀为 <code>_2</code> 的级别：因为完全基于磁盘文件进行数据的读写，会导致性能急剧降低，导致网络较大开销</p><h3 id="尽量避免使用-shuffle-类算子"><a href="#尽量避免使用-shuffle-类算子" class="headerlink" title="尽量避免使用 shuffle 类算子"></a>尽量避免使用 shuffle 类算子</h3><p>如果有可能的话，要尽量避免使用 shuffle 类算子，最消耗性能的地方就是 shuffle 过程。shuffle 过程中，各个节点上的相同 key 都会先写入本地磁盘文件中，然后其他节点需要通过网络传输拉取各个节点上的磁盘文件中的相同 key。而且相同 key 都拉取到同一个节点进行聚合操作时，还有可能会因为一个节点上处理的 key 过多，导致内存不够存放，进而溢写到磁盘文件中。因此在 shuffle 过程中，可能会发生大量的磁盘文件读写的 IO 操作，以及数据的网络传输操作。磁盘 IO 和网络数据传输也是 shuffle 性能较差的主要原因。</p><p>尽可能避免使用 reduceByKey、join、distinct、repartition 等会进行 shuffle 的算子，尽量使用 map 类的非 shuffle 算子。传统的 join 操作会导致 shuffle 操作。因为两个 RDD 中，相同的 key 都需要通过网络拉取到一个节点上，由一个 task 进行 join 操作。</p><p></p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> rdd3 = rdd1.join(rdd2)</span><br></pre></td></tr></table></figure><p></p><p>Broadcast + map 的 join 操作，不会导致 shuffle 操作。使用 Broadcast 将一个数据量较小的 RDD 作为广播变量。</p><p></p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> rdd2Data = rdd2.collect()</span><br><span class="line"><span class="keyword">val</span> rdd2DataBroadcast = sc.broadcast(rdd2Data)</span><br><span class="line"><span class="keyword">val</span> rdd3 = rdd1.map(rdd2DataBroadcast...)</span><br></pre></td></tr></table></figure><p></p><p>注意：以上操作，建议仅仅在 rdd2 的数据量比较少（比如几百 M，或者一两 G）的情况下使用。因为每个 Executor 的内存中，都会驻留一份 rdd2 的全量数据。</p><h3 id="使用-map-side-预聚合的-shuffle-操作"><a href="#使用-map-side-预聚合的-shuffle-操作" class="headerlink" title="使用 map-side 预聚合的 shuffle 操作"></a>使用 map-side 预聚合的 shuffle 操作</h3><p>如果因为业务需要，一定要使用 shuffle 操作，无法用 map 类的算子来替代，那么尽量使用可以 map-side 预聚合的算子，类似于 MapReduce 中的本地 combiner。map-side 预聚合之后，每个节点本地就只会有一条相同的 key，因为多条相同的 key 都被聚合起来了。其他节点在拉取所有节点上的相同 key 时，就会大大减少需要拉取的数据数量，从而也就减少了磁盘 IO 以及网络传输开销。</p><p>建议使用 reduceByKey 或者 aggregateByKey 算子来替代掉 groupByKey 算子</p><p><img src="https://npm.elemecdn.com/eurkon-cdn/hexo/images/user/loading.gif" data-lazy-src="/images/post/bigdata_interview/spark_map_side.png" alt="map-side 预聚合"></p><h3 id="使用高性能的算子"><a href="#使用高性能的算子" class="headerlink" title="使用高性能的算子"></a>使用高性能的算子</h3><ul><li>使用 reduceByKey/aggregateByKey 替代 groupByKey：map-side</li><li>使用 mapPartitions 替代普通 map：函数执行频率</li><li>使用 foreachPartitions 替代 foreach：函数执行频率</li><li>使用 filter 之后进行 coalesce 操作：filter 后对分区进行压缩</li><li>使用 repartitionAndSortWithinPartitions 替代 repartition 与 sort 类操作</li><li>repartitionAndSortWithinPartitions 是 Spark 官网推荐的一个算子，官方建议，如果需要在 repartition 重分区之后，还要进行排序，建议直接使用 repartitionAndSortWithinPartitions 算子</li></ul><h3 id="广播大变量"><a href="#广播大变量" class="headerlink" title="广播大变量"></a>广播大变量</h3><p>有时在开发过程中，会遇到需要在算子函数中使用外部变量的场景（尤其是大变量，比如 100M 以上的大集合），那么此时就应该使用 Spark 的广播（Broadcast）功能来提升性能。</p><p>默认情况下，Spark 会将该变量复制多个副本，通过网络传输到 task 中，此时每个 task 都有一个变量副本。如果变量本身比较大的话（比如 100M，甚至 1G），那么大量的变量副本在网络中传输的性能开销，以及在各个节点的 Executor 中占用过多内存导致的频繁 GC，都会极大地影响性能。</p><p>广播后的变量，会保证每个 Executor 的内存中，只驻留一份变量副本，而 Executor 中的 task 执行时共享该 Executor 中的那份变量副本。</p><h3 id="使用-Kryo-优化序列化性能"><a href="#使用-Kryo-优化序列化性能" class="headerlink" title="使用 Kryo 优化序列化性能"></a>使用 Kryo 优化序列化性能</h3><ul><li>在算子函数中使用到外部变量时，该变量会被序列化后进行网络传输。</li><li>将自定义的类型作为 RDD 的泛型类型时（比如 JavaRDD，Student 是自定义类型），所有自定义类型对象，都会进行序列化。因此这种情况下，也要求自定义的类必须实现 Serializable 接口。</li><li>使用可序列化的持久化策略时（比如 <code>MEMORY_ONLY_SER</code>），Spark 会将 RDD 中的每个 partition 都序列化成一个大的字节数组。</li></ul><p>Spark 默认使用的是 Java 的序列化机制，你可以使用 Kryo 作为序列化类库，效率要比 Java 的序列化机制要高</p><p></p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 创建 SparkConf 对象。</span></span><br><span class="line"><span class="keyword">val</span> conf = <span class="keyword">new</span> <span class="type">SparkConf</span>().setMaster(...).setAppName(...)</span><br><span class="line"><span class="comment">// 设置序列化器为 KryoSerializer。</span></span><br><span class="line">conf.set(<span class="string">&quot;spark.serializer&quot;</span>, <span class="string">&quot;org.apache.spark.serializer.KryoSerializer&quot;</span>)</span><br><span class="line"><span class="comment">// 注册要序列化的自定义类型。</span></span><br><span class="line">conf.registerKryoClasses(<span class="type">Array</span>(classOf[<span class="type">MyClass1</span>], classOf[<span class="type">MyClass2</span>]))</span><br></pre></td></tr></table></figure><p></p><h3 id="分区-Shuffle-优化"><a href="#分区-Shuffle-优化" class="headerlink" title="分区 Shuffle 优化"></a>分区 Shuffle 优化</h3><p>例如当遇到 userData 和 events 进行 join 时，userData 比较大，而且 join 操作比较频繁，这个时候，可以先将 userData 调用了 partitionBy() 分区，可以极大提高效率。</p><p>cogroup()、 groupWith()、join()、leftOuterJoin()、rightOuterJoin()、groupByKey()、reduceByKey()、 combineByKey() 以及 lookup() 等都能够受益</p><p><img src="https://npm.elemecdn.com/eurkon-cdn/hexo/images/user/loading.gif" data-lazy-src="/images/post/bigdata_interview/spark_shuffle_partition.png" alt="分区 Shuffle 优化"></p><p>总结：如果遇到一个 RDD 频繁和其他 RDD 进行 Shuffle 类操作，比如 cogroup()、 groupWith()、join()、leftOuterJoin()、rightOuterJoin()、groupByKey()、reduceByKey()、 combineByKey() 以及 lookup() 等，那么最好将该 RDD 通过 partitionBy() 操作进行预分区，这些操作在 Shuffle 过程中会减少 Shuffle 的数据量</p><h3 id="优化数据结构"><a href="#优化数据结构" class="headerlink" title="优化数据结构"></a>优化数据结构</h3><p>Java 中，有三种类型比较耗费内存：</p><ul><li>对象，每个 Java 对象都有对象头、引用等额外的信息，因此比较占用内存空间。</li><li>字符串，每个字符串内部都有一个字符数组以及长度等额外信息。</li><li>集合类型，比如 HashMap、LinkedList 等，因为集合类型内部通常会使用一些内部类来封装集合元素，比如 Map.Entry。</li></ul><p>Spark 官方建议，在 Spark 编码实现中，特别是对于算子函数中的代码，尽量不要使用上述三种数据结构，尽量使用字符串替代对象，使用原始类型（比如 Int、Long）替代字符串，使用数组替代集合类型，这样尽可能地减少内存占用，从而降低 GC 频率，提升性能。</p><h3 id="Shuffle-配置调优"><a href="#Shuffle-配置调优" class="headerlink" title="Shuffle 配置调优"></a>Shuffle 配置调优</h3><h3 id="spark-shuffle-file-buffer"><a href="#spark-shuffle-file-buffer" class="headerlink" title="spark.shuffle.file.buffer"></a><code>spark.shuffle.file.buffer</code></h3><ul><li><p>默认值：32k</p></li><li><p>参数说明：该参数用于设置 shuffle write task 的 BufferedOutputStream 的 buffer 缓冲大小。将数据写到磁盘文件之前，会先写入 buffer 缓冲中，待缓冲写满之后，才会溢写到磁盘。</p></li><li><p>调优建议：如果作业可用的内存资源较为充足的话，可以适当增加这个参数的大小（比如 64k），从而减少 shuffle write 过程中溢写磁盘文件的次数，也就可以减少磁盘 IO 次数，进而提升性能。在实践中发现，合理调节该参数，性能会有 1%~5% 的提升。</p></li></ul><h3 id="spark-reducer-maxSizeInFlight"><a href="#spark-reducer-maxSizeInFlight" class="headerlink" title="spark.reducer.maxSizeInFlight"></a><code>spark.reducer.maxSizeInFlight</code></h3><ul><li><p>默认值：48m</p></li><li><p>参数说明：该参数用于设置 shuffle read task 的 buffer 缓冲大小，而这个 buffer 缓冲决定了每次能够拉取多少数据。</p></li><li><p>调优建议：如果作业可用的内存资源较为充足的话，可以适当增加这个参数的大小（比如 96m），从而减少拉取数据的次数，也就可以减少网络传输的次数，进而提升性能。在实践中发现，合理调节该参数，性能会有 1%~5% 的提升。</p></li></ul><h3 id="spark-shuffle-io-maxRetries"><a href="#spark-shuffle-io-maxRetries" class="headerlink" title="spark.shuffle.io.maxRetries"></a><code>spark.shuffle.io.maxRetries</code></h3><ul><li><p>默认值：3</p></li><li><p>参数说明：shuffle read task 从 shuffle write task 所在节点拉取属于自己的数据时，如果因为网络异常导致拉取失败，是会自动进行重试的。该参数就代表了可以重试的最大次数。如果在指定次数之内拉取还是没有成功，就可能会导致作业执行失败。</p></li><li><p>调优建议：对于那些包含了特别耗时的 shuffle 操作的作业，建议增加重试最大次数（比如 60 次），以避免由于 JVM 的 FULL GC 或者网络不稳定等因素导致的数据拉取失败。在实践中发现，对于针对超大数据量（数十亿~上百亿）的 shuffle 过程，调节该参数可以大幅度提升稳定性。</p></li></ul><h3 id="spark-shuffle-io-retryWait"><a href="#spark-shuffle-io-retryWait" class="headerlink" title="spark.shuffle.io.retryWait"></a><code>spark.shuffle.io.retryWait</code></h3><ul><li><p>默认值：5s</p></li><li><p>参数说明：shuffle read task 从 shuffle write task 所在节点拉取属于自己的数据时，如果因为网络异常导致拉取失败，是会自动进行重试的，该参数代表了每次重试拉取数据的等待间隔，默认是 5s。</p></li><li><p>调优建议：建议加大间隔时长（比如 60s），以增加 shuffle 操作的稳定性。</p></li></ul><h3 id="spark-shuffle-memoryFraction"><a href="#spark-shuffle-memoryFraction" class="headerlink" title="spark.shuffle.memoryFraction"></a><code>spark.shuffle.memoryFraction</code></h3><ul><li><p>默认值：0.2</p></li><li><p>参数说明：该参数代表了 Executor 内存中，分配给 shuffle read task 进行聚合操作的内存比例，默认是 20%。</p></li><li><p>调优建议：在资源参数调优中讲解过这个参数。如果内存充足，而且很少使用持久化操作，建议调高这个比例，给 shuffle read 的聚合操作更多内存，以避免由于内存不足导致聚合过程中频繁读写磁盘。在实践中发现，合理调节该参数可以将性能提升 10% 左右。</p></li></ul><h3 id="spark-shuffle-manager"><a href="#spark-shuffle-manager" class="headerlink" title="spark.shuffle.manager"></a><code>spark.shuffle.manager</code></h3><ul><li><p>默认值：sort</p></li><li><p>参数说明：该参数用于设置 ShuffleManager 的类型。Spark 1.5 以后，有三个可选项：<code>hash</code>、<code>sort</code> 和 <code>tungsten-sort</code>。HashShuffleManager 是 Spark 1.2 以前的默认选项，但是 Spark 1.2 以及之后的版本默认都是 SortShuffleManager 了。<code>tungsten-sort</code> 与 <code>sort</code> 类似，但是使用了 tungsten 计划中的堆外内存管理机制，内存使用效率更高。</p></li><li><p>调优建议：由于 SortShuffleManager 默认会对数据进行排序，因此如果你的业务逻辑中需要该排序机制的话，则使用默认的 SortShuffleManager 就可以；而如果你的业务逻辑不需要对数据进行排序，那么建议参考后面的几个参数调优，通过 bypass 机制或优化的 HashShuffleManager 来避免排序操作，同时提供较好的磁盘读写性能。这里要注意的是，<code>tungsten-sort</code> 要慎用，因为之前发现了一些相应的 bug。</p></li></ul><h3 id="spark-shuffle-sort-bypassMergeThreshold"><a href="#spark-shuffle-sort-bypassMergeThreshold" class="headerlink" title="spark.shuffle.sort.bypassMergeThreshold"></a><code>spark.shuffle.sort.bypassMergeThreshold</code></h3><ul><li><p>默认值：200</p></li><li><p>参数说明：当 ShuffleManager 为 SortShuffleManager 时，如果 shuffle read task 的数量小于这个阈值（默认是 200），则 shuffle write 过程中不会进行排序操作，而是直接按照未经优化的 HashShuffleManager 的方式去写数据，但是最后会将每个 task 产生的所有临时磁盘文件都合并成一个文件，并会创建单独的索引文件。</p></li><li><p>调优建议：当你使用 SortShuffleManager 时，如果的确不需要排序操作，那么建议将这个参数调大一些，大于 shuffle read task 的数量。那么此时就会自动启用 bypass 机制，map-side 就不会进行排序了，减少了排序的性能开销。但是这种方式下，依然会产生大量的磁盘文件，因此 shuffle write 性能有待提高。</p></li></ul><h3 id="spark-shuffle-consolidateFiles"><a href="#spark-shuffle-consolidateFiles" class="headerlink" title="spark.shuffle.consolidateFiles"></a><code>spark.shuffle.consolidateFiles</code></h3><ul><li><p>默认值：false</p></li><li><p>参数说明：如果使用 HashShuffleManager，该参数有效。如果设置为 true，那么就会开启 consolidate 机制，会大幅度合并 shuffle write 的输出文件，对于 shuffle read task 数量特别多的情况下，这种方法可以极大地减少磁盘 IO 开销，提升性能。</p></li><li><p>调优建议：如果的确不需要 SortShuffleManager 的排序机制，那么除了使用 bypass 机制，还可以尝试将 <code>spark.shuffle.manager</code> 参数手动指定为 hash，使用 HashShuffleManager，同时开启 consolidate 机制。在实践中尝试过，发现其性能比开启了 bypass 机制的 SortShuffleManager 要高出 10%~30%。</p></li></ul><h3 id="Shuffle-配置调优总结："><a href="#Shuffle-配置调优总结：" class="headerlink" title="Shuffle 配置调优总结："></a>Shuffle 配置调优总结：</h3><ul><li><code>spark.shuffle.file.buffer</code>：主要是设置的 Shuffle 过程中写文件的缓冲，默认 32k，如果内存足够，可以适当调大，来减少写入磁盘的数量。</li><li><code>spark.reducer.maxSizeInFight</code>：主要是设置 Shuffle 过程中读文件的缓冲区，一次能够读取多少数据，如果内存足够，可以适当扩大，减少整个网络传输次数。</li><li><code>spark.shuffle.io.maxRetries</code>：主要是设置网络连接失败时，重试次数，适当调大能够增加稳定性。</li><li><code>spark.shuffle.io.retryWait</code>：主要设置每次重试之间的间隔时间，可以适当调大，增加程序稳定性。</li><li><code>spark.shuffle.memoryFraction</code>：Shuffle 过程中的内存占用，如果程序中较多使用了 Shuffle 操作，那么可以适当调大该区域。</li><li><code>spark.shuffle.manager</code>：hash 和 sort 方式，sort 是默认，hash 在 reduce 数量 比较少的时候，效率会很高。</li><li><code>spark.shuffle.sort. bypassMergeThreshold</code>：设置的是 Sort 方式中，启用 Hash 输出方式的临界值，如果你的程序数据不需要排序，而且 reduce 数量比较少，那推荐可以适当增大临界值。</li><li><code>spark. shuffle.consolidateFiles</code>：如果你使用 Hash shuffle 方式，推荐打开该配置，实现更少的文件输出。</li></ul></article><div class="post-copyright"><div class="post-copyright__title"><span class="post-copyright-info">Spark 面试题解析</span></div><div class="post-copyright__url"><span class="post-copyright-info"><a id="post-url" href="https://blog.eurkon.com/post/cccf27af.html">https://blog.eurkon.com/post/cccf27af.html</a><a id="post-url-copy" title="复制文章链接" onclick="btf.copyFn(&quot;https://blog.eurkon.com/post/cccf27af.html&quot;)"><i class="fas fa-paste copy-button"></i></a></span></div><div class="post-copyright__cc"><span class="post-copyright-info">转载前请阅读本站 <a href="/protocol/copyright/" title="本站所有原创文章采用知识共享(Creative Commons)署名—非商业性使用—相同方式共享4.0国际公共许可协议">版权协议</a>，文章著作权归 <a href="https://blog.eurkon.com/">Eurkon</a> 所有，转载请注明出处。</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/">大数据</a><a class="post-meta__tags" href="/tags/Spark/">Spark</a></div><div class="post-share"><div class="social-share" data-image="/images/cover/bigdata_interview.png" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.4/sharejs/dist/css/share.min.css" media="print" onload='this.media="all"'><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.4/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><a class="pagination-related" href="/post/1a169b5a.html" title="Hexo 博客访问日历图"><img class="cover" src="/images/cover/hexo.png" onerror='onerror=null,src="https://npm.elemecdn.com/eurkon-cdn/hexo/images/user/404.jpg"' alt="cover of previous post"><div class="info"><div class="info-1"><div class="info-item-1">上一篇</div><div class="info-item-2">Hexo 博客访问日历图</div></div><div class="info-2"><div class="info-item-1">前言本文教程主要针对 Hexo 博客，参考冰老师的 hexo-githubcalendar 插件，对博客站点的每日的访问进行统计，绘制出类似与 GitHub 贡献日历的博客访问日历。 本文数据来源均为百度统计，请确保博客站点已加入百度统计，以 butterfly 主题为例，可参照 Butterfly 安装文档(四) 主题配置-2 的分析统计段落实现。 本地主机访问（localhost）也会记录到百度统计，推荐在 【百度统计】--【管理】--【统计规则设置】--【过滤规则设置】--【受访域名统计规则】--【勾选排除 localhost（本地主机）】 排除本地主机访问（貌似在勾选后生效，但是以前的访问记录仍会统计）。 本教程将会泄漏属于百度统计的站点 ID 和百度统计 AccessToken，请先前往 百度统计用户手册 了解，介意者请谨慎部署。 2022-03-29 使用 LeanCloud 存储百度统计的 AccessToken 和 RefreshToken，并使用 Github Action...</div></div></div></a><a class="pagination-related" href="/post/38b005e1.html" title="Butterfly 微博热搜侧边栏"><img class="cover" src="/images/cover/butterfly_weibo.jpg" onerror='onerror=null,src="https://npm.elemecdn.com/eurkon-cdn/hexo/images/user/404.jpg"' alt="cover of next post"><div class="info text-right"><div class="info-1"><div class="info-item-1">下一篇</div><div class="info-item-2">Butterfly 微博热搜侧边栏</div></div><div class="info-2"><div class="info-item-1">前言本文教程主要针对 Hexo Butterfly 主题博客，使用 Vercel API 爬取微博热搜，具体效果可以查看本站侧边栏微博热搜板块。 2021-09-07 新浪微博热搜增加“音”、“影”、“剧”、“综”等标签，教程同步增加相应的 css 样式。 2021-09-28 由于微博热搜改为了异步加载，旧的爬取方法暂时不能用了，可以去 GitHub 更新代码，也可以参考 Python 代码，可以使用其他方法（可能会出现跨域）请求 微博热搜数据。 2023-03-20 文章 weibo-top-api.vercel.app 地址已失效，vercel 需要绑定域名使用，可以改成 weibo.eurkon.com，尽量自己新建 Vercel。 card_weibo.js可以使用博主的 card_weibo.js 地址，或者自己创建 card_weibo.js...</div></div></div></a></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><a class="pagination-related" href="/post/7e24cf66.html" title="大数据面试题解析"><img class="cover" src="/images/cover/bigdata_interview.png" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2021-03-25</div><div class="info-item-2">大数据面试题解析</div></div><div class="info-2"><div class="info-item-1">Hadoop 面试题解析Zookeeper 面试题解析Flume 面试题解析Kafka 面试题解析Hive 面试题解析HBase 面试题解析Sqoop 面试题解析MySQL 面试题解析Spark 面试题解析Elasticsearch 面试题解析</div></div></div></a><a class="pagination-related" href="/post/c55e5115.html" title="Spark RDD 常用算子"><img class="cover" src="/images/cover/spark_rdd.jpg" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2021-05-07</div><div class="info-item-2">Spark RDD 常用算子</div></div><div class="info-2"><div class="info-item-1">Spark 的算子的分类 从大方向来说，Spark 算子大致可以分为以下两类: Transformation 变换/转换算子：这种变换并不触发提交作业，完成作业中间过程处理。 Transformation 操作是延迟计算的，也就是说从一个 RDD 转换生成另一个 RDD 的转换操作不是马上执行，需要等到有 Action 操作的时候才会真正触发运算。 Action 行动算子：这类算子会触发 SparkContext 提交 Job 作业。 Action 算子会触发 Spark 提交作业（Job），并将数据输出 Spark 系统。 从小方向来说，Spark 算子大致可以分为以下三类: Value 数据类型的 Transformation 算子，这种变换并不触发提交作业，针对处理的数据项是 Value 型的数据。 Key-Value 数据类型的 Transformation 算子，这种变换并不触发提交作业，针对处理的数据项是 Key-Value 型的数据对。 Action 算子，这类算子会触发 SparkContext 提交 Job 作业。 Value 数据类型的...</div></div></div></a><a class="pagination-related" href="/post/d1e7dfd3.html" title="HDFS Shell 命令"><img class="cover" src="/images/cover/hdfs_shell.jpg" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2021-03-05</div><div class="info-item-2">HDFS Shell 命令</div></div><div class="info-2"><div class="info-item-1">FS Shell 调用文件系统（FS）的 Shell 命令应使用 bin/hadoop fs &lt;args&gt; 的形式。 所有的 FS shell 命令使用 URI 路径作为参数。 URI 格式是 scheme://authority/path。对 HDFS 文件系统，scheme 是 hdfs，对本地文件系统，scheme 是 file。其中 scheme 和 authority 参数都是可选的，如果未加指定，就会使用配置中指定的默认 scheme。 一个 HDFS 文件或目录比如 /parent/child 可以表示成 hdfs://namenode:namenodeport/parent/child，或者更简单的 /parent/child（假设你配置文件中的默认值是 namenode:namenodeport）。 大多数 FS Shell 命令的行为和对应的 Unix Shell 命令类似，不同之处会在下面介绍各命令使用详情时指出。出错信息会输出到 stderr，其他信息输出到 stdout。 cat 使用方法： 1hadoop fs -cat...</div></div></div></a><a class="pagination-related" href="/post/5a2a12a6.html" title="Flume 面试题解析"><img class="cover" src="/images/cover/bigdata_interview.png" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2021-03-29</div><div class="info-item-2">Flume 面试题解析</div></div><div class="info-2"><div class="info-item-1">Flume 使用场景？线上数据一般主要是落地（存储到磁盘）或者通过 socket 传输给另外一个系统，这种情况下，你很难推动线上应用或服务去修改接口，实现直接向 Kafka 里写数据，这时候你可能就需要 Flume 这样的系统帮你去做传输。 Flume 丢包问题？单机 upd 的 Flume source 的配置，100+M/s 数据量，10w qps Flume 就开始大量丢包，因此很多公司在搭建系统时，抛弃了 Flume，自己研发传输系统，但是往往会参考 Flume 的 Source-Channel-Sink 模式。 一些公司在 Flume 工作过程中，会对业务日志进行监控，例如 Flume agent 中有多少条日志，Flume 到 Kafka 后有多少条日志等等，如果数据丢失保持在 1% 左右是没有问题的，当数据丢失达到 5% 左右时就必须采取相应措施。 Flume 与 Kafka 的选取？采集层主要可以使用 Flume、Kafka 两种技术。 Flume：Flume 是管道流方式，提供了很多的默认实现，让用户通过参数部署，及扩展 API。 Kafka：Kafka...</div></div></div></a><a class="pagination-related" href="/post/420614eb.html" title="Sqoop 面试题解析"><img class="cover" src="/images/cover/bigdata_interview.png" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2021-04-13</div><div class="info-item-2">Sqoop 面试题解析</div></div><div class="info-2"><div class="info-item-1">Sqoop 参数Sqoop 导入数据到 HDFS 中的参数 123456789101112131415/opt/module/sqoop/bin/sqoop import \--connect jdbc 的 url 字符串\--username 账号\--password 密码\# HDFS 目标的目录--target-dir \# 导入的目标目录如果存在则删除那个目录--delete-target-dir \# 相当于 -m，并行导入时 MapTask 的个数--num-mappers \--fields-terminated-by \# 指定满足 sql 和条件的数据导入# --query：增加检索条件部分数据抽取# $CONDITIONS：数据分割条件的占位符--query &quot;$2&quot; &#x27;and $CONDITIONS;&#x27; Sqoop 导入数据到 Hive 中的参数 123456789# 一步将表结构和数据都导入到 hive 中bin/sqoop import \--connect jdbc 的 url 字符串\--table...</div></div></div></a><a class="pagination-related" href="/post/2f1ea7f2.html" title="Zookeeper 面试题解析"><img class="cover" src="/images/cover/bigdata_interview.png" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2021-03-27</div><div class="info-item-2">Zookeeper 面试题解析</div></div><div class="info-2"><div class="info-item-1">请简述 Zookeeper 的选举机制？假设有五台服务器组成的 Zookeeper 集群，它们的 id 从 1-5，同时它们都是最新启动的，也就是没有历史数据，在存放数据量这一点上，都是一样的。假设这些服务器依序启动，来看看会发生什么。 服务器 1 启动，此时只有它一台服务器启动了，它发出去的报没有任何响应，所以它的选举状态一直是 LOOKING 状态； 服务器 2 启动，它与最开始启动的服务器 1 进行通信，互相交换自己的选举结果，由于两者都没有历史数据，所以 id 值较大的服务器 2 胜出，但是由于没有达到超过半数以上的服务器都同意选举它(这个例子中的半数以上是 3)，所以服务器 1、2 还是继续保持 LOOKING 状态； 服务器 3 启动，根据前面的理论分析，服务器 3 成为服务器 1、2、3 中的 Leader，而与上面不同的是，此时有三台服务器选举了它，所以它成为了这次选举的 Leader； 服务器 4 启动，根据前面的分析，理论上服务器 4 应该是服务器 1、2、3、4 中最大的，但是由于前面已经有半数以上的服务器选举了服务器 3，所以它成为...</div></div></div></a></div></div></div><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i> <span>评论</span></div><div id="comment-close" onclick="custom.switchCommentMode()"><i class="fas fa-xmark"></i></div></div><div class="comment-wrap"><div><div id="twikoo-wrap"></div></div></div></div><div id="comment-mask"></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info text-center"><div class="card-info-top"><div id="card-info-hello"></div><div class="card-info-img"><img src="https://npm.elemecdn.com/eurkon-cdn/hexo/images/user/avatar.jpg" onerror='this.onerror=null,this.src="https://npm.elemecdn.com/eurkon-cdn/hexo/images/user/loading.gif"' alt="avatar"></div></div><div class="author-info-name is-center">Eurkon</div><div class="author-info-description">在这里我将记录学习过程中的笔记、分享一些经验与想法。希望能够帮助到您！</div><script defer data-pjax="data-pjax" src="/js/card_info.js"></script><div class="site-data"><a href="/archives/"><div class="headline">文章</div><div class="length-num">88</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">28</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">6</div></a></div><div class="card-info-social-icons"><a class="social-icon" href="https://github.com/Eurkon" rel="external nofollow noreferrer" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="mailto:eurkon@foxmail.com" rel="external nofollow noreferrer" target="_blank" title="Email"><i class="fas fa-envelope"></i></a></div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#Spark-%E5%86%85%E6%A0%B8"><span class="toc-number">1.</span> <span class="toc-text">Spark 内核</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Spark-%E7%9A%84%E6%9C%89%E5%87%A0%E7%A7%8D%E9%83%A8%E7%BD%B2%E6%A8%A1%E5%BC%8F%EF%BC%8C%E6%AF%8F%E7%A7%8D%E6%A8%A1%E5%BC%8F%E7%89%B9%E7%82%B9%EF%BC%9F"><span class="toc-number">1.1.</span> <span class="toc-text">Spark 的有几种部署模式，每种模式特点？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Spark-%E4%B8%BA%E4%BB%80%E4%B9%88%E6%AF%94-MapReduce-%E5%BF%AB%EF%BC%9F"><span class="toc-number">1.2.</span> <span class="toc-text">Spark 为什么比 MapReduce 快？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%AE%80%E5%8D%95%E8%AF%B4%E4%B8%80%E4%B8%8B-Hadoop-%E5%92%8C-Spark-%E7%9A%84-shuffle-%E7%9B%B8%E5%90%8C%E5%92%8C%E5%B7%AE%E5%BC%82%EF%BC%9F"><span class="toc-number">1.3.</span> <span class="toc-text">简单说一下 Hadoop 和 Spark 的 shuffle 相同和差异？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Spark-%E5%B7%A5%E4%BD%9C%E6%9C%BA%E5%88%B6%EF%BC%9FSpark-%E5%BA%94%E7%94%A8%E7%A8%8B%E5%BA%8F%E7%9A%84%E6%89%A7%E8%A1%8C%E8%BF%87%E7%A8%8B%EF%BC%9F"><span class="toc-number">1.4.</span> <span class="toc-text">Spark 工作机制？Spark 应用程序的执行过程？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Spark-%E7%9A%84%E4%BC%98%E5%8C%96%E6%80%8E%E4%B9%88%E5%81%9A%EF%BC%9F"><span class="toc-number">1.5.</span> <span class="toc-text">Spark 的优化怎么做？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E6%9C%AC%E5%9C%B0%E6%80%A7%E6%98%AF%E5%9C%A8%E5%93%AA%E4%B8%AA%E7%8E%AF%E8%8A%82%E7%A1%AE%E5%AE%9A%E7%9A%84%EF%BC%9F"><span class="toc-number">1.6.</span> <span class="toc-text">数据本地性是在哪个环节确定的？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#RDD-%E7%9A%84%E5%BC%B9%E6%80%A7%E8%A1%A8%E7%8E%B0%E5%9C%A8%E5%93%AA%E5%87%A0%E7%82%B9%EF%BC%9F"><span class="toc-number">1.7.</span> <span class="toc-text">RDD 的弹性表现在哪几点？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#RDD-%E6%9C%89%E5%93%AA%E4%BA%9B%E7%BC%BA%E9%99%B7%EF%BC%9F"><span class="toc-number">1.8.</span> <span class="toc-text">RDD 有哪些缺陷？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Spark-%E7%9A%84-shuffle-%E8%BF%87%E7%A8%8B%EF%BC%9F"><span class="toc-number">1.9.</span> <span class="toc-text">Spark 的 shuffle 过程？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Spark-%E7%9A%84%E6%95%B0%E6%8D%AE%E6%9C%AC%E5%9C%B0%E6%80%A7%E6%9C%89%E5%93%AA%E5%87%A0%E7%A7%8D%EF%BC%9F"><span class="toc-number">1.10.</span> <span class="toc-text">Spark 的数据本地性有哪几种？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Spark-%E4%B8%BA%E4%BB%80%E4%B9%88%E8%A6%81%E6%8C%81%E4%B9%85%E5%8C%96%EF%BC%8C%E4%B8%80%E8%88%AC%E4%BB%80%E4%B9%88%E5%9C%BA%E6%99%AF%E4%B8%8B%E8%A6%81%E8%BF%9B%E8%A1%8C-persist-%E6%93%8D%E4%BD%9C%EF%BC%9F"><span class="toc-number">1.11.</span> <span class="toc-text">Spark 为什么要持久化，一般什么场景下要进行 persist 操作？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BB%8B%E7%BB%8D%E4%B8%80%E4%B8%8B-join-%E6%93%8D%E4%BD%9C%E4%BC%98%E5%8C%96%E7%BB%8F%E9%AA%8C%EF%BC%9F"><span class="toc-number">1.12.</span> <span class="toc-text">介绍一下 join 操作优化经验？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%8F%8F%E8%BF%B0-Yarn-%E6%89%A7%E8%A1%8C%E4%B8%80%E4%B8%AA%E4%BB%BB%E5%8A%A1%E7%9A%84%E8%BF%87%E7%A8%8B%EF%BC%9F"><span class="toc-number">1.13.</span> <span class="toc-text">描述 Yarn 执行一个任务的过程？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Spark-on-Yarn-%E6%A8%A1%E5%BC%8F%E6%9C%89%E5%93%AA%E4%BA%9B%E4%BC%98%E7%82%B9%EF%BC%9F"><span class="toc-number">1.14.</span> <span class="toc-text">Spark on Yarn 模式有哪些优点？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%B0%88%E8%B0%88%E4%BD%A0%E5%AF%B9-Container-%E7%9A%84%E7%90%86%E8%A7%A3%EF%BC%9F"><span class="toc-number">1.15.</span> <span class="toc-text">谈谈你对 Container 的理解？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Spark-%E4%BD%BF%E7%94%A8-parquet-%E6%96%87%E4%BB%B6%E5%AD%98%E5%82%A8%E6%A0%BC%E5%BC%8F%E8%83%BD%E5%B8%A6%E6%9D%A5%E5%93%AA%E4%BA%9B%E5%A5%BD%E5%A4%84%EF%BC%9F"><span class="toc-number">1.16.</span> <span class="toc-text">Spark 使用 parquet 文件存储格式能带来哪些好处？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BB%8B%E7%BB%8D-partition-%E5%92%8C-block-%E6%9C%89%E4%BB%80%E4%B9%88%E5%85%B3%E8%81%94%E5%85%B3%E7%B3%BB%EF%BC%9F"><span class="toc-number">1.17.</span> <span class="toc-text">介绍 partition 和 block 有什么关联关系？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%8D%E9%9C%80%E8%A6%81%E6%8E%92%E5%BA%8F%E7%9A%84-hash-shuffle-%E6%98%AF%E5%90%A6%E4%B8%80%E5%AE%9A%E6%AF%94%E9%9C%80%E8%A6%81%E6%8E%92%E5%BA%8F%E7%9A%84-sort-shuffle-%E9%80%9F%E5%BA%A6%E5%BF%AB%EF%BC%9F"><span class="toc-number">1.18.</span> <span class="toc-text">不需要排序的 hash shuffle 是否一定比需要排序的 sort shuffle 速度快？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Sort-based-shuffle-%E7%9A%84%E7%BC%BA%E9%99%B7%EF%BC%9F"><span class="toc-number">1.19.</span> <span class="toc-text">Sort-based shuffle 的缺陷？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#spark-storage-memoryFraction-%E5%8F%82%E6%95%B0%E7%9A%84%E5%90%AB%E4%B9%89%EF%BC%8C%E5%AE%9E%E9%99%85%E7%94%9F%E4%BA%A7%E4%B8%AD%E5%A6%82%E4%BD%95%E8%B0%83%E4%BC%98%EF%BC%9F"><span class="toc-number">1.20.</span> <span class="toc-text">spark.storage.memoryFraction 参数的含义，实际生产中如何调优？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BB%8B%E7%BB%8D%E4%B8%80%E4%B8%8B%E4%BD%A0%E5%AF%B9-Unified-Memory-Management-%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86%E6%A8%A1%E5%9E%8B%E7%9A%84%E7%90%86%E8%A7%A3%EF%BC%9F"><span class="toc-number">1.21.</span> <span class="toc-text">介绍一下你对 Unified Memory Management 内存管理模型的理解？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Spark-%E6%9C%89%E5%93%AA%E4%B8%A4%E7%A7%8D%E7%AE%97%E5%AD%90%EF%BC%9F"><span class="toc-number">1.22.</span> <span class="toc-text">Spark 有哪两种算子？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Spark-%E6%9C%89%E5%93%AA%E4%BA%9B%E8%81%9A%E5%90%88%E7%B1%BB%E7%9A%84%E7%AE%97%E5%AD%90%EF%BC%8C%E6%88%91%E4%BB%AC%E5%BA%94%E8%AF%A5%E5%B0%BD%E9%87%8F%E9%81%BF%E5%85%8D%E4%BB%80%E4%B9%88%E7%B1%BB%E5%9E%8B%E7%9A%84%E7%AE%97%E5%AD%90%EF%BC%9F"><span class="toc-number">1.23.</span> <span class="toc-text">Spark 有哪些聚合类的算子，我们应该尽量避免什么类型的算子？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%A6%82%E4%BD%95%E4%BB%8E-Kafka-%E4%B8%AD%E8%8E%B7%E5%8F%96%E6%95%B0%E6%8D%AE%EF%BC%9F"><span class="toc-number">1.24.</span> <span class="toc-text">如何从 Kafka 中获取数据？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#RDD-%E5%88%9B%E5%BB%BA%E6%9C%89%E5%93%AA%E5%87%A0%E7%A7%8D%E6%96%B9%E5%BC%8F%EF%BC%9F"><span class="toc-number">1.25.</span> <span class="toc-text">RDD 创建有哪几种方式？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Spark-%E5%B9%B6%E8%A1%8C%E5%BA%A6%E6%80%8E%E4%B9%88%E8%AE%BE%E7%BD%AE%E6%AF%94%E8%BE%83%E5%90%88%E9%80%82%EF%BC%9F"><span class="toc-number">1.26.</span> <span class="toc-text">Spark 并行度怎么设置比较合适？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Spark-%E5%A6%82%E4%BD%95%E5%A4%84%E7%90%86%E4%B8%8D%E8%83%BD%E8%A2%AB%E5%BA%8F%E5%88%97%E5%8C%96%E7%9A%84%E5%AF%B9%E8%B1%A1%EF%BC%9F"><span class="toc-number">1.27.</span> <span class="toc-text">Spark 如何处理不能被序列化的对象？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#collect-%E5%8A%9F%E8%83%BD%E6%98%AF%E4%BB%80%E4%B9%88%EF%BC%8C%E5%85%B6%E5%BA%95%E5%B1%82%E6%98%AF%E6%80%8E%E4%B9%88%E5%AE%9E%E7%8E%B0%E7%9A%84%EF%BC%9F"><span class="toc-number">1.28.</span> <span class="toc-text">collect 功能是什么，其底层是怎么实现的？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%BA%E4%BB%80%E4%B9%88-Spark-Application-%E5%9C%A8%E6%B2%A1%E6%9C%89%E8%8E%B7%E5%BE%97%E8%B6%B3%E5%A4%9F%E7%9A%84%E8%B5%84%E6%BA%90%EF%BC%8Cjob-%E5%B0%B1%E5%BC%80%E5%A7%8B%E6%89%A7%E8%A1%8C%E4%BA%86%EF%BC%8C%E5%8F%AF%E8%83%BD%E4%BC%9A%E5%AF%BC%E8%87%B4%E4%BB%80%E4%B9%88%E4%BB%80%E4%B9%88%E9%97%AE%E9%A2%98%E5%8F%91%E7%94%9F%EF%BC%9F"><span class="toc-number">1.29.</span> <span class="toc-text">为什么 Spark Application 在没有获得足够的资源，job 就开始执行了，可能会导致什么什么问题发生？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#map-%E4%B8%8E-flatMap-%E7%9A%84%E5%8C%BA%E5%88%AB%EF%BC%9F"><span class="toc-number">1.30.</span> <span class="toc-text">map 与 flatMap 的区别？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Spark-on-Mesos-%E4%B8%AD%EF%BC%8C%E4%BB%80%E4%B9%88%E6%98%AF%E7%9A%84%E7%B2%97%E7%B2%92%E5%BA%A6%E5%88%86%E9%85%8D%EF%BC%8C%E4%BB%80%E4%B9%88%E6%98%AF%E7%BB%86%E7%B2%92%E5%BA%A6%E5%88%86%E9%85%8D%EF%BC%8C%E5%90%84%E8%87%AA%E7%9A%84%E4%BC%98%E7%82%B9%E5%92%8C%E7%BC%BA%E7%82%B9%E6%98%AF%E4%BB%80%E4%B9%88%EF%BC%9F"><span class="toc-number">1.31.</span> <span class="toc-text">Spark on Mesos 中，什么是的粗粒度分配，什么是细粒度分配，各自的优点和缺点是什么？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Driver-%E7%9A%84%E5%8A%9F%E8%83%BD%E6%98%AF%E4%BB%80%E4%B9%88%EF%BC%9F"><span class="toc-number">1.32.</span> <span class="toc-text">Driver 的功能是什么？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Spark-%E6%8A%80%E6%9C%AF%E6%A0%88%E6%9C%89%E5%93%AA%E4%BA%9B%E7%BB%84%E4%BB%B6%EF%BC%8C%E6%AF%8F%E4%B8%AA%E7%BB%84%E4%BB%B6%E9%83%BD%E6%9C%89%E4%BB%80%E4%B9%88%E5%8A%9F%E8%83%BD%EF%BC%8C%E9%80%82%E5%90%88%E4%BB%80%E4%B9%88%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF%EF%BC%9F"><span class="toc-number">1.33.</span> <span class="toc-text">Spark 技术栈有哪些组件，每个组件都有什么功能，适合什么应用场景？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Spark-%E4%B8%AD-Worker-%E7%9A%84%E4%B8%BB%E8%A6%81%E5%B7%A5%E4%BD%9C%E6%98%AF%E4%BB%80%E4%B9%88%EF%BC%9F"><span class="toc-number">1.34.</span> <span class="toc-text">Spark 中 Worker 的主要工作是什么？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#MapReduce-%E5%92%8C-Spark-%E7%9A%84%E9%83%BD%E6%98%AF%E5%B9%B6%E8%A1%8C%E8%AE%A1%E7%AE%97%EF%BC%8C%E9%82%A3%E4%B9%88%E4%BB%96%E4%BB%AC%E6%9C%89%E4%BB%80%E4%B9%88%E7%9B%B8%E5%90%8C%E5%92%8C%E5%8C%BA%E5%88%AB%EF%BC%9F"><span class="toc-number">1.35.</span> <span class="toc-text">MapReduce 和 Spark 的都是并行计算，那么他们有什么相同和区别？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#RDD-%E6%9C%BA%E5%88%B6%EF%BC%9F"><span class="toc-number">1.36.</span> <span class="toc-text">RDD 机制？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BB%80%E4%B9%88%E6%98%AF-RDD-%E5%AE%BD%E4%BE%9D%E8%B5%96%E5%92%8C%E7%AA%84%E4%BE%9D%E8%B5%96%EF%BC%9F"><span class="toc-number">1.37.</span> <span class="toc-text">什么是 RDD 宽依赖和窄依赖？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#cache-%E5%92%8C-persist-%E7%9A%84%E5%8C%BA%E5%88%AB%EF%BC%9F"><span class="toc-number">1.38.</span> <span class="toc-text">cache 和 persist 的区别？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#cache-%E5%90%8E%E9%9D%A2%E8%83%BD%E4%B8%8D%E8%83%BD%E6%8E%A5%E5%85%B6%E4%BB%96%E7%AE%97%E5%AD%90%EF%BC%8C%E5%AE%83%E6%98%AF%E4%B8%8D%E6%98%AF-action-%E6%93%8D%E4%BD%9C%EF%BC%9F"><span class="toc-number">1.39.</span> <span class="toc-text">cache 后面能不能接其他算子，它是不是 action 操作？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#reduceByKey-%E6%98%AF%E4%B8%8D%E6%98%AF-action%EF%BC%9F"><span class="toc-number">1.40.</span> <span class="toc-text">reduceByKey 是不是 action？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#RDD-%E9%80%9A%E8%BF%87-Lineage%EF%BC%88%E8%AE%B0%E5%BD%95%E6%95%B0%E6%8D%AE%E6%9B%B4%E6%96%B0%EF%BC%89%E7%9A%84%E6%96%B9%E5%BC%8F%E4%B8%BA%E4%BD%95%E5%BE%88%E9%AB%98%E6%95%88%EF%BC%9F"><span class="toc-number">1.41.</span> <span class="toc-text">RDD 通过 Lineage（记录数据更新）的方式为何很高效？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%BA%E4%BB%80%E4%B9%88%E8%A6%81%E8%BF%9B%E8%A1%8C%E5%BA%8F%E5%88%97%E5%8C%96%E5%BA%8F%E5%88%97%E5%8C%96%EF%BC%9F"><span class="toc-number">1.42.</span> <span class="toc-text">为什么要进行序列化序列化？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Yarn-%E4%B8%AD%E7%9A%84-Container-%E6%98%AF%E7%94%B1%E8%B0%81%E8%B4%9F%E8%B4%A3%E9%94%80%E6%AF%81%E7%9A%84%EF%BC%8C%E5%9C%A8-Hadoop-MapReduce-%E4%B8%AD-Container-%E5%8F%AF%E4%BB%A5%E5%A4%8D%E7%94%A8%E4%B9%88%EF%BC%9F"><span class="toc-number">1.43.</span> <span class="toc-text">Yarn 中的 Container 是由谁负责销毁的，在 Hadoop MapReduce 中 Container 可以复用么？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%8F%90%E4%BA%A4%E4%BB%BB%E5%8A%A1%E6%97%B6%EF%BC%8C%E5%A6%82%E4%BD%95%E6%8C%87%E5%AE%9A-Spark-Application-%E7%9A%84%E8%BF%90%E8%A1%8C%E6%A8%A1%E5%BC%8F%EF%BC%9F"><span class="toc-number">1.44.</span> <span class="toc-text">提交任务时，如何指定 Spark Application 的运行模式？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%8D%E5%90%AF%E5%8A%A8-Spark-%E9%9B%86%E7%BE%A4-Master-%E5%92%8C-Worker-%E6%9C%8D%E5%8A%A1%EF%BC%8C%E5%8F%AF%E4%B8%8D%E5%8F%AF%E4%BB%A5%E8%BF%90%E8%A1%8C-Spark-%E7%A8%8B%E5%BA%8F%EF%BC%9F"><span class="toc-number">1.45.</span> <span class="toc-text">不启动 Spark 集群 Master 和 Worker 服务，可不可以运行 Spark 程序？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Spark-on-Yarn-Cluster-%E6%A8%A1%E5%BC%8F%E4%B8%8B%EF%BC%8CApplicationMaster-%E5%92%8C-Driver-%E6%98%AF%E5%9C%A8%E5%90%8C%E4%B8%80%E4%B8%AA%E8%BF%9B%E7%A8%8B%E4%B9%88%EF%BC%9F"><span class="toc-number">1.46.</span> <span class="toc-text">Spark on Yarn Cluster 模式下，ApplicationMaster 和 Driver 是在同一个进程么？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%BF%90%E8%A1%8C%E5%9C%A8-Yarn-%E4%B8%AD-Application-%E6%9C%89%E5%87%A0%E7%A7%8D%E7%B1%BB%E5%9E%8B%E7%9A%84-Container%EF%BC%9F"><span class="toc-number">1.47.</span> <span class="toc-text">运行在 Yarn 中 Application 有几种类型的 Container？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Executor-%E5%90%AF%E5%8A%A8%E6%97%B6%EF%BC%8C%E8%B5%84%E6%BA%90%E9%80%9A%E8%BF%87%E5%93%AA%E5%87%A0%E4%B8%AA%E5%8F%82%E6%95%B0%E6%8C%87%E5%AE%9A%EF%BC%9F"><span class="toc-number">1.48.</span> <span class="toc-text">Executor 启动时，资源通过哪几个参数指定？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%88%97%E5%87%BA%E4%BD%A0%E6%89%80%E7%9F%A5%E9%81%93%E7%9A%84%E8%B0%83%E5%BA%A6%E5%99%A8%EF%BC%8C%E8%AF%B4%E6%98%8E%E5%85%B6%E5%B7%A5%E4%BD%9C%E5%8E%9F%E7%90%86"><span class="toc-number">1.49.</span> <span class="toc-text">列出你所知道的调度器，说明其工作原理</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AF%BC%E8%87%B4-Executor-%E4%BA%A7%E7%94%9F-FULL-GC-%E7%9A%84%E5%8E%9F%E5%9B%A0%EF%BC%8C%E5%8F%AF%E8%83%BD%E5%AF%BC%E8%87%B4%E4%BB%80%E4%B9%88%E9%97%AE%E9%A2%98%EF%BC%9F"><span class="toc-number">1.50.</span> <span class="toc-text">导致 Executor 产生 FULL GC 的原因，可能导致什么问题？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Spark-%E7%B4%AF%E5%8A%A0%E5%99%A8%E6%9C%89%E5%93%AA%E4%BA%9B%E7%89%B9%E7%82%B9%EF%BC%9F"><span class="toc-number">1.51.</span> <span class="toc-text">Spark 累加器有哪些特点？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#HashPartitioner-%E7%9A%84%E5%BC%8A%E7%AB%AF%E6%98%AF%E4%BB%80%E4%B9%88%EF%BC%9F"><span class="toc-number">1.52.</span> <span class="toc-text">HashPartitioner 的弊端是什么？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#RangePartitioner-%E5%88%86%E5%8C%BA%E7%9A%84%E5%8E%9F%E7%90%86%EF%BC%9F"><span class="toc-number">1.53.</span> <span class="toc-text">RangePartitioner 分区的原理？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%A6%82%E4%BD%95%E7%90%86%E8%A7%A3-Standalone-%E6%A8%A1%E5%BC%8F%E4%B8%8B%EF%BC%8CSpark-%E8%B5%84%E6%BA%90%E5%88%86%E9%85%8D%E6%98%AF%E7%B2%97%E7%B2%92%E5%BA%A6%E7%9A%84%EF%BC%9F"><span class="toc-number">1.54.</span> <span class="toc-text">如何理解 Standalone 模式下，Spark 资源分配是粗粒度的？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#union-%E6%93%8D%E4%BD%9C%E6%98%AF%E4%BA%A7%E7%94%9F%E5%AE%BD%E4%BE%9D%E8%B5%96%E8%BF%98%E6%98%AF%E7%AA%84%E4%BE%9D%E8%B5%96%EF%BC%9F"><span class="toc-number">1.55.</span> <span class="toc-text">union 操作是产生宽依赖还是窄依赖？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%AA%84%E4%BE%9D%E8%B5%96%E7%88%B6-RDD-%E7%9A%84-partition-%E5%92%8C%E5%AD%90-RDD-%E7%9A%84-partition-%E6%98%AF%E4%B8%8D%E6%98%AF%E9%83%BD%E6%98%AF%E4%B8%80%E5%AF%B9%E4%B8%80%E7%9A%84%E5%85%B3%E7%B3%BB%EF%BC%9F"><span class="toc-number">1.56.</span> <span class="toc-text">窄依赖父 RDD 的 partition 和子 RDD 的 partition 是不是都是一对一的关系？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Hadoop-%E4%B8%AD%EF%BC%8CMapReduce-%E6%93%8D%E4%BD%9C%E7%9A%84-mapper-%E5%92%8C-reducer-%E9%98%B6%E6%AE%B5%E7%9B%B8%E5%BD%93%E4%BA%8E-Spark-%E4%B8%AD%E7%9A%84%E5%93%AA%E5%87%A0%E4%B8%AA%E7%AE%97%E5%AD%90%EF%BC%9F"><span class="toc-number">1.57.</span> <span class="toc-text">Hadoop 中，MapReduce 操作的 mapper 和 reducer 阶段相当于 Spark 中的哪几个算子？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BB%80%E4%B9%88%E6%98%AF-shuffle%EF%BC%8C%E4%BB%A5%E5%8F%8A%E4%B8%BA%E4%BB%80%E4%B9%88%E9%9C%80%E8%A6%81-shuffle%EF%BC%9F"><span class="toc-number">1.58.</span> <span class="toc-text">什么是 shuffle，以及为什么需要 shuffle？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Spark-%E4%B8%AD%E7%9A%84-HashShuffle-%E7%9A%84%E6%9C%89%E5%93%AA%E4%BA%9B%E4%B8%8D%E8%B6%B3%EF%BC%9F"><span class="toc-number">1.59.</span> <span class="toc-text">Spark 中的 HashShuffle 的有哪些不足？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#consolidate-%E6%98%AF%E5%A6%82%E4%BD%95%E4%BC%98%E5%8C%96-Hash-shuffle-%E6%97%B6%E5%9C%A8-map-%E7%AB%AF%E4%BA%A7%E7%94%9F%E7%9A%84%E5%B0%8F%E6%96%87%E4%BB%B6%EF%BC%9F"><span class="toc-number">1.60.</span> <span class="toc-text">consolidate 是如何优化 Hash shuffle 时在 map 端产生的小文件？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#spark-default-parallelism-%E8%BF%99%E4%B8%AA%E5%8F%82%E6%95%B0%E6%9C%89%E4%BB%80%E4%B9%88%E6%84%8F%E4%B9%89%EF%BC%8C%E5%AE%9E%E9%99%85%E7%94%9F%E4%BA%A7%E4%B8%AD%E5%A6%82%E4%BD%95%E8%AE%BE%E7%BD%AE%EF%BC%9F"><span class="toc-number">1.61.</span> <span class="toc-text">spark.default.parallelism 这个参数有什么意义，实际生产中如何设置？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#spark-shuffle-memoryFraction-%E5%8F%82%E6%95%B0%E7%9A%84%E5%90%AB%E4%B9%89%EF%BC%8C%E4%BB%A5%E5%8F%8A%E4%BC%98%E5%8C%96%E7%BB%8F%E9%AA%8C%EF%BC%9F"><span class="toc-number">1.62.</span> <span class="toc-text">spark.shuffle.memoryFraction 参数的含义，以及优化经验？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Spark-%E4%B8%AD-Standalone-%E6%A8%A1%E5%BC%8F%E7%89%B9%E7%82%B9%EF%BC%8C%E6%9C%89%E5%93%AA%E4%BA%9B%E4%BC%98%E7%82%B9%E5%92%8C%E7%BC%BA%E7%82%B9%EF%BC%9F"><span class="toc-number">1.63.</span> <span class="toc-text">Spark 中 Standalone 模式特点，有哪些优点和缺点？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#FIFO-%E8%B0%83%E5%BA%A6%E6%A8%A1%E5%BC%8F%E7%9A%84%E5%9F%BA%E6%9C%AC%E5%8E%9F%E7%90%86%E3%80%81%E4%BC%98%E7%82%B9%E5%92%8C%E7%BC%BA%E7%82%B9%EF%BC%9F"><span class="toc-number">1.64.</span> <span class="toc-text">FIFO 调度模式的基本原理、优点和缺点？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#FAIR-%E8%B0%83%E5%BA%A6%E6%A8%A1%E5%BC%8F%E7%9A%84%E4%BC%98%E7%82%B9%E5%92%8C%E7%BC%BA%E7%82%B9%EF%BC%9F"><span class="toc-number">1.65.</span> <span class="toc-text">FAIR 调度模式的优点和缺点？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#CAPACITY-%E8%B0%83%E5%BA%A6%E6%A8%A1%E5%BC%8F%E7%9A%84%E4%BC%98%E7%82%B9%E5%92%8C%E7%BC%BA%E7%82%B9%EF%BC%9F"><span class="toc-number">1.66.</span> <span class="toc-text">CAPACITY 调度模式的优点和缺点？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%B8%B8%E8%A7%81%E7%9A%84%E6%95%B0%E6%8D%AE%E5%8E%8B%E7%BC%A9%E6%96%B9%E5%BC%8F%EF%BC%8C%E4%BD%A0%E4%BB%AC%E7%94%9F%E4%BA%A7%E9%9B%86%E7%BE%A4%E9%87%87%E7%94%A8%E4%BA%86%E4%BB%80%E4%B9%88%E5%8E%8B%E7%BC%A9%E6%96%B9%E5%BC%8F%EF%BC%8C%E6%8F%90%E5%8D%87%E4%BA%86%E5%A4%9A%E5%B0%91%E6%95%88%E7%8E%87%EF%BC%9F"><span class="toc-number">1.67.</span> <span class="toc-text">常见的数据压缩方式，你们生产集群采用了什么压缩方式，提升了多少效率？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BD%BF%E7%94%A8-scala-%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0-WordCount%EF%BC%9F"><span class="toc-number">1.68.</span> <span class="toc-text">使用 scala 代码实现 WordCount？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Spark-RDD-%E5%92%8C-MapReduce2-%E7%9A%84%E5%8C%BA%E5%88%AB%EF%BC%9F"><span class="toc-number">1.69.</span> <span class="toc-text">Spark RDD 和 MapReduce2 的区别？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Spark-%E5%92%8C-MapReduce-%E5%BF%AB%EF%BC%9F%E4%B8%BA%E4%BB%80%E4%B9%88%E5%BF%AB%E5%91%A2%EF%BC%9F%E5%BF%AB%E5%9C%A8%E5%93%AA%E9%87%8C%E5%91%A2%EF%BC%9F"><span class="toc-number">1.70.</span> <span class="toc-text">Spark 和 MapReduce 快？为什么快呢？快在哪里呢？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Spark-SQL-%E4%B8%BA%E4%BB%80%E4%B9%88%E6%AF%94-Hive-%E5%BF%AB%E5%91%A2%EF%BC%9F"><span class="toc-number">1.71.</span> <span class="toc-text">Spark SQL 为什么比 Hive 快呢？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#RDD-%E7%9A%84%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E6%98%AF%E6%80%8E%E4%B9%88%E6%A0%B7%E7%9A%84%EF%BC%9F"><span class="toc-number">1.72.</span> <span class="toc-text">RDD 的数据结构是怎么样的？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#RDD-%E7%AE%97%E5%AD%90%E9%87%8C%E6%93%8D%E4%BD%9C%E4%B8%80%E4%B8%AA%E5%A4%96%E9%83%A8-map%EF%BC%8C%E6%AF%94%E5%A6%82%E5%BE%80%E9%87%8C%E9%9D%A2-put-%E6%95%B0%E6%8D%AE%EF%BC%8C%E7%84%B6%E5%90%8E%E7%AE%97%E5%AD%90%E5%A4%96%E5%86%8D%E9%81%8D%E5%8E%86-map%EF%BC%8C%E4%BC%9A%E6%9C%89%E4%BB%80%E4%B9%88%E9%97%AE%E9%A2%98%E5%90%97%EF%BC%9F"><span class="toc-number">1.73.</span> <span class="toc-text">RDD 算子里操作一个外部 map，比如往里面 put 数据，然后算子外再遍历 map，会有什么问题吗？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#HBase-region-%E5%A4%9A%E5%A4%A7%E4%BC%9A%E5%88%86%E5%8C%BA%EF%BC%8CSpark-%E8%AF%BB%E5%8F%96-HBase-%E6%95%B0%E6%8D%AE%E6%98%AF%E5%A6%82%E4%BD%95%E5%88%92%E5%88%86-partition-%E7%9A%84%EF%BC%9F"><span class="toc-number">1.74.</span> <span class="toc-text">HBase region 多大会分区，Spark 读取 HBase 数据是如何划分 partition 的？</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Spark-%E8%B0%83%E4%BC%98"><span class="toc-number">2.</span> <span class="toc-text">Spark 调优</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E5%80%BE%E6%96%9C"><span class="toc-number">2.1.</span> <span class="toc-text">数据倾斜</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BB%80%E4%B9%88%E6%98%AF%E6%95%B0%E6%8D%AE%E5%80%BE%E6%96%9C%EF%BC%9F"><span class="toc-number">2.2.</span> <span class="toc-text">什么是数据倾斜？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%A6%82%E4%BD%95%E5%AE%9A%E4%BD%8D%E6%95%B0%E6%8D%AE%E5%80%BE%E6%96%9C%EF%BC%9F"><span class="toc-number">2.3.</span> <span class="toc-text">如何定位数据倾斜？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E5%80%BE%E6%96%9C%E7%9A%84%E5%87%A0%E7%A7%8D%E5%85%B8%E5%9E%8B%E6%83%85%E5%86%B5%EF%BC%9F"><span class="toc-number">2.4.</span> <span class="toc-text">数据倾斜的几种典型情况？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E5%80%BE%E6%96%9C%E7%9A%84%E5%A4%84%E7%90%86%E6%96%B9%E6%B3%95%EF%BC%9F"><span class="toc-number">2.5.</span> <span class="toc-text">数据倾斜的处理方法？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%B5%84%E6%BA%90%E8%B0%83%E4%BC%98"><span class="toc-number">2.6.</span> <span class="toc-text">资源调优</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%B5%84%E6%BA%90%E8%BF%90%E8%A1%8C%E4%B8%AD%E7%9A%84%E9%9B%86%E4%B8%AD%E6%83%85%E5%86%B5"><span class="toc-number">2.7.</span> <span class="toc-text">资源运行中的集中情况</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%BF%90%E8%A1%8C%E8%B5%84%E6%BA%90%E4%BC%98%E5%8C%96%E9%85%8D%E7%BD%AE"><span class="toc-number">2.8.</span> <span class="toc-text">运行资源优化配置</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%A8%8B%E5%BA%8F%E5%BC%80%E5%8F%91%E8%B0%83%E4%BC%98"><span class="toc-number">2.9.</span> <span class="toc-text">程序开发调优</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%81%BF%E5%85%8D%E5%88%9B%E5%BB%BA%E9%87%8D%E5%A4%8D%E7%9A%84-RDD"><span class="toc-number">2.10.</span> <span class="toc-text">避免创建重复的 RDD</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%B0%BD%E5%8F%AF%E8%83%BD%E5%A4%8D%E7%94%A8%E5%90%8C%E4%B8%80%E4%B8%AA-RDD"><span class="toc-number">2.11.</span> <span class="toc-text">尽可能复用同一个 RDD</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AF%B9%E5%A4%9A%E6%AC%A1%E4%BD%BF%E7%94%A8%E7%9A%84-RDD-%E8%BF%9B%E8%A1%8C%E6%8C%81%E4%B9%85%E5%8C%96"><span class="toc-number">2.12.</span> <span class="toc-text">对多次使用的 RDD 进行持久化</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%B0%BD%E9%87%8F%E9%81%BF%E5%85%8D%E4%BD%BF%E7%94%A8-shuffle-%E7%B1%BB%E7%AE%97%E5%AD%90"><span class="toc-number">2.13.</span> <span class="toc-text">尽量避免使用 shuffle 类算子</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BD%BF%E7%94%A8-map-side-%E9%A2%84%E8%81%9A%E5%90%88%E7%9A%84-shuffle-%E6%93%8D%E4%BD%9C"><span class="toc-number">2.14.</span> <span class="toc-text">使用 map-side 预聚合的 shuffle 操作</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BD%BF%E7%94%A8%E9%AB%98%E6%80%A7%E8%83%BD%E7%9A%84%E7%AE%97%E5%AD%90"><span class="toc-number">2.15.</span> <span class="toc-text">使用高性能的算子</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%B9%BF%E6%92%AD%E5%A4%A7%E5%8F%98%E9%87%8F"><span class="toc-number">2.16.</span> <span class="toc-text">广播大变量</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BD%BF%E7%94%A8-Kryo-%E4%BC%98%E5%8C%96%E5%BA%8F%E5%88%97%E5%8C%96%E6%80%A7%E8%83%BD"><span class="toc-number">2.17.</span> <span class="toc-text">使用 Kryo 优化序列化性能</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%88%86%E5%8C%BA-Shuffle-%E4%BC%98%E5%8C%96"><span class="toc-number">2.18.</span> <span class="toc-text">分区 Shuffle 优化</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BC%98%E5%8C%96%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84"><span class="toc-number">2.19.</span> <span class="toc-text">优化数据结构</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Shuffle-%E9%85%8D%E7%BD%AE%E8%B0%83%E4%BC%98"><span class="toc-number">2.20.</span> <span class="toc-text">Shuffle 配置调优</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#spark-shuffle-file-buffer"><span class="toc-number">2.21.</span> <span class="toc-text">spark.shuffle.file.buffer</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#spark-reducer-maxSizeInFlight"><span class="toc-number">2.22.</span> <span class="toc-text">spark.reducer.maxSizeInFlight</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#spark-shuffle-io-maxRetries"><span class="toc-number">2.23.</span> <span class="toc-text">spark.shuffle.io.maxRetries</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#spark-shuffle-io-retryWait"><span class="toc-number">2.24.</span> <span class="toc-text">spark.shuffle.io.retryWait</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#spark-shuffle-memoryFraction"><span class="toc-number">2.25.</span> <span class="toc-text">spark.shuffle.memoryFraction</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#spark-shuffle-manager"><span class="toc-number">2.26.</span> <span class="toc-text">spark.shuffle.manager</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#spark-shuffle-sort-bypassMergeThreshold"><span class="toc-number">2.27.</span> <span class="toc-text">spark.shuffle.sort.bypassMergeThreshold</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#spark-shuffle-consolidateFiles"><span class="toc-number">2.28.</span> <span class="toc-text">spark.shuffle.consolidateFiles</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Shuffle-%E9%85%8D%E7%BD%AE%E8%B0%83%E4%BC%98%E6%80%BB%E7%BB%93%EF%BC%9A"><span class="toc-number">2.29.</span> <span class="toc-text">Shuffle 配置调优总结：</span></a></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/post/b0188c87.html" title="ECharts 帕累托图"><img src="/images/cover/echarts_pareto.png" onerror='this.onerror=null,this.src="https://npm.elemecdn.com/eurkon-cdn/hexo/images/user/404.jpg"' alt="ECharts 帕累托图"></a><div class="content"><a class="title" href="/post/b0188c87.html" title="ECharts 帕累托图">ECharts 帕累托图</a><time datetime="2023-05-30T01:00:00.000Z" title="发表于 2023-05-30 09:00:00">2023-05-30</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/post/620d6870.html" title="ECharts 子弹图"><img src="/images/cover/echarts_bullet.png" onerror='this.onerror=null,this.src="https://npm.elemecdn.com/eurkon-cdn/hexo/images/user/404.jpg"' alt="ECharts 子弹图"></a><div class="content"><a class="title" href="/post/620d6870.html" title="ECharts 子弹图">ECharts 子弹图</a><time datetime="2023-04-27T01:00:00.000Z" title="发表于 2023-04-27 09:00:00">2023-04-27</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/post/22774ddc.html" title="ECharts 径向条形图"><img src="/images/cover/echarts_radial_bar.png" onerror='this.onerror=null,this.src="https://npm.elemecdn.com/eurkon-cdn/hexo/images/user/404.jpg"' alt="ECharts 径向条形图"></a><div class="content"><a class="title" href="/post/22774ddc.html" title="ECharts 径向条形图">ECharts 径向条形图</a><time datetime="2023-04-26T01:00:00.000Z" title="发表于 2023-04-26 09:00:00">2023-04-26</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/post/68739172.html" title="ECharts 渐变折线图"><img src="/images/cover/echarts_line_gradient.png" onerror='this.onerror=null,this.src="https://npm.elemecdn.com/eurkon-cdn/hexo/images/user/404.jpg"' alt="ECharts 渐变折线图"></a><div class="content"><a class="title" href="/post/68739172.html" title="ECharts 渐变折线图">ECharts 渐变折线图</a><time datetime="2023-03-12T01:00:00.000Z" title="发表于 2023-03-12 09:00:00">2023-03-12</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/post/1c85bfc3.html" title="数仓设计与 ETL 规范"><img src="/images/cover/etl_norm.png" onerror='this.onerror=null,this.src="https://npm.elemecdn.com/eurkon-cdn/hexo/images/user/404.jpg"' alt="数仓设计与 ETL 规范"></a><div class="content"><a class="title" href="/post/1c85bfc3.html" title="数仓设计与 ETL 规范">数仓设计与 ETL 规范</a><time datetime="2022-12-31T02:00:00.000Z" title="发表于 2022-12-31 10:00:00">2022-12-31</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/post/553238e8.html" title="ECharts 生涯彩虹图"><img src="/images/cover/echarts_career.png" onerror='this.onerror=null,this.src="https://npm.elemecdn.com/eurkon-cdn/hexo/images/user/404.jpg"' alt="ECharts 生涯彩虹图"></a><div class="content"><a class="title" href="/post/553238e8.html" title="ECharts 生涯彩虹图">ECharts 生涯彩虹图</a><time datetime="2022-11-06T01:00:00.000Z" title="发表于 2022-11-06 09:00:00">2022-11-06</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div id="footer-group-container"><div class="footer-group"><span class="footer-group-title">统计</span><a class="footer-group-item" href="/charts/">文章统计</a><a class="footer-group-item" href="/census/">博客统计</a></div><div class="footer-group"><span class="footer-group-title">导航</span><a class="footer-group-item" href="/link/#我的友链-amp-友链格式">申请友链</a><a class="footer-group-item" target="_blank" rel="noopener external nofollow noreferrer" href="https://github.com/Eurkon/hexo-theme-butterfly-eurkon">魔改源码</a><a class="footer-group-item" href="/stars/">网站收藏</a><a class="footer-group-item" href="javascript:toRandomPost();" rel="external nofollow noreferrer">随机文章</a></div><div class="footer-group"><span class="footer-group-title">分类</span><a class="footer-group-item" href="/categories/学习笔记/">学习笔记</a><a class="footer-group-item" href="/categories/魔改教程/">魔改教程</a><a class="footer-group-item" href="/categories/分享转载/">分享转载</a><a class="footer-group-item" href="/categories/作品案例/">作品案例</a></div><div class="footer-group"><span class="footer-group-title">关于</span><a class="footer-group-item" href="/notice/">网站公告</a><a class="footer-group-item" href="/update/">博客更新</a><a class="footer-group-item" href="/message/">给我留言</a><a class="footer-group-item" href="mailto:eurkon@foxmail.com" rel="external nofollow noreferrer">联系博主</a></div><div class="footer-group"><span class="footer-group-title">服务</span><a class="footer-group-item" href="/fcircle/">友链订阅</a><a class="footer-group-item" href="/rss.xml">RSS 订阅</a><a class="footer-group-item" href="/atom.xml">Atom 订阅</a><a class="footer-group-item" target="_blank" rel="noopener external nofollow noreferrer" href="https://bf.zzxworld.com/s/686">BlogFinder</a></div><div class="footer-group" id="footer-group-flink"><span class="footer-group-title">友链<i class="fas fa-sync" title="随机友链" onclick="eurkon.footerRandomFlink(flinks,3)"></i></span><a class="footer-group-item" href="" target="_blank" rel="noopener external nofollow noreferrer">加载中...</a><a class="footer-group-item" href="" target="_blank" rel="noopener external nofollow noreferrer">加载中...</a><a class="footer-group-item" href="" target="_blank" rel="noopener external nofollow noreferrer">加载中...</a><a class="footer-group-item" href="/link/">更多友链</a></div><div class="footer-group"><span class="footer-group-title">协议</span><a class="footer-group-item" href="/protocol/comment/" title="用户发言前，请认真阅读本条例。一经发言，即视为同意接受本条例；如不同意，请勿发言。">评论协议</a><a class="footer-group-item" href="/protocol/copyright/" title="本站所有原创文章采用知识共享(Creative Commons)署名—非商业性使用—相同方式共享4.0国际公共许可协议">版权协议</a></div></div><div id="footer-banner"><div id="footer-banner-container"><div class="footer-banner"><div class="copyright">Copyright &copy; 2021 - 2024 Eurkon.com All Rights Reserved.</div></div><div class="footer-banner"><div class="framework-info"><span>框架</span> <a target="_blank" rel="noopener external nofollow noreferrer" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题</span> <a target="_blank" rel="noopener external nofollow noreferrer" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div><div class="footer-banner"><a target="_blank" rel="noopener external nofollow noreferrer" href="https://beian.miit.gov.cn">粤ICP备2022108639号</a><a href="/protocol/copyright/" title="版权协议"><i class="fab fa-creative-commons"></i><i class="fab fa-creative-commons-by"></i><i class="fab fa-creative-commons-nc"></i><i class="fab fa-creative-commons-sa"></i></a></div></div></div></div></footer></div><div class="hidden" id="rightside-mask" onclick="eurkon.switchRightSide()"></div><div class="hidden" id="rightside"><div id="rightside-header"><div id="rightside-back"><i class="fas fa-chevron-left" onclick="eurkon.backRightSide()"></i></div><div id="rightside-title">设置</div><div id="rightside-close" onclick="eurkon.switchRightSide()"><i class="fas fa-xmark"></i></div></div><div id="rightside-content"><div id="card-newest-comments"><div class="item-headline"><i class="fas fa-comment-dots"></i><span>最新评论</span></div><div class="aside-list"><span>加载中...</span></div></div><div id="card-post-content"><div class="card-widget card-categories"><div class="item-headline"><i class="fas fa-folder-open"></i> <span>分类</span></div><ul class="card-category-list" id="aside-cat-list"><li class="card-category-list-item"><a class="card-category-list-link" href="/categories/%E4%BD%9C%E5%93%81%E6%A1%88%E4%BE%8B/"><span class="card-category-list-name">🖥️作品案例</span><span class="card-category-list-count">23</span></a></li><li class="card-category-list-item"><a class="card-category-list-link" href="/categories/%E5%88%86%E4%BA%AB%E8%BD%AC%E8%BD%BD/"><span class="card-category-list-name">🌐分享转载</span><span class="card-category-list-count">3</span></a></li><li class="card-category-list-item"><a class="card-category-list-link" href="/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"><span class="card-category-list-name">📚学习笔记</span><span class="card-category-list-count">24</span></a></li><li class="card-category-list-item"><a class="card-category-list-link" href="/categories/%E7%94%9F%E6%B4%BB%E9%9A%8F%E7%AC%94/"><span class="card-category-list-name">💬生活随笔</span><span class="card-category-list-count">1</span></a></li><li class="card-category-list-item"><a class="card-category-list-link" href="/categories/%E9%9D%A2%E8%AF%95%E7%B3%BB%E5%88%97/"><span class="card-category-list-name">📝面试系列</span><span class="card-category-list-count">21</span></a></li><li class="card-category-list-item"><a class="card-category-list-link" href="/categories/%E9%AD%94%E6%94%B9%E6%95%99%E7%A8%8B/"><span class="card-category-list-name">🎨魔改教程</span><span class="card-category-list-count">16</span></a></li></ul></div><div class="card-widget card-tags"><div class="item-headline"><i class="fas fa-tags"></i><span>标签</span></div><div class="card-tag-cloud"><a href="/tags/%E7%AE%97%E6%B3%95/" style="font-size:1.1em;color:#999">算法</a> <a href="/tags/%E6%96%87%E6%A1%A3/" style="font-size:1.26em;color:#999fa8">文档</a> <a href="/tags/R/" style="font-size:1.22em;color:#999ea4">R</a> <a href="/tags/Python/" style="font-size:1.1em;color:#999">Python</a> <a href="/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/" style="font-size:1.46em;color:#99a7bb">大数据</a> <a href="/tags/Butterfly/" style="font-size:1.34em;color:#99a3b0">Butterfly</a> <a href="/tags/JavaScript/" style="font-size:1.1em;color:#999">JavaScript</a> <a href="/tags/ECharts/" style="font-size:1.5em;color:#99a9bf">ECharts</a> <a href="/tags/Git/" style="font-size:1.1em;color:#999">Git</a> <a href="/tags/Kafka/" style="font-size:1.14em;color:#999b9d">Kafka</a> <a href="/tags/Hexo/" style="font-size:1.42em;color:#99a6b7">Hexo</a> <a href="/tags/%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93/" style="font-size:1.1em;color:#999">数据仓库</a> <a href="/tags/HTML/" style="font-size:1.1em;color:#999">HTML</a> <a href="/tags/Hive/" style="font-size:1.18em;color:#999ca1">Hive</a> <a href="/tags/MySQL/" style="font-size:1.26em;color:#999fa8">MySQL</a> <a href="/tags/Java/" style="font-size:1.38em;color:#99a4b4">Java</a> <a href="/tags/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/" style="font-size:1.3em;color:#99a1ac">数据分析</a> <a href="/tags/HBase/" style="font-size:1.14em;color:#999b9d">HBase</a> <a href="/tags/Linux/" style="font-size:1.1em;color:#999">Linux</a> <a href="/tags/Spark/" style="font-size:1.18em;color:#999ca1">Spark</a> <a href="/tags/Markdown/" style="font-size:1.1em;color:#999">Markdown</a> <a href="/tags/Elasticsearch/" style="font-size:1.1em;color:#999">Elasticsearch</a> <a href="/tags/PostgreSQL/" style="font-size:1.3em;color:#99a1ac">PostgreSQL</a> <a href="/tags/Flume/" style="font-size:1.14em;color:#999b9d">Flume</a> <a href="/tags/Sqoop/" style="font-size:1.14em;color:#999b9d">Sqoop</a> <a href="/tags/Zookeeper/" style="font-size:1.14em;color:#999b9d">Zookeeper</a> <a href="/tags/Hadoop/" style="font-size:1.18em;color:#999ca1">Hadoop</a> <a href="/tags/%E7%94%9F%E6%B4%BB%E9%9A%8F%E7%AC%94/" style="font-size:1.1em;color:#999">生活随笔</a></div></div></div></div><div id="rightside-config-hide"><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="translateLink" type="button" title="简繁转换">繁</button><button id="darkmode" type="button" title="日间和夜间模式切换"><i class="fas fa-sun"></i><i class="fas fa-moon"></i></button><button id="barrage-btn" type="button" title="热评开关" onclick="eurkon.switchCommentBarrage()"><i class="fas fa-message"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div id="rightmenu"><div class="rightmenu-group rightmenu-small"><div class="rightmenu-item" id="menu-backward" onclick="window.history.back()"><i class="fas fa-arrow-left"></i></div><div class="rightmenu-item" id="menu-forward" onclick="window.history.forward()"><i class="fas fa-arrow-right"></i></div><div class="rightmenu-item" id="menu-refresh" onclick="location.reload()"><i class="fas fa-arrow-rotate-right"></i></div><div class="rightmenu-item" id="menu-top" onclick="btf.scrollToDest(0,500)"><i class="fas fa-arrow-up"></i></div></div><div class="rightmenu-group rightmenu-line" id="rightmenu-text"><div class="rightmenu-item" id="menu-copy"><i class="fas fa-copy"></i><span>复制内容</span></div><div class="rightmenu-item" id="menu-comment"><i class="fas fa-comment"></i><span>引用评论</span></div><div class="rightmenu-item" id="menu-paste"><i class="fas fa-paste"></i><span>粘贴文本</span></div><div class="rightmenu-item" id="menu-search"><i class="fas fa-search"></i><span>在本站搜索</span></div><div class="rightmenu-item" id="menu-baidu"><i class="fas fa-search-plus"></i><span>去百度搜索</span></div></div><div class="rightmenu-group rightmenu-line" id="rightmenu-href"><div class="rightmenu-item" id="menu-copy-image"><i class="fas fa-copy"></i><span>复制图片</span></div><div class="rightmenu-item" id="menu-download-image"><i class="fas fa-download"></i><span>下载图片</span></div><div class="rightmenu-item" id="menu-link"><i class="fas fa-share"></i><span>分享链接</span></div><div class="rightmenu-item" id="menu-window"><i class="fas fa-window-restore"></i><span>新窗口打开</span></div></div><div class="rightmenu-group rightmenu-line" id="rightmenu-post"><a class="rightmenu-item" id="menu-random" href="/random/"><i class="fas fa-random"></i><span>随机文章</span></a><a class="rightmenu-item" id="menu-categories" href="/categories/"><i class="fas fa-shapes"></i><span>全部分类</span></a><a class="rightmenu-item" id="menu-tags" href="/tags/"><i class="fas fa-tags"></i><span>所有标签</span></a><div class="rightmenu-item" id="menu-share"><i class="fas fa-share-square"></i><span>分享本页</span></div></div><div class="rightmenu-group rightmenu-line" id="rightmenu-site"><a class="rightmenu-item" id="menu-message" href="/message/"><i class="fas fa-envelope"></i><span>留言信箱</span></a><a class="rightmenu-item" id="menu-about" href="/about/"><i class="fas fa-address-card"></i><span>关于本站</span></a></div></div><div id="rightmenu-mask"></div><div><script src="/js/utils.js?v=5.1.0"></script><script src="/js/main.js?v=5.1.0"></script><script src="/js/eurkon/color-thief.min.js"></script><script defer src="/js/eurkon/eurkon.js"></script><script defer data-pjax src="/js/eurkon/refresh.js"></script><script src="/js/tw_cn.js?v=5.1.0"></script><script src="https://cdn.jsdelivr.net/npm/instant.page@5.2.0/instantpage.min.js" type="module"></script><script src="https://cdn.jsdelivr.net/npm/vanilla-lazyload@19.1.3/dist/lazyload.iife.min.js"></script><script src="https://cdn.jsdelivr.net/npm/node-snackbar@0.1.16/dist/snackbar.min.js"></script><div class="js-pjax"><script>(() => {
  const runMermaid = ele => {
    window.loadMermaid = true
    const theme = document.documentElement.getAttribute('data-theme') === 'dark' ? 'dark' : 'default'

    ele.forEach((item, index) => {
      const mermaidSrc = item.firstElementChild
      const mermaidThemeConfig = `%%{init:{ 'theme':'${theme}'}}%%\n`
      const mermaidID = `mermaid-${index}`
      const mermaidDefinition = mermaidThemeConfig + mermaidSrc.textContent

      const renderFn = mermaid.render(mermaidID, mermaidDefinition)
      const renderMermaid = svg => {
        mermaidSrc.insertAdjacentHTML('afterend', svg)
      }

      // mermaid v9 and v10 compatibility
      typeof renderFn === 'string' ? renderMermaid(renderFn) : renderFn.then(({ svg }) => renderMermaid(svg))
    })
  }

  const codeToMermaid = () => {
    const codeMermaidEle = document.querySelectorAll('pre > code.mermaid')
    if (codeMermaidEle.length === 0) return

    codeMermaidEle.forEach(ele => {
      const preEle = document.createElement('pre')
      preEle.className = 'mermaid-src'
      preEle.hidden = true
      preEle.textContent = ele.textContent
      const newEle = document.createElement('div')
      newEle.className = 'mermaid-wrap'
      newEle.appendChild(preEle)
      ele.parentNode.replaceWith(newEle)
    })
  }

  const loadMermaid = () => {
    if (true) codeToMermaid()
    const $mermaid = document.querySelectorAll('#article-container .mermaid-wrap')
    if ($mermaid.length === 0) return

    const runMermaidFn = () => runMermaid($mermaid)
    btf.addGlobalFn('themeChange', runMermaidFn, 'mermaid')
    window.loadMermaid ? runMermaidFn() : btf.getScript('https://cdn.jsdelivr.net/npm/mermaid@11.3.0/dist/mermaid.min.js').then(runMermaidFn)
  }

  btf.addGlobalFn('encrypt', loadMermaid, 'mermaid')
  window.pjax ? loadMermaid() : document.addEventListener('DOMContentLoaded', loadMermaid)
})()</script><script>(() => {
  const getCount = () => {
    const countELement = document.getElementById('twikoo-count')
    if(!countELement) return
    twikoo.getCommentsCount({
      envId: 'https://twikoo.eurkon.com/',
      region: '',
      urls: [window.location.pathname],
      includeReply: false
    }).then(res => {
      countELement.textContent = res[0].count
    }).catch(err => {
      console.error(err)
    })
  }

  const init = () => {
    twikoo.init(Object.assign({
      el: '#twikoo-wrap',
      envId: 'https://twikoo.eurkon.com/',
      region: '',
      onCommentLoaded: () => {
        btf.loadLightbox(document.querySelectorAll('#twikoo .tk-content img:not(.tk-owo-emotion)'))
        setTimeout(function(){
          let tk_comment = document.querySelectorAll('.tk-comments-container .tk-comment')
          if (tk_comment.length > 0) {
            let html = `<div class="swiper-wrapper">`
            for (let i = 0; i < tk_comment.length; i++) {
              let tk_id = tk_comment[i].getAttribute('id') || ''
              let tk_nick = tk_comment[i].querySelector('.tk-nick')?.innerText || ''
              let tk_href = tk_comment[i].querySelector('.tk-nick')?.href || ''
              let tk_avatar = tk_comment[i].querySelector('.tk-avatar-img')?.src || ''
              let tk_time = tk_comment[i].querySelector('.tk-time')?.innerText || ''
              let tk_city = tk_comment[i].querySelector('.tk-extras .tk-extra:first-child span:last-child')?.innerText || ''
              let tk_content = tk_comment[i].querySelector('.tk-content>span:last-child')?.innerHTML || ''
              tk_content = tk_content.replace(/\n/g, '') // replace \n
              tk_content = tk_content.replace(/<blockquote>.*?<\/blockquote>/gi, '') // replace blockquote
              //- tk_content = tk_content.replace(/<a[^>]+?data-caption="image".*?<img.*?src="(.*?)"?[^\>]+><\/a>/ig, '[图片]') // replace image link
              //- tk_content = tk_content.replace(/<img.*?src="(.*?)"?[^\>]+>/ig, '[图片]') // replace image link
              //- tk_content = tk_content.replace(/<a[^>]+?href=["']?([^"']+)["']?[^>]*>([^<]+)<\/a>/gi, '[链接]') // replace url
              tk_content = tk_content.replace(/<pre.*?<\/pre>/gi, '[代码]') // replace code
              //- tk_content = tk_content.replace(/<[^>]+>/g, "") // remove html tag
              html += `
                <div class="swiper-slide">
                  <div class="comment-barrage-item">
                    <div class="barrage-info">
                      <a class="barrage-title" title="跳转至评论区" href="#post-comment">热评</a>
                      <a href="${tk_href ? tk_href + '" target="_blank" rel="noopener noreferrer" title="访问 '+ tk_nick +'"' : 'javascript:void(0);"'}>
                        <img class="barrage-avatar" src="${tk_avatar}">
                      </a>
                      <span class="barrage-nick">${tk_nick}</span>
                      <span class="barrage-city">${tk_city}</span>
                      <span class="barrage-time">${tk_time}</span>
                      <a class="barrage-close" onclick="eurkon.switchCommentBarrage()" title="隐藏热评"><i class="fa-solid fa-xmark"></i></a>
                    </div>
                    <div class="barrage-content">
                      <a title="跳转至该评论" href="#${tk_id}">${tk_content}</a>
                    </div>
                  </div>
                </div>`
            }
            html += '</div>'
            let barrageContainer = document.getElementById('comment-barrage') || document.createElement('div')
            barrageContainer.id = 'comment-barrage'
            barrageContainer.innerHTML = html
            barrageContainer.style.bottom = window.localStorage.getItem('commentBarrageDisplay') === 'false' ? '-1000px' : '1rem'
            if( document.getElementById('barrage-btn') ) document.getElementById('barrage-btn').classList.add(window.localStorage.getItem('commentBarrageDisplay') === 'false' ? 'off' : 'on')
            document.getElementById('post-comment').appendChild(barrageContainer)
            var barrageSwiper = new Swiper('#comment-barrage', {
              direction: 'vertical',
              loop: true,
              mousewheel: true,
              autoplay: {
                delay: 3000,
                disableOnInteraction: true,
              }
            })
            barrageContainer.onmouseenter = function () {
              barrageSwiper.autoplay.stop()
            };
            barrageContainer.onmouseleave = function () {
              barrageSwiper.autoplay.start()
            };
          }
        }, 1000)
      }
    }, null))

    GLOBAL_CONFIG_SITE.isPost && getCount()
  }

  const loadTwikoo = () => {
    if (typeof twikoo === 'object') setTimeout(init,0)
    else btf.getScript('https://cdn.jsdelivr.net/npm/twikoo@1.6.39/dist/twikoo.all.min.js').then(init)
  }

  if ('Twikoo' === 'Twikoo' || !false) {
    if (false) btf.loadComment(document.getElementById('twikoo-wrap'), loadTwikoo)
    else loadTwikoo()
  } else {
    window.loadOtherComment = loadTwikoo
  }
})()</script></div><script>window.newestComments = {
  changeContent: content => {
    if (content === '') return content

    content = content.replace(/<img.*?src="(.*?)"?[^\>]+>/ig, '[图片]') // replace image link
    content = content.replace(/<a[^>]+?href=["']?([^"']+)["']?[^>]*>([^<]+)<\/a>/gi, '[链接]') // replace url
    content = content.replace(/<pre><code>.*?<\/pre>/gi, '[代码]') // replace code
    content = content.replace(/<code>.*?<\/code>/gi, '[代码]') // replace code      
    content = content.replace(/<[^>]+>/g, "") // remove html tag

    if (content.length > 150) {
      content = content.substring(0, 150) + '...'
    }
    return content
  },

  generateHtml: (array, ele) => {
    let result = ''

    if (array.length) {
      for (let i = 0; i < array.length; i++) {
        result += '<div class="aside-list-item">'

        if (true && array[i].avatar) {
          const imgAttr = 'data-lazy-src'
          result += `<a href="${array[i].url}" class="thumbnail"><img ${imgAttr}="${array[i].avatar}" alt="${array[i].nick}"></a>`
        }

        result += `<div class="content">
        <a class="comment" href="${array[i].url}" title="${array[i].content}">${array[i].content}</a>
        <div class="name"><span>${array[i].nick} / </span><time datetime="${array[i].date}">${btf.diffDate(array[i].date, true)}</time></div>
        </div></div>`
      }
    } else {
      result += '暂无评论'
    }

    ele.innerHTML = result
    window.lazyLoadInstance && window.lazyLoadInstance.update()
    window.pjax && window.pjax.refresh(ele)
  },

  newestCommentInit: (name, getComment) => {
    const $dom = document.querySelector('#card-newest-comments .aside-list')
    if ($dom) {
      const data = btf.saveToLocal.get(name)
      if (data) {
        newestComments.generateHtml(JSON.parse(data), $dom)
      } else {
        getComment($dom)
      }
    }
  },

  run: (name, getComment) => {
    newestComments.newestCommentInit(name, getComment)
    btf.addGlobalFn('pjaxComplete', () => newestComments.newestCommentInit(name, getComment), name)
  }
}</script><script>window.addEventListener('load', () => {
  const keyName = 'twikoo-newest-comments'
  const { changeContent, generateHtml, run } = window.newestComments

  const getComment = ele => {
    const runTwikoo = () => {
      twikoo.getRecentComments({
        envId: 'https://twikoo.eurkon.com/',
        region: '',
        pageSize: 8,
        includeReply: true
      }).then(res => {
        const twikooArray = res.map(e => {
          return {
            'content': changeContent(e.comment),
            'avatar': e.avatar,
            'nick': e.nick,
            'url': e.url + '#' + e.id,
            'date': new Date(e.created).toISOString()
          }
        })

        btf.saveToLocal.set(keyName, JSON.stringify(twikooArray), 10/(60*24))
        generateHtml(twikooArray, ele)
      }).catch(err => {
        console.error(err)
        ele.textContent= "无法获取评论，请确认相关配置是否正确"
      })
    }

    if (typeof twikoo === 'object') {
      runTwikoo()
    } else {
      btf.getScript('https://cdn.jsdelivr.net/npm/twikoo@1.6.39/dist/twikoo.all.min.js').then(runTwikoo)
    }
  }

  run(keyName, getComment)
})</script><script defer async src="//at.alicdn.com/t/font_2358265_expoyqe85d4.js"></script><script defer src="/js/custom.js"></script><script defer data-pjax src="/js/refresh.js"></script><script src="https://cdn.jsdelivr.net/npm/pjax@0.2.8/pjax.min.js"></script><script>(() => {
  const pjaxSelectors = ["head > title","#config-diff","#body-wrap","#rightside-config-hide","#rightside-config-show",".js-pjax"]

  window.pjax = new Pjax({
    elements: 'a:not([target="_blank"])',
    selectors: pjaxSelectors,
    cacheBust: false,
    analytics: false,
    scrollRestoration: false
  })

  const triggerPjaxFn = (val) => {
    if (!val) return
    Object.values(val).forEach(fn => fn())
  }

  document.addEventListener('pjax:send', () => {
    // removeEventListener
    btf.removeGlobalFnEvent('pjaxSendOnce')
    btf.removeGlobalFnEvent('themeChange')

    // reset readmode
    const $bodyClassList = document.body.classList
    if ($bodyClassList.contains('read-mode')) $bodyClassList.remove('read-mode')

    triggerPjaxFn(window.globalFn.pjaxSend)
  })

  document.addEventListener('pjax:complete', () => {
    btf.removeGlobalFnEvent('pjaxCompleteOnce')
    document.querySelectorAll('script[data-pjax]').forEach(item => {
      const newScript = document.createElement('script')
      const content = item.text || item.textContent || item.innerHTML || ""
      Array.from(item.attributes).forEach(attr => newScript.setAttribute(attr.name, attr.value))
      newScript.appendChild(document.createTextNode(content))
      item.parentNode.replaceChild(newScript, item)
    })

    triggerPjaxFn(window.globalFn.pjaxComplete)
  })

  document.addEventListener('pjax:error', e => {
    if (e.request.status === 404) {
      pjax.loadUrl('/404.html')
    }
  })
})()</script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="text-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i> <span>数据加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"></div></div><hr><div id="local-search-results"></div><div id="local-search-stats-wrap"></div></div></div><div id="search-mask"></div><script src="/js/search/local-search.js?v=5.1.0"></script></div></div></body></html><script>var posts=[{title:"ECharts 同X轴多Y轴图表",path:"/post/acc26f11.html",categories:[{name:"作品案例",path:"/categories/作品案例/"}],tags:[{name:"ECharts",path:"/tags/ECharts/"}],cover:"/images/cover/echarts_multi_chart.png",date:"2021-08-30T01:00:00.000Z",updated:"2021-08-30T01:00:00.000Z"},{title:"ECharts 地图上显示柱状图",path:"/post/5a6784e7.html",categories:[{name:"作品案例",path:"/categories/作品案例/"}],tags:[{name:"ECharts",path:"/tags/ECharts/"}],cover:"/images/cover/echarts_map_bar.png",date:"2021-11-10T01:00:00.000Z",updated:"2021-11-10T01:00:00.000Z"},{title:"ECharts 地图上显示饼图",path:"/post/d8b77f28.html",categories:[{name:"作品案例",path:"/categories/作品案例/"}],tags:[{name:"ECharts",path:"/tags/ECharts/"}],cover:"/images/cover/echarts_map_pie.png",date:"2021-11-01T01:00:00.000Z",updated:"2021-11-01T01:00:00.000Z"},{title:"ECharts 子弹图",path:"/post/620d6870.html",categories:[{name:"作品案例",path:"/categories/作品案例/"}],tags:[{name:"ECharts",path:"/tags/ECharts/"}],cover:"/images/cover/echarts_bullet.png",date:"2023-04-27T01:00:00.000Z",updated:"2023-04-27T01:00:00.000Z"},{title:"ECharts 对比漏斗图",path:"/post/ee94ffd8.html",categories:[{name:"作品案例",path:"/categories/作品案例/"}],tags:[{name:"ECharts",path:"/tags/ECharts/"}],cover:"/images/cover/echarts_funnel.png",date:"2022-06-10T01:00:00.000Z",updated:"2022-06-10T01:00:00.000Z"},{title:"ECharts 帕累托图",path:"/post/b0188c87.html",categories:[{name:"作品案例",path:"/categories/作品案例/"}],tags:[{name:"ECharts",path:"/tags/ECharts/"}],cover:"/images/cover/echarts_pareto.png",date:"2023-05-30T01:00:00.000Z",updated:"2023-05-30T01:00:00.000Z"},{title:"ECharts 弹窗悬浮图表",path:"/post/8050767e.html",categories:[{name:"作品案例",path:"/categories/作品案例/"}],tags:[{name:"ECharts",path:"/tags/ECharts/"}],cover:"/images/cover/echarts_tooltip_chart.png",date:"2021-08-15T01:00:00.000Z",updated:"2021-08-15T01:00:00.000Z"},{title:"ECharts 径向条形图",path:"/post/22774ddc.html",categories:[{name:"作品案例",path:"/categories/作品案例/"}],tags:[{name:"ECharts",path:"/tags/ECharts/"}],cover:"/images/cover/echarts_radial_bar.png",date:"2023-04-26T01:00:00.000Z",updated:"2023-04-26T01:00:00.000Z"},{title:"ECharts 散点地图",path:"/post/e3dd705b.html",categories:[{name:"作品案例",path:"/categories/作品案例/"}],tags:[{name:"ECharts",path:"/tags/ECharts/"}],cover:"/images/cover/echarts_scatter_map.png",date:"2021-09-01T01:00:00.000Z",updated:"2021-09-01T01:00:00.000Z"},{title:"ECharts 日期旭日图",path:"/post/9bcf49c7.html",categories:[{name:"作品案例",path:"/categories/作品案例/"}],tags:[{name:"ECharts",path:"/tags/ECharts/"}],cover:"/images/cover/echarts_date_sunburst.png",date:"2022-06-21T01:00:00.000Z",updated:"2022-06-21T01:00:00.000Z"},{title:"ECharts 时序图",path:"/post/b9e0457b.html",categories:[{name:"作品案例",path:"/categories/作品案例/"}],tags:[{name:"ECharts",path:"/tags/ECharts/"}],cover:"/images/cover/echarts_timeline.png",date:"2021-08-01T01:00:00.000Z",updated:"2021-08-01T01:00:00.000Z"},{title:"ECharts 时间极坐标",path:"/post/97890f7.html",categories:[{name:"作品案例",path:"/categories/作品案例/"}],tags:[{name:"ECharts",path:"/tags/ECharts/"}],cover:"/images/cover/echarts_time_polar.png",date:"2022-07-05T01:00:00.000Z",updated:"2022-07-05T01:00:00.000Z"},{title:"ECharts 标签地图",path:"/post/19a77adb.html",categories:[{name:"作品案例",path:"/categories/作品案例/"}],tags:[{name:"ECharts",path:"/tags/ECharts/"}],cover:"/images/cover/echarts_label_map.png",date:"2021-10-01T01:00:00.000Z",updated:"2021-10-01T01:00:00.000Z"},{title:"ECharts 水球图",path:"/post/51a3160b.html",categories:[{name:"作品案例",path:"/categories/作品案例/"}],tags:[{name:"ECharts",path:"/tags/ECharts/"}],cover:"/images/cover/echarts_liquidfill.png",date:"2022-05-16T01:00:00.000Z",updated:"2022-05-16T01:00:00.000Z"},{title:"ECharts 流程图",path:"/post/b7fd4932.html",categories:[{name:"作品案例",path:"/categories/作品案例/"}],tags:[{name:"ECharts",path:"/tags/ECharts/"}],cover:"/images/cover/echarts_flowchart.png",date:"2022-05-05T01:00:00.000Z",updated:"2022-05-05T01:00:00.000Z"},{title:"ECharts 渐变折线图",path:"/post/68739172.html",categories:[{name:"作品案例",path:"/categories/作品案例/"}],tags:[{name:"ECharts",path:"/tags/ECharts/"}],cover:"/images/cover/echarts_line_gradient.png",date:"2023-03-12T01:00:00.000Z",updated:"2023-03-12T01:00:00.000Z"},{title:"ECharts 热力地图",path:"/post/85c31989.html",categories:[{name:"作品案例",path:"/categories/作品案例/"}],tags:[{name:"ECharts",path:"/tags/ECharts/"}],cover:"/images/cover/echarts_heat_map.png",date:"2021-09-15T01:00:00.000Z",updated:"2021-09-15T01:00:00.000Z"},{title:"ECharts 词云图",path:"/post/f6f4d480.html",categories:[{name:"作品案例",path:"/categories/作品案例/"}],tags:[{name:"ECharts",path:"/tags/ECharts/"}],cover:"/images/cover/echarts_word_cloud.png",date:"2022-05-13T01:00:00.000Z",updated:"2022-05-13T01:00:00.000Z"},{title:"ECharts 迁徙地图",path:"/post/165ef0d3.html",categories:[{name:"作品案例",path:"/categories/作品案例/"}],tags:[{name:"ECharts",path:"/tags/ECharts/"}],cover:"/images/cover/echarts_migration_map.png",date:"2021-10-15T01:00:00.000Z",updated:"2021-10-15T01:00:00.000Z"},{title:"Python 自建 API 合集",path:"/post/ee499a0b.html",categories:[{name:"作品案例",path:"/categories/作品案例/"}],tags:[{name:"Python",path:"/tags/Python/"}],cover:"/images/cover/python_api.jpg",date:"2021-06-07T01:00:00.000Z",updated:"2021-03-08T01:00:00.000Z"},{title:"AARRR 用户运营分析",path:"/post/fa6d499a.html",categories:[{name:"学习笔记",path:"/categories/学习笔记/"}],tags:[{name:"数据分析",path:"/tags/数据分析/"},{name:"PostgreSQL",path:"/tags/PostgreSQL/"}],cover:"/images/cover/aarrr_analysis.png",date:"2022-03-15T02:00:00.000Z",updated:"2022-03-15T02:00:00.000Z"},{title:"ABC 分类法",path:"/post/3e7451d9.html",categories:[{name:"学习笔记",path:"/categories/学习笔记/"}],tags:[{name:"数据分析",path:"/tags/数据分析/"},{name:"PostgreSQL",path:"/tags/PostgreSQL/"}],cover:"/images/cover/abc.png",date:"2022-01-15T02:00:00.000Z",updated:"2022-01-15T02:00:00.000Z"},{title:"HDFS Shell 命令",path:"/post/d1e7dfd3.html",categories:[{name:"学习笔记",path:"/categories/学习笔记/"}],tags:[{name:"大数据",path:"/tags/大数据/"},{name:"Hadoop",path:"/tags/Hadoop/"}],cover:"/images/cover/hdfs_shell.jpg",date:"2021-03-05T02:31:14.000Z",updated:"2021-03-05T02:31:14.000Z"},{title:"JavaScript 实用技巧",path:"/post/ea69450.html",categories:[{name:"学习笔记",path:"/categories/学习笔记/"}],tags:[{name:"JavaScript",path:"/tags/JavaScript/"}],cover:"/images/cover/js_skill.png",date:"2021-12-25T02:00:00.000Z",updated:"2021-12-25T02:00:00.000Z"},{title:"RFM 客户分析模型",path:"/post/97f6661d.html",categories:[{name:"学习笔记",path:"/categories/学习笔记/"}],tags:[{name:"数据分析",path:"/tags/数据分析/"},{name:"PostgreSQL",path:"/tags/PostgreSQL/"}],cover:"/images/cover/rfm.png",date:"2022-01-01T02:00:00.000Z",updated:"2022-01-01T02:00:00.000Z"},{title:"库存周转分析",path:"/post/e305ad56.html",categories:[{name:"学习笔记",path:"/categories/学习笔记/"}],tags:[{name:"数据分析",path:"/tags/数据分析/"},{name:"PostgreSQL",path:"/tags/PostgreSQL/"}],cover:"/images/cover/inventory_turnover_analysis.png",date:"2022-04-01T02:00:00.000Z",updated:"2022-04-01T02:00:00.000Z"},{title:"波士顿矩阵",path:"/post/dd96e05f.html",categories:[{name:"学习笔记",path:"/categories/学习笔记/"}],tags:[{name:"数据分析",path:"/tags/数据分析/"},{name:"PostgreSQL",path:"/tags/PostgreSQL/"}],cover:"/images/cover/bcg_matrix.png",date:"2022-02-01T02:00:00.000Z",updated:"2022-02-01T02:00:00.000Z"},{title:"电商转化漏斗模型",path:"/post/72736a6d.html",categories:[{name:"学习笔记",path:"/categories/学习笔记/"}],tags:[{name:"数据分析",path:"/tags/数据分析/"},{name:"PostgreSQL",path:"/tags/PostgreSQL/"}],cover:"/images/cover/e-commerce_conversion.png",date:"2022-02-15T02:00:00.000Z",updated:"2022-02-15T02:00:00.000Z"},{title:"购物篮分析",path:"/post/931f21f9.html",categories:[{name:"学习笔记",path:"/categories/学习笔记/"}],tags:[{name:"数据分析",path:"/tags/数据分析/"},{name:"PostgreSQL",path:"/tags/PostgreSQL/"}],cover:"/images/cover/basket_analysis.png",date:"2022-03-01T02:00:00.000Z",updated:"2022-03-01T02:00:00.000Z"},{title:"26 个字母 26 句话",path:"/post/32c40e7c.html",categories:[{name:"生活随笔",path:"/categories/生活随笔/"}],tags:[{name:"生活随笔",path:"/tags/生活随笔/"}],cover:"/images/cover/letter_proverb.png",date:"2021-02-12T00:00:00.000Z",updated:"2021-02-12T00:00:00.000Z"},{title:"HTML 特殊符号编码对照表",path:"/post/65795b97.html",categories:[{name:"分享转载",path:"/categories/分享转载/"}],tags:[{name:"HTML",path:"/tags/HTML/"},{name:"文档",path:"/tags/文档/"}],cover:"/images/cover/html_symbols.jpg",date:"2021-03-12T07:54:12.000Z",updated:"2021-03-12T07:54:12.000Z"},{title:"特殊符号",path:"/post/73bb9016.html",categories:[{name:"分享转载",path:"/categories/分享转载/"}],tags:[{name:"文档",path:"/tags/文档/"}],cover:"/images/cover/special_symbols.jpg",date:"2021-03-10T02:23:12.000Z",updated:"2021-03-10T02:23:12.000Z"},{title:"Flume 面试题解析",path:"/post/5a2a12a6.html",categories:[{name:"面试系列",path:"/categories/面试系列/"}],tags:[{name:"大数据",path:"/tags/大数据/"},{name:"Flume",path:"/tags/Flume/"}],cover:"/images/cover/bigdata_interview.png",date:"2021-03-29T01:00:00.000Z",updated:"2021-03-29T01:00:00.000Z"},{title:"Java 面试题解析",path:"/post/d2aef718.html",categories:[{name:"面试系列",path:"/categories/面试系列/"}],tags:[{name:"Java",path:"/tags/Java/"}],cover:"/images/cover/java_interview.jpg",date:"2021-03-15T01:00:00.000Z",updated:"2021-03-15T01:00:00.000Z"},{title:"Java 面试题解析（IO流）",path:"/post/af128a42.html",categories:[{name:"面试系列",path:"/categories/面试系列/"}],tags:[{name:"Java",path:"/tags/Java/"}],cover:"/images/cover/java_interview.jpg",date:"2021-03-19T01:00:00.000Z",updated:"2021-03-19T01:00:00.000Z"},{title:"Java 面试题解析（反射）",path:"/post/9fbf7373.html",categories:[{name:"面试系列",path:"/categories/面试系列/"}],tags:[{name:"Java",path:"/tags/Java/"}],cover:"/images/cover/java_interview.jpg",date:"2021-03-21T01:00:00.000Z",updated:"2021-03-21T01:00:00.000Z"},{title:"Java 面试题解析（容器）",path:"/post/d07acd09.html",categories:[{name:"面试系列",path:"/categories/面试系列/"}],tags:[{name:"Java",path:"/tags/Java/"}],cover:"/images/cover/java_interview.jpg",date:"2021-03-17T01:00:00.000Z",updated:"2021-03-17T01:00:00.000Z"},{title:"Sqoop 面试题解析",path:"/post/420614eb.html",categories:[{name:"面试系列",path:"/categories/面试系列/"}],tags:[{name:"大数据",path:"/tags/大数据/"},{name:"Sqoop",path:"/tags/Sqoop/"}],cover:"/images/cover/bigdata_interview.png",date:"2021-04-13T01:00:00.000Z",updated:"2021-04-13T01:00:00.000Z"},{title:"Zookeeper 面试题解析",path:"/post/2f1ea7f2.html",categories:[{name:"面试系列",path:"/categories/面试系列/"}],tags:[{name:"大数据",path:"/tags/大数据/"},{name:"Zookeeper",path:"/tags/Zookeeper/"}],cover:"/images/cover/bigdata_interview.png",date:"2021-03-27T01:00:00.000Z",updated:"2021-03-27T01:00:00.000Z"},{title:"大数据面试题解析",path:"/post/7e24cf66.html",categories:[{name:"面试系列",path:"/categories/面试系列/"}],tags:[{name:"大数据",path:"/tags/大数据/"},{name:"Hadoop",path:"/tags/Hadoop/"},{name:"Flume",path:"/tags/Flume/"},{name:"Sqoop",path:"/tags/Sqoop/"},{name:"Zookeeper",path:"/tags/Zookeeper/"},{name:"Kafka",path:"/tags/Kafka/"},{name:"Hive",path:"/tags/Hive/"},{name:"HBase",path:"/tags/HBase/"},{name:"MySQL",path:"/tags/MySQL/"},{name:"Spark",path:"/tags/Spark/"}],cover:"/images/cover/bigdata_interview.png",date:"2021-03-25T01:00:00.000Z",updated:"2021-03-25T01:00:00.000Z"},{title:"Butterffly 分类页和标签页隐藏侧栏",path:"/post/d498d8b1.html",categories:[{name:"魔改教程",path:"/categories/魔改教程/"}],tags:[{name:"Hexo",path:"/tags/Hexo/"},{name:"Butterfly",path:"/tags/Butterfly/"}],cover:"/images/cover/butterfly_hide_side.png",date:"2022-07-20T01:00:00.000Z",updated:"2022-08-04T01:00:00.000Z"},{title:"Butterfly Twikoo 评论热评",path:"/post/364efc10.html",categories:[{name:"魔改教程",path:"/categories/魔改教程/"}],tags:[{name:"Hexo",path:"/tags/Hexo/"},{name:"Butterfly",path:"/tags/Butterfly/"}],cover:"/images/cover/twikoo_comment_barrage.png",date:"2022-09-13T01:00:00.000Z",updated:"2022-09-13T01:00:00.000Z"},{title:"Butterfly 分类标签导航栏",path:"/post/65b72006.html",categories:[{name:"魔改教程",path:"/categories/魔改教程/"}],tags:[{name:"Hexo",path:"/tags/Hexo/"},{name:"Butterfly",path:"/tags/Butterfly/"}],cover:"/images/post/butterfly/butterfly_categories_list.png",date:"2022-05-23T02:00:00.000Z",updated:"2023-03-21T02:00:00.000Z"},{title:"Butterfly 分类标签归档页增加文章索引",path:"/post/27df86b.html",categories:[{name:"魔改教程",path:"/categories/魔改教程/"}],tags:[{name:"Hexo",path:"/tags/Hexo/"},{name:"Butterfly",path:"/tags/Butterfly/"}],cover:"/images/cover/butterfly_post_index_eurkon.png",date:"2022-07-28T01:00:00.000Z",updated:"2022-07-28T01:00:00.000Z"},{title:"Butterfly 微博热搜侧边栏",path:"/post/38b005e1.html",categories:[{name:"魔改教程",path:"/categories/魔改教程/"}],tags:[{name:"Hexo",path:"/tags/Hexo/"},{name:"Butterfly",path:"/tags/Butterfly/"}],cover:"/images/cover/butterfly_weibo.jpg",date:"2021-06-03T01:00:00.000Z",updated:"2023-03-20T01:00:00.000Z"},{title:"Butterfly 推荐文章增加文章描述",path:"/post/3d2664bb.html",categories:[{name:"魔改教程",path:"/categories/魔改教程/"}],tags:[{name:"Hexo",path:"/tags/Hexo/"},{name:"Butterfly",path:"/tags/Butterfly/"}],cover:"/images/cover/butterfly_related_post.png",date:"2022-08-16T02:00:00.000Z",updated:"2022-08-16T02:00:00.000Z"},{title:"Butterfly 文章增加段落序号",path:"/post/70e521c2.html",categories:[{name:"魔改教程",path:"/categories/魔改教程/"}],tags:[{name:"Hexo",path:"/tags/Hexo/"},{name:"Butterfly",path:"/tags/Butterfly/"}],cover:"/images/cover/butterfly_toc_number.png",date:"2022-10-31T01:00:00.000Z",updated:"2022-10-31T01:00:00.000Z"},{title:"Butterfly 标签云增加文章数上下标",path:"/post/6687849c.html",categories:[{name:"魔改教程",path:"/categories/魔改教程/"}],tags:[{name:"Hexo",path:"/tags/Hexo/"},{name:"Butterfly",path:"/tags/Butterfly/"}],cover:"/images/cover/butterfly_tags_cloud.png",date:"2021-07-15T01:00:00.000Z",updated:"2021-07-15T01:00:00.000Z"},{title:"Front-matter",path:"/post/31e4c77c.html",categories:[{name:"魔改教程",path:"/categories/魔改教程/"}],tags:[{name:"Hexo",path:"/tags/Hexo/"},{name:"Butterfly",path:"/tags/Butterfly/"}],cover:"/images/cover/hexo.png",date:"2021-01-02T13:59:56.000Z",updated:"2021-01-02T13:59:56.000Z"},{title:"Hello Hexo",path:"/post/a1751c09.html",categories:[{name:"魔改教程",path:"/categories/魔改教程/"}],tags:[{name:"Hexo",path:"/tags/Hexo/"}],cover:"/images/cover/hexo.png",date:"2021-01-01T00:00:00.000Z",updated:"2021-01-01T00:00:00.000Z"},{title:"在 Hexo 中插入 Chart 动态图表",path:"/post/a6e75a2b.html",categories:[{name:"魔改教程",path:"/categories/魔改教程/"}],tags:[{name:"Hexo",path:"/tags/Hexo/"}],cover:"/images/cover/hexo_chartjs.svg",date:"2021-01-04T01:38:32.000Z",updated:"2021-01-04T01:38:32.000Z"},{title:"ECharts 地图上显示折线图",path:"/post/e83030eb.html",categories:[{name:"作品案例",path:"/categories/作品案例/"}],tags:[{name:"ECharts",path:"/tags/ECharts/"}],cover:"/images/cover/echarts_map_line.png",date:"2021-11-20T01:00:00.000Z",updated:"2021-11-20T01:00:00.000Z"},{title:"ECharts 生涯彩虹图",path:"/post/553238e8.html",categories:[{name:"作品案例",path:"/categories/作品案例/"}],tags:[{name:"ECharts",path:"/tags/ECharts/"}],cover:"/images/cover/echarts_career.png",date:"2022-11-06T01:00:00.000Z",updated:"2022-11-06T01:00:00.000Z"},{title:"Git 使用教程",path:"/post/c3cf24c7.html",categories:[{name:"学习笔记",path:"/categories/学习笔记/"}],tags:[{name:"Git",path:"/tags/Git/"}],cover:"/images/cover/git.png",date:"2021-02-21T05:16:02.000Z",updated:"2021-02-21T05:16:02.000Z"},{title:"Linux 常用命令",path:"/post/817c7d82.html",categories:[{name:"学习笔记",path:"/categories/学习笔记/"}],tags:[{name:"Linux",path:"/tags/Linux/"}],cover:"/images/cover/linux_command.png",date:"2021-04-19T01:00:00.000Z",updated:"2021-04-19T01:00:00.000Z"},{title:"Markdown 基本语法",path:"/post/c894e39a.html",categories:[{name:"学习笔记",path:"/categories/学习笔记/"}],tags:[{name:"Markdown",path:"/tags/Markdown/"}],cover:"/images/cover/markdown_grammar.jpg",date:"2021-01-03T06:14:53.000Z",updated:"2021-01-03T06:14:53.000Z"},{title:"MySQL 优化",path:"/post/d7961cf0.html",categories:[{name:"学习笔记",path:"/categories/学习笔记/"}],tags:[{name:"大数据",path:"/tags/大数据/"},{name:"MySQL",path:"/tags/MySQL/"}],cover:"/images/cover/mysql_optimization.jpg",date:"2021-01-14T05:32:11.000Z",updated:"2021-01-14T05:32:11.000Z"},{title:"MySQL 常用命令行",path:"/post/4bd4f98e.html",categories:[{name:"学习笔记",path:"/categories/学习笔记/"}],tags:[{name:"大数据",path:"/tags/大数据/"},{name:"MySQL",path:"/tags/MySQL/"}],cover:"/images/cover/mysql_command.png",date:"2021-01-13T01:24:44.000Z",updated:"2021-01-13T01:24:44.000Z"},{title:"R 语言图表",path:"/post/b35ac98a.html",categories:[{name:"学习笔记",path:"/categories/学习笔记/"}],tags:[{name:"大数据",path:"/tags/大数据/"},{name:"R",path:"/tags/R/"}],cover:"/images/cover/r_chart.jpg",date:"2021-01-20T08:04:45.000Z",updated:"2021-01-20T08:04:45.000Z"},{title:"排序算法",path:"/post/735e5788.html",categories:[{name:"学习笔记",path:"/categories/学习笔记/"}],tags:[{name:"算法",path:"/tags/算法/"}],cover:"/images/cover/sort_algorithm.jpg",date:"2021-03-13T05:16:02.000Z",updated:"2021-03-13T05:16:02.000Z"},{title:"数仓设计与 ETL 规范",path:"/post/1c85bfc3.html",categories:[{name:"学习笔记",path:"/categories/学习笔记/"}],tags:[{name:"文档",path:"/tags/文档/"},{name:"数据仓库",path:"/tags/数据仓库/"}],cover:"/images/cover/etl_norm.png",date:"2022-12-31T02:00:00.000Z",updated:"2022-12-31T02:00:00.000Z"},{title:"Elasticsearch 面试题解析",path:"/post/fae3ec89.html",categories:[{name:"面试系列",path:"/categories/面试系列/"}],tags:[{name:"大数据",path:"/tags/大数据/"},{name:"Elasticsearch",path:"/tags/Elasticsearch/"}],cover:"/images/cover/bigdata_interview.png",date:"2021-06-25T01:00:00.000Z",updated:"2021-06-25T01:00:00.000Z"},{title:"HBase 面试题解析",path:"/post/47457d03.html",categories:[{name:"面试系列",path:"/categories/面试系列/"}],tags:[{name:"大数据",path:"/tags/大数据/"},{name:"HBase",path:"/tags/HBase/"}],cover:"/images/cover/bigdata_interview.png",date:"2021-04-02T01:00:00.000Z",updated:"2021-04-02T01:00:00.000Z"},{title:"Hive 面试题解析",path:"/post/62c9bbde.html",categories:[{name:"面试系列",path:"/categories/面试系列/"}],tags:[{name:"大数据",path:"/tags/大数据/"},{name:"Hive",path:"/tags/Hive/"}],cover:"/images/cover/bigdata_interview.png",date:"2021-03-31T01:00:00.000Z",updated:"2021-03-31T01:00:00.000Z"},{title:"Java 面试题解析（并发）",path:"/post/32cf50db.html",categories:[{name:"面试系列",path:"/categories/面试系列/"}],tags:[{name:"Java",path:"/tags/Java/"}],cover:"/images/cover/java_interview.jpg",date:"2021-03-18T01:00:00.000Z",updated:"2021-03-18T01:00:00.000Z"},{title:"Java 面试题解析（数据库）",path:"/post/73adfcb0.html",categories:[{name:"面试系列",path:"/categories/面试系列/"}],tags:[{name:"Java",path:"/tags/Java/"}],cover:"/images/cover/java_interview.jpg",date:"2021-03-20T01:00:00.000Z",updated:"2021-03-20T01:00:00.000Z"},{title:"Java 面试题解析（设计模式）",path:"/post/1cfbd3b3.html",categories:[{name:"面试系列",path:"/categories/面试系列/"}],tags:[{name:"Java",path:"/tags/Java/"}],cover:"/images/cover/java_interview.jpg",date:"2021-03-21T04:00:00.000Z",updated:"2021-03-21T04:00:00.000Z"},{title:"Kafka 面试题解析",path:"/post/89cabcb1.html",categories:[{name:"面试系列",path:"/categories/面试系列/"}],tags:[{name:"大数据",path:"/tags/大数据/"},{name:"Kafka",path:"/tags/Kafka/"}],cover:"/images/cover/bigdata_interview.png",date:"2021-03-30T01:00:00.000Z",updated:"2021-03-30T01:00:00.000Z"},{title:"Hexo 博客实时访问统计图",path:"/post/61763977.html",categories:[{name:"魔改教程",path:"/categories/魔改教程/"}],tags:[{name:"ECharts",path:"/tags/ECharts/"},{name:"Hexo",path:"/tags/Hexo/"}],cover:"/images/cover/hexo.png",date:"2021-05-17T01:00:00.000Z",updated:"2022-03-29T01:00:00.000Z"},{title:"Hexo 博客访问日历图",path:"/post/1a169b5a.html",categories:[{name:"魔改教程",path:"/categories/魔改教程/"}],tags:[{name:"Hexo",path:"/tags/Hexo/"}],cover:"/images/cover/hexo.png",date:"2021-05-17T04:00:00.000Z",updated:"2022-03-29T04:00:00.000Z"},{title:"Hexo 博客访问统计图（弃用）",path:"/post/ef1da941.html",categories:[{name:"魔改教程",path:"/categories/魔改教程/"}],tags:[{name:"ECharts",path:"/tags/ECharts/"},{name:"Hexo",path:"/tags/Hexo/"}],cover:"/images/cover/hexo.png",date:"2021-04-01T04:00:00.000Z",updated:"2022-03-29T01:00:00.000Z"},{title:"在 Hexo 中插入 ECharts 动态图表",path:"/post/6f565d8c.html",categories:[{name:"魔改教程",path:"/categories/魔改教程/"}],tags:[{name:"ECharts",path:"/tags/ECharts/"},{name:"Hexo",path:"/tags/Hexo/"}],cover:"/images/cover/hexo_echarts.png",date:"2021-01-05T03:51:01.000Z",updated:"2021-01-05T03:51:01.000Z"},{title:"ECharts 流域图",path:"/post/364f4c67.html",categories:[{name:"作品案例",path:"/categories/作品案例/"}],tags:[{name:"ECharts",path:"/tags/ECharts/"}],cover:"/images/cover/echarts_river.png",date:"2022-05-10T01:00:00.000Z",updated:"2022-05-10T01:00:00.000Z"},{title:"R 语言数据接口",path:"/post/996a1090.html",categories:[{name:"学习笔记",path:"/categories/学习笔记/"}],tags:[{name:"大数据",path:"/tags/大数据/"},{name:"R",path:"/tags/R/"}],cover:"/images/cover/r_data_interface.png",date:"2021-01-21T05:52:32.000Z",updated:"2021-01-21T05:52:32.000Z"},{title:"R 语言统计分析",path:"/post/741c153c.html",categories:[{name:"学习笔记",path:"/categories/学习笔记/"}],tags:[{name:"大数据",path:"/tags/大数据/"},{name:"R",path:"/tags/R/"}],cover:"/images/cover/r_statistics.jpg",date:"2021-01-22T02:10:41.000Z",updated:"2021-01-22T02:10:41.000Z"},{title:"Emoji 表情大全",path:"/post/f349e1f0.html",categories:[{name:"分享转载",path:"/categories/分享转载/"}],tags:[{name:"文档",path:"/tags/文档/"}],cover:"/images/cover/emoji.png",date:"2021-06-22T01:00:00.000Z",updated:"2021-06-22T01:00:00.000Z"},{title:"Hadoop 面试题解析",path:"/post/2b822834.html",categories:[{name:"面试系列",path:"/categories/面试系列/"}],tags:[{name:"大数据",path:"/tags/大数据/"},{name:"Hadoop",path:"/tags/Hadoop/"}],cover:"/images/cover/bigdata_interview.png",date:"2021-03-26T01:00:00.000Z",updated:"2021-03-26T01:00:00.000Z"},{title:"MySQL 面试题解析",path:"/post/54dbb40b.html",categories:[{name:"面试系列",path:"/categories/面试系列/"}],tags:[{name:"大数据",path:"/tags/大数据/"},{name:"MySQL",path:"/tags/MySQL/"}],cover:"/images/cover/bigdata_interview.png",date:"2021-04-14T01:00:00.000Z",updated:"2021-04-14T01:00:00.000Z"},{title:"Hexo 博客文章统计图",path:"/post/1213ef82.html",categories:[{name:"魔改教程",path:"/categories/魔改教程/"}],tags:[{name:"ECharts",path:"/tags/ECharts/"},{name:"Hexo",path:"/tags/Hexo/"}],cover:"/images/cover/hexo.png",date:"2021-04-01T01:00:00.000Z",updated:"2022-08-15T01:00:00.000Z"},{title:"Spark RDD 常用算子",path:"/post/c55e5115.html",categories:[{name:"学习笔记",path:"/categories/学习笔记/"}],tags:[{name:"大数据",path:"/tags/大数据/"},{name:"Spark",path:"/tags/Spark/"}],cover:"/images/cover/spark_rdd.jpg",date:"2021-05-07T01:00:00.000Z",updated:"2021-05-07T01:00:00.000Z"},{title:"Java 面试题解析（Java Web）",path:"/post/d24a315e.html",categories:[{name:"面试系列",path:"/categories/面试系列/"}],tags:[{name:"Java",path:"/tags/Java/"}],cover:"/images/cover/java_interview.jpg",date:"2021-03-22T01:00:00.000Z",updated:"2021-03-22T01:00:00.000Z"},{title:"Java 面试题解析（基础）",path:"/post/11ea51ea.html",categories:[{name:"面试系列",path:"/categories/面试系列/"}],tags:[{name:"Java",path:"/tags/Java/"}],cover:"/images/cover/java_interview.jpg",date:"2021-03-16T01:00:00.000Z",updated:"2021-03-16T01:00:00.000Z"},{title:"Spark 面试题解析",path:"/post/cccf27af.html",categories:[{name:"面试系列",path:"/categories/面试系列/"}],tags:[{name:"大数据",path:"/tags/大数据/"},{name:"Spark",path:"/tags/Spark/"}],cover:"/images/cover/bigdata_interview.png",date:"2021-05-26T01:00:00.000Z",updated:"2021-05-26T01:00:00.000Z"},{title:"R 语言教程",path:"/post/de0e67e.html",categories:[{name:"学习笔记",path:"/categories/学习笔记/"}],tags:[{name:"大数据",path:"/tags/大数据/"},{name:"R",path:"/tags/R/"}],cover:"/images/cover/r_course.png",date:"2021-01-18T08:20:11.000Z",updated:"2021-01-18T08:20:11.000Z"},{title:"Hive SQL 大全",path:"/post/7891b2e6.html",categories:[{name:"学习笔记",path:"/categories/学习笔记/"}],tags:[{name:"大数据",path:"/tags/大数据/"},{name:"Hive",path:"/tags/Hive/"}],cover:"/images/cover/hive.jpg",date:"2021-04-07T01:00:00.000Z",updated:"2021-04-07T01:00:00.000Z"},{title:"大数据精选清单",path:"/post/fc3d946f.html",categories:[{name:"学习笔记",path:"/categories/学习笔记/"}],tags:[{name:"大数据",path:"/tags/大数据/"},{name:"文档",path:"/tags/文档/"}],cover:"/images/cover/bigdata_list.jpg",date:"2021-01-07T02:35:46.000Z",updated:"2021-01-07T02:35:46.000Z"},{title:"Java 面试题解析（Java EE）",path:"/post/dc04fa32.html",categories:[{name:"面试系列",path:"/categories/面试系列/"}],tags:[{name:"Java",path:"/tags/Java/"}],cover:"/images/cover/java_interview.jpg",date:"2021-03-23T01:00:00.000Z",updated:"2021-03-23T01:00:00.000Z"},{title:"MySQL 教程",path:"/post/7f59cefa.html",categories:[{name:"学习笔记",path:"/categories/学习笔记/"}],tags:[{name:"大数据",path:"/tags/大数据/"},{name:"MySQL",path:"/tags/MySQL/"}],cover:"/images/cover/mysql_course.jpg",date:"2021-01-09T02:35:46.000Z",updated:"2021-01-09T02:35:46.000Z"}];function toRandomPost(){window.pjax?pjax.loadUrl(posts[Math.floor(Math.random()*posts.length)].path):window.open(posts[Math.floor(Math.random()*posts.length)].path,"_self")}</script><script>var flinks=[{name:"Eurkon",link:"https://blog.eurkon.com",avatar:"https://blog.eurkon.com/images/user/avatar.jpg",descr:"及时当勉励，岁月不待人。"},{name:"MYW",link:"https://crazywong.com/",avatar:"https://crazywong.com/img/avatar.png",descr:"今日事,今日毕"},{name:"Akilar",link:"https://akilar.top/",avatar:"https://npm.elemecdn.com/akilar-friends@latest/avatar/akilar.top.jpg",descr:"期待您的光临！",siteshot:null},{name:"小冰博客",link:"https://zfe.space",avatar:"https://zfe.space/images/headimage.png",descr:"做个有梦想的人！"},{name:"Heo",link:"https://blog.zhheo.com/",avatar:"https://blog.zhheo.com/img/avatar.png",descr:"爱折腾的设计师"},{name:"Leonus",link:"https://blog.leonus.cn/",avatar:"https://q1.qlogo.cn/g?b=qq&nk=553344777&s=5",descr:"进一寸有进一寸的欢喜。"},{name:"Maxbit",link:"https://cakepanit.com/",avatar:"https://cakepanit.com/img/avatar.jpg",descr:"寻找属于自己的彩虹海",siteshot:"https://fastly.jsdelivr.net/gh/zhangyazhuang/cdn/img/bei.jpg"},{name:"FF",link:"https://foolishfox.cn/",avatar:"https://asset.foolishfox.cn/static/avatar.jpg",descr:"foolish fox"},{name:"Harris",link:"https://blog.harriswong.top/",avatar:"https://cdn.jsdelivr.net/npm/hassan-assets/img/avatar_blog.jpg",descr:"时不我待，只争朝夕"},{name:"Tianli",link:"https://tianli-blog.club",avatar:"https://q2.qlogo.cn/headimg_dl?dst_uin=507249007&spec=640",descr:"惟其不可能，所以才相信。"},{name:"慕木",link:"https://iori-yimaga.top",avatar:"https://avatars.githubusercontent.com/u/33000237?v=4",descr:"当程序运行的那一刻，我知道是编译器对我的温柔",siteshot:"https://fastly.jsdelivr.net/gh/Iori-yimaga/ScreenShot@gh-pages/iori-yimaga.top.jpg"},{name:"沐印小站",link:"https://c.undf.top/",avatar:"https://c.undf.top/icon/android-chrome-144x144.png",descr:"时间不在于你拥有多少，而在于你如何使用!"},{name:"MJ",link:"https://blog.justlovesmile.top",avatar:"https://blog.justlovesmile.top/img/avatar.jpg",descr:"醒亦念卿，梦亦念卿"},{name:"Gahotx",link:"https://gahotx.cn/",avatar:"https://pub.gahotx.cn/photo/cat.jpg",descr:"Don’t repeat yourself"},{name:"小孙同学",link:"https://blog.sunguoqi.com/",avatar:"https://blog.sunguoqi.com/images/avatar.jpg",descr:"热爱可抵漫长岁月！"},{name:"星空下的YZY",link:"https://226yzy.com",avatar:"https://226yzy.com/medias/avatar.jpg",descr:"记录一枚菜鸟的征程"},{name:"DoraKika",link:"https://blog.dorakika.cn",avatar:"https://thirdqq.qlogo.cn/g?b=sdk&nk=1633198089&s=140",descr:"热爱漫无边际，生活自有分寸！"},{name:"ImCaO",link:"https://www.imcao.cn",avatar:"https://www.imcao.cn/avatar.png",descr:"花有重开日，人无再少年。"},{name:"btwoa",link:"https://blog.btwoa.com",avatar:"https://ovo.btwoa.com/img/gif/btwoa.gif",descr:"我仍相信人间滚烫"},{name:"小曹同学",link:"https://cgq.suduhulian.top/",avatar:"http://q1.qlogo.cn/g?b=qq&nk=3514332263&s=640",descr:"一个学Py的人"},{name:"欢乐小王",link:"https://happyking.top/",avatar:"https://happyking.top/img/avatar.gif",descr:"聚散无常,别来无恙."},{name:"EmoryHuang",link:"https://emoryhuang.cn/",avatar:"https://static.emoryhuang.cn/img/emoryhuang-avatar.png",descr:"Learning everything"},{name:"LanYun",link:"https://lanyundev.com/",avatar:"https://lanyundev.com/img/logo.jpg.webp",descr:"Share Technology."},{name:"Bore",link:"https://bore.vip",avatar:"https://bore.vip/img/avatar.jpg",descr:"博观而约取，厚积而薄发。"},{name:"JayHrn",link:"https://blog.lvhrn.cn/",avatar:"https://npm.onmicrosoft.cn/hrn-img@1.0.0/img/avatar.jpg",descr:"念念不忘，必有回响"},{name:"枫叶",link:"https://blog.aqcoder.cn",avatar:"https://blog.aqcoder.cn/img/avatar.png",descr:"分享知识，认识世界"},{name:"liferecords",link:"https://nav.liferecords.top/",avatar:"https://cdn.liferecords.top/person/logo.jpg",descr:"从私域转到公域的助益者"},{name:"Fomalhaut🥝",link:"https://www.fomal.cc/",avatar:"https://www.fomal.cc/assets/avatar.webp",descr:"Future is now 🍭🍭🍭",siteshot:"https://source.fomal.cc/siteshot/www.fomal.cc.webp"},{name:"Mycpen",link:"https://blog.cpen.top/",avatar:"https://image.cpen.top/image/avatar.jpg",descr:"这是一个有趣的博客"},{name:"小城故事",link:"https://www.webxc.ml/",avatar:"https://npm.elemecdn.com/webxc/logo/logo.jpg",descr:"欢迎光临小城故事!"},{name:"Xlenco",link:"https://xlenco.eu.org",avatar:"https://ik.imagekit.io/nicexl/head.jpg",descr:"最好的地方是没去过的地方，最好的时光，是回不来的时光。"},{name:"ichika",link:"https://ichika.cc",avatar:"https://ichika.cc/img/Page/HeadIcon.jpg",descr:"Hello,gamer!",siteshot:"https://cos.ichika.cc/link/ichikashot.png"},{name:"九九九感冒绫",link:"https://miku-39.love/",avatar:"https://s2.loli.net/2022/10/18/soq82lvxakjeHB1.jpg",descr:"这是我的梦想,我会慢慢的完成它",siteshot:"https://s2.loli.net/2022/10/18/9KaSTU7OrWHkyEq.png"},{name:"丘卡饮品店",link:"https://blog.zerolacqua.top",avatar:"https://unpkg.com/zerolacqua-assets/images/avatar.png",descr:"要来点喝的吗？"},{name:"张时贰",link:"https://zhsher.cn",avatar:"https://q1.qlogo.cn/g?b=qq&nk=1310446718&s=5",descr:"环转码，爱敲代码的小张！"},{name:"Heyiki",link:"https://www.heyiki.top",avatar:"https://npm.elemecdn.com/heyiki-cdn/img/1.jpg",descr:"梦在旅途，永不止步。"},{name:"小华同学927",link:"https://blog.xiaohua927.top/",avatar:"https://i.imgtg.com/2022/12/01/DM501.jpg",descr:"行而不辍，未来可期！"},{name:"竹山一叶",link:"https://zsyyblog.com",avatar:"https://img.zsyyblog.com/favicon.jpg",descr:"来了就不想走的小家"},{name:"云野生SRE",link:"https://www.xadocker.cn",avatar:"https://www.xadocker.cn/wp-content/uploads/2022/04/2082e818343d236c1e5268eae30480bb-96x96.jpeg",descr:"云野生SRE"},{name:"SLOVER",link:"https://678777.xyz",avatar:"https://s1.vika.cn/space/2022/11/06/9e4c4d54cff74c70b1a4abe37d4bd6e8",descr:"诱导已亮，前方净空，祝君武运昌隆",siteshot:"https://s1.vika.cn/space/2023/01/03/ed2f8872abc64ea18af2fbbd6a1120c7"},{name:"ReCclay🖥️",link:"https://www.recclay.cc/",siteshot:"https://www.recclay.cc/img/2023-01-02.png",avatar:"https://www.recclay.cc/img/recclay.png",descr:"芯片硅农，别忘无恙🧐"},{name:"Shine",link:"https://blog.shineyu.cn/",avatar:"https://s3.bmp.ovh/imgs/2022/11/23/129c19d56d22c637.png",descr:"Let’s go! Target: The Vast Stars!",siteshot:"https://s3.bmp.ovh/imgs/2022/12/28/fe2452f7c4ff48ee.png"},{name:"小码博客",link:"https://blog.hikki.site",avatar:"https://bu.dusays.com/2022/11/04/636511250b21b.jpg",descr:"喜欢的东西就努力去追求，万一成功了呢!"},{name:"南方嘉木",link:"https://gavin-chen.top/",avatar:"https://i.imgtg.com/2023/01/06/GZRKN.jpg",descr:"不畏将来, 不念过往。"},{name:"Prong",link:"https://prong.ltd",avatar:"https://prong-1316442664.cos.ap-nanjing.myqcloud.com/picgo/202301242359645.webp",descr:"尖头叉子在霍格沃茨的休息室~",siteshot:"https://prong-1316442664.cos.ap-nanjing.myqcloud.com/picgo/202301252110840.webp"},{name:"满心记",link:"https://blog.lovelu.top",avatar:"https://cdn.lovelu.top/img/logo.png",descr:"追求让人充实，分享让人快乐"},{name:"怕冷爱上雪",link:"https://blog.4t.pw/",avatar:"https://blog.4t.pw/img/favicon.webp",descr:"千里之行，始于足下。"},{name:"雷雷屋头",link:"https://ll.sc.cn",avatar:"https://ll.sc.cn/img/avatar.png",descr:"爱生活，爱工作，爱折腾。",siteshot:"https://ll.sc.cn/img/siteshot.webp"},{name:"小吉崽汁の窝",link:"https://wuxingzzz.top",avatar:"https://www.wuxingzzz.top/hexo/IMG_3969.JPG",siteshot:"https://www.wuxingzzz.top/article/1592180893591904258.jpg",descr:"A programmer of vegetable chicken"},{name:"龙儿之家",link:"https://blog.huangge1199.cn",avatar:"https://blog.huangge1199.cn/upload/favicon.png",descr:"一个热衷于做小码农的程序媛！！！"},{name:"小朋同学",link:"https://blog.vip88.email",avatar:"https://blog.vip88.email/img/default_avatar.webp",descr:"朝着诗和远方慢慢走去",siteshot:"https://img.vip88.email/img/999.png"},{name:"王同学",link:"https://demo.wxz666.icu/",avatar:"http://www.wxz666.icu/img/favicon.ico.jpg",descr:"须知少时凌云志，曾许人间第一流"},{name:"李程ic",link:"https://www.licic.net/",avatar:"https://admin.licic.net/favicon.png",descr:"坚持很难；但是很酷！",siteshot:"https://admin.licic.net/screenshot.png"},{name:"回忆航线",link:"https://moony.la/",avatar:"https://moony.la/upload/logo.png",descr:"喜欢捣鼓的博主"},{name:"爱吃肉的猫",link:"https://meuicat.com/",avatar:"https://s1.ax1x.com/2023/05/26/p9qChjI.jpg",descr:"有肉有猫有生活."},{name:"虎了吧唧",link:"https://hulebaji.me",avatar:"https://cravatar.cn/avatar/c126bb295caa6f29cbbd32083708cda4?d=identicon",descr:"研墨成浆，提笔思量"},{name:"毕少侠",link:"https://hexo.geekswg.top/",avatar:"https://hexo.geekswg.top/imgs/avatar.webp",descr:"毕少侠也在江湖",siteshot:"https://hexo.geekswg.top/imgs/default-cover.webp"},{name:"猫四叔",link:"https://blog.hieroglyphs.top/",avatar:"https://npm.elemecdn.com/hieroglyphs.files/images/others/logo.png",descr:"一生俯首拜阳明"},{name:"铭心石刻",link:"https://blog.kouseki.cn/",avatar:"https://blog.kouseki.cn/imgs/avatar.webp",descr:"愿岁并谢，与友长兮"},{name:"xhang",link:"https://xhablog.online/",avatar:"https://i.postimg.cc/VNTPknVj/avatar.webp",descr:"一切都值得期待"},{name:"海拥",link:"https://haiyong.site",avatar:"https://haiyong.site/img/favicon.png",descr:"一枚乐于分享技术与快乐的博主"},{name:"虹色轨迹🌠",link:"https://ovoz.cn",avatar:"https://ovoz.cn/assets/avatar.webp",descr:"做一颗星星，有棱有角，黑暗中闪闪发光🍭🍭🍭",siteshot:"https://ovoz.cn/assets/ovoz.cn.jpg"},{name:"SuYi-宿仪",link:"https://www.thotz.top/",avatar:"https://pic.imgdb.cn/item/6497c3401ddac507ccd9334c.jpg",descr:"随心写作，随缘阅读"},{name:"神经蛙",link:"https://hexo.sjava.cn/",avatar:"https://hexo.sjava.cn/img/pic.png",descr:"种一棵树最好的时间是十年前，其次是现在。",siteshot:"https://hexo.sjava.cn/img/sjw.png"},{name:"小嗷犬的技术小站",link:"https://blog.marquis.eu.org/",avatar:"https://blog.marquis.eu.org/img/avatar/2.png",descr:"为天地立心，为生民立命，为往圣继绝学，为万世开太平"},{name:"Cisyam",link:"https://manamn.space/",avatar:"https://gaoziman.oss-cn-hangzhou.aliyuncs.com/img/202307151545455.jpg",descr:"分享思想，留下痕迹",siteshot:"https://gaoziman.oss-cn-hangzhou.aliyuncs.com/img/202307151545874.png"},{name:"杀死一只知更鸟",link:"https://www.shangjidong.com",avatar:"https://www.shangjidong.com/usr/uploads/2023/07/1002399499.gif",descr:"前端技术分享、前端学习记录"},{name:"棋の小站",link:"https://blog.qi1.zone/",avatar:"https://blog.qi1.zone/avatar.png",descr:"记录生活与心得。"},{name:"qxdn",link:"https://qianxu.run",avatar:"https://qianxu.run/images/avatar.jpg",descr:"蓬生麻中，不扶自直"},{name:"阳小楊",link:"https://blog.yxyang.top",avatar:"https://pic.imgdb.cn/item/65708f75c458853aefa8c951.jpg",descr:"无人了解你的灵魂．",siteshot:"https://pic.imgdb.cn/item/65709596c458853aefc6469c.png"},{name:"云深不知处",link:"https://www.lanzlz.cn",avatar:"https://oss.lanzlz.cn/private/hIwTot.png",descr:"不食人间烟火 且饮半杯风霜"},{name:"虹色轨迹🌠",link:"https://dil.illlli.com",avatar:"https://dil.illlli.com/assets/avatar.webp",descr:"做一颗星星，有棱有角，黑暗中闪闪发光🍭🍭🍭",siteshot:"https://dil.illlli.com/assets/dil.webp"},{name:"小鹿",link:"https://siena.zone",avatar:"https://siena.zone/favicon_compressed.png",descr:"跳吧，在无比宏大的星系！"},{name:"Calyee",link:"https://blog.calyee.top/",avatar:"https://blog.calyee.top/img/avatar.jpg",descr:"追求充实，分享快乐",siteshot:"https://blog.calyee.top/img/siteshot.png"},{name:"琅環书生",link:"https://www.zlog.us.kg",avatar:"https://images.zlog.us.kg/hexo/琅環书生头像.webp",descr:"无远弗届，皆有可能",siteshot:"https://images.zlog.us.kg/hexo/琅環书生站点.webp"},{name:"SeaEpoch",link:"https://www.seayj.cn",avatar:"https://www.seayj.cn/img/avatar.png",descr:"她站在那里，就像一个小小的永恒！",siteshot:"https://www.seayj.cn/img/siteshoot.jpg"},{name:"彬红茶栈",link:"https://resource.redcha.cn",avatar:"https://cn-sy1.rains3.com/binhongtea/studio2.png",descr:"彬红茶栈"}];function toRandomFlink(){window.open(flinks[Math.floor(Math.random()*flinks.length)].link)}</script>